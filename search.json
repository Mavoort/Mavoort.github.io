[
  {
    "objectID": "rss-feed.html",
    "href": "rss-feed.html",
    "title": "RSS Feed",
    "section": "",
    "text": "Julia Tutorial\n\n\nLast week we started programming with Julia, covering basic control flow, functions and strings. In this video we will learn about Julias type system and a very powerful mechanism called “multiple dispatch”. We will also talk about important data structures such as arrays, sets and dictionaries.\n\n\n\n\n\nJan 12, 2025\n\n\nMarcel Angenvoort\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "Optimization/fundamentals_of_optimization.html",
    "href": "Optimization/fundamentals_of_optimization.html",
    "title": "Fundamentals of Optimization",
    "section": "",
    "text": "An Optimization problem in standard form is given by:\n\\[\n\\begin{aligned}\n\\text{minimize} &\\quad f(\\mathbf{x}) \\\\\n\\text{s.t.} \\quad\n\\mathbf{h}(\\mathbf{x}) &= 0 \\\\\n\\mathbf{g}(\\mathbf{x}) &\\leq 0\n\\end{aligned}\n\\]\n. . .\nWe call \\(\\mathbf{x}^\\ast\\) an optimal point if it solves the optimization problem, and \\(p^\\ast\\) is the corresponding optimal value.\n. . .\nExamples: (see notes 1)\n\nbox constraints\nmaximization problems\nequivalence of optimization problems\n\n\n\nWe can transform the optimization problem from the standard form to the epigraph form:\n\\[\n\\begin{aligned}\n\\text{minimize} \\quad &t \\\\\n\\text{s.t.}  \\quad\nf(\\mathbf{x}) - t &\\leq 0 \\\\\n\\qquad \\mathbf{g}(\\mathbf{x}) &\\leq \\mathbf{0} \\\\\n\\qquad \\mathbf{h}(\\mathbf{x}) &= \\mathbf{0}\n\\end{aligned}\n\\]\n. . .\nGeometrically, we can interpret this as an optimisation problem in ‘graph space’. Find \\(x\\) and \\(t\\) such that \\((x, t)\\) belongs to the epigraph of \\(f\\), and such that \\(x\\) belongs to the feasible region.\n\n\nCode\nusing Plots\nusing LaTeXStrings\ntheme(:dark)\n\n#default(size = (800, 600))  # set default plot size\n\n# Define the function f(x)\nf(x) = - 0.0457x^3 + 0.7886x^2 - 3.0857x + 5.5\n\n# Define the x-range\nx_range = 0:0.01:6\n\n# Find the minimum point (x*, f(x*)) for the visualization\nx_star = 2.5\n\n# Create the plot\nplot(x_range, f.(x_range),\n    label = \"f(x)\",\n    linewidth = 4,\n    color = :black,\n    xlabel = \"x\",\n    ylabel = \"t\",\n    title = \"Optimization Problem in Epigraph Form\",\n    ylim = (0, 5.5),\n    legend = false,\n)\n\n# Fill the area above the graph in blue to represent epi(f)\nplot!(x_range, f.(x_range),\n  fillrange = 5.5, fillalpha = 0.2, c = :blue, linealpha = 0)\n\n# Add the label \"epi(f)\" in the middle of the blue area\nannotate!(2.5, 4, text(\"epi(f)\", :center, 20, :black))\nannotate!(2.6, 1.9, text(L\"(x^\\ast, t^\\ast)\", :left, :top, :white, 20))\n\n# Add the red point at (x*, f(x*))\nscatter!([x_star], [f(x_star)],\n    markersize = 8,\n    markercolor = :red,\n)\n\n\n\n\n\n\n\nFigure 1: Optimization problem in Epigraph form\n\n\n\n\n\nConsider the following optimization problem: \\[\n\\begin{aligned}\n\\text{minimize} \\quad&f(\\mathbf{x}_1, \\mathbf{x}_2) \\\\\n\\text{subject to}\\quad &\\mathbf{g}(\\mathbf{x_1}) \\leq 0 \\\\\n&\\tilde{\\mathbf{g}}(\\mathbf{x_2}) \\leq 0\n\\end{aligned}\n\\]\n. . .\nIf we define the function \\(\\tilde{f}\\) via \\[\n\\tilde{f}(\\mathbf{x}) := \\inf \\bigl\\{ f(\\mathbf{x}, \\mathbf{z}) : \\tilde{g}(\\mathbf{z}) \\leq \\mathbf{0} \\bigr\\},\n\\]\n. . .\nthen the optimization problem is equivalent to: \\[\n\\begin{aligned}\n\\text{minimize} \\quad &\\tilde{f}(\\mathbf{x}) \\\\\n\\text{subject to} \\quad &\\mathbf{g}(\\mathbf{x}) \\leq 0\n\\end{aligned}\n\\]\n. . .\nExample: see notes 2.\n\n\n\nA convex optimization problem has the form:\n\\[\n\\begin{aligned}\n\\text{minimize}\\quad &f(\\mathbf{x}) \\\\\n\\text{s.t.} \\quad &\\mathbf{g}(\\mathbf{x}) \\leq 0 \\\\\n&\\mathbf{a}^\\mathrm{T} \\mathbf{x} = b\n\\end{aligned}\n\\]\nwhere:\n\nthe objective function \\(f\\) is convex,\nthe inequality constraints \\(\\mathbf{g}\\) are convex,\nthe equality constraints \\(\\mathbf{h}\\) are affine\n\n\n\n\nLet \\[\nX := \\bigl \\{ \\mathbf{x} \\in \\mathbb{R}^n: \\, \\mathbf{g}(\\mathbf{x}) \\leq \\mathbf{0}, \\, \\mathbf{h}(\\mathbf{x}) = \\mathbf{0} \\bigr \\}\n\\] be the feasible set.\nThen the following optimality criterion holds:\n. . .\n\n\n\n\n\n\nImportantOptimality Criterion\n\n\n\nThe point \\(x^\\ast\\) is an optimal point for the optimization problem if and only if \\[\n\\nabla f(\\mathbf{x}^\\ast) \\cdot ( \\mathbf{y} - \\mathbf{x}^\\ast ) \\geq 0 \\quad \\forall \\mathbf{y} \\in X\n\\]\n\n\n\nProof. See notes 3.\n\n\n\n\nA linear program is an optimization problem where the objective function is linear and the constraint functions are affine.\n\\[\n\\begin{aligned}\n\\text{minimize} \\quad & \\mathbf{c}^\\mathrm{T} \\mathrm{x} + \\mathbf{d} \\\\\n\\text{s.t.} \\quad& B\\mathbf{x} \\leq \\mathbf{h}, \\\\\n&A\\mathbf{x} = \\mathbf{b}\n\\end{aligned}\n\\]\n. . .\nBy introducing a slack variable \\(s\\), this can be transformed into a linear program in standard form:\n. . .\n\\[\n\\begin{aligned}\n\\text{minimize} \\quad \\mathbf{c}^\\mathrm{T} \\mathbf{x} \\\\\n\\begin{aligned}\n\\text{s.t.} \\quad\nB\\mathbf{x} + \\mathbf{s} &= \\mathbf{h} \\\\\nA\\mathbf{x} &= \\mathbf{b} \\\\\n\\mathbf{s} &\\geq \\mathbf{0}\n\\end{aligned}\n\\end{aligned}\n\\]\n\n\n\nThe convex optimization problem is called a quadratic program (QP) if the objective function is quadratic, and the constraint functions are affine.\n\\[\n\\begin{aligned}\n\\text{minimize}\\quad & \\frac{1}{2} \\mathbf{x}^\\mathrm{T} P \\mathbf{x} + \\mathbf{q}^\\mathrm{T} \\mathbf{x} + r, \\\\\n\\text{subject to} \\quad &\\quad G\\mathbf{x} \\leq \\mathbf{h} \\\\\n&\\quad A\\mathbf{x} = \\mathbf{b}\n\\end{aligned}\n\\]\n. . .\nVisually, this means we are minimizing a quadratic function over a polyhedron.\n\n\n\n\n\n\nFigure 2: Quadratic Programming\nIllustration of a quadratic program. You can see the contour lines of the objective function. The feasible set is a Polyhedron.\nauthor: Stéphane Caron\nsource: scaron.info license: CC BY 4.0\n\n\n\n. . .\nA generalization of a quadratic program is the quadratically constrained quadratic program (QCQP):\n\\[\n\\begin{aligned}\n\\text{minimize}\\quad & \\frac{1}{2} \\mathbf{x}^\\mathrm{T} P \\mathbf{x} + \\mathbf{q}^\\mathrm{T} \\mathbf{x} + r, \\\\\n\\text{subject to} \\quad& \\frac{1}{2} \\mathbf{x}^\\mathrm{T} P_i \\mathbf{x} + \\mathbf{q}_i^\\mathrm{T} \\mathbf{x} + r_i \\leq 0, \\\\\n&\\quad A\\mathbf{x} = \\mathbf{b}\n\\end{aligned}\n\\]\nwhere \\(P_i\\) are all symmetric positive definite.\n. . .\nObviously, every quadratic program is also a QCQP.\n\n\n\nLinear regression leads to an over-determined linear system of equations \\(A\\mathbf{x} = \\mathbf{b}\\).\nFinding the optimal solution is equivalent to minimizing the residual sum-of-sqares error\n\\[\nE(\\mathbf{x}) = \\frac{1}{2} \\lVert A\\mathbf{x} - b \\rVert^2.\n\\]\nThis is a quadratic program and has the simple solution\n\\[\n\\mathbf{x} = A^\\dagger \\mathbf{b},\n\\]\nwhere \\(A^\\dagger = (A^\\mathrm{T} A)^{-1} A^\\mathrm{T}\\) is the pseudo-inverse of \\(A\\).\n. . .\nSometimes additional constraints are added as a lower and upper bound for \\(x\\), making the problem more complicated:\n\\[\n\\begin{aligned}\n\\text{minimize} \\quad &\\frac{1}{2} \\lVert A \\mathbf{x} - \\mathbf{b} \\rVert^2 \\\\\n\\text{s.t.} \\quad & a_i \\leq x_i \\leq b_i\n\\end{aligned}\n\\]\nFor a quadratic program like that there is no simple analytical solution anymore.\n\n\n\n\n\n\n\nTipDistance between Polyhedra\n\n\n\nConsider two Polyhedra:\n\\[\n\\mathcal{P}_1 := \\{ x : A_1 \\mathbf{x} \\leq \\mathbf{b}_1 \\bigr\\},\n\\qquad\n\\mathcal{P}_2 := \\{ x : A_2 \\mathbf{x} \\leq \\mathbf{b}_2 \\bigr\\}\n\\]\nThe distance between those polyhedra is given by:\n\\[\n\\mathrm{dist}(\\mathcal{P}_1, \\mathcal{P}_2) = \\inf \\bigl\\{ \\lVert \\mathbf{x}_1 - \\mathbf{x}_2 \\rVert_2 : \\mathbf{x}_1 \\in \\mathcal{P}_1, \\mathbf{x}_2 \\in \\mathcal{P}_2 \\bigr\\}\n\\]\n\n\n\nComputing the distance between two polyhedra leads to a quadratic program.\nlicense: CC0 (public domain)\n\n\nThis leads to the following optimization problem: \\[\n\\begin{aligned}\n\\text{minimize} \\quad &\\lVert \\mathbf{x}_1 - \\mathbf{x}_2 \\rVert^2 \\\\\n\\text{subject to} \\quad& A_1 \\mathbf{x}_1 \\leq \\mathbf{b}_1, \\quad A_2 \\mathbf{x}_2 \\leq \\mathbf{b}_2\n\\end{aligned}\n\\]\n\n\n\n\n\nClosely related to QCQP are second order cone programs (SOCP), which have the following form:\n\\[\n\\begin{aligned}\n\\text{minimize} & \\quad f(\\mathbf{x}) \\\\\n\\text{s.t.} &\\quad \\lVert A_i \\mathbf{x} + \\mathbf{b} \\rVert \\leq \\mathbf{c}_i^\\mathrm{T} \\mathbf{x} + \\mathbf{d}_i \\\\\n&\\quad F \\mathbf{x} = \\mathbf{g}\n\\end{aligned}\n\\]\nExample: minimal surface equation (see notes 4).\n\n\n\n\n\n\nNote\n\n\n\n\n\nTaylor-approximation: \\[\nf(\\mathbf{x}^\\ast + h\\Delta \\mathbf{x}) = f(\\mathbf{x}^\\ast) + h \\underbrace{\\nabla f(\\mathbf{x}^\\ast) \\cdot \\Delta \\mathbf{x}}_{=0} + \\frac{1}{2} \\Delta \\mathbf{x}^\\mathrm{T} H \\Delta \\mathbf{x} + \\mathcal{O}(h^3)\n\\]\nSince \\(f(\\mathbf{x}^\\ast + h \\Delta \\mathbf{x}) &gt; f(\\mathbf{x}^\\ast)\\), and \\(\\nabla f(\\mathbf{x}^\\ast) = \\mathbf{0}\\), we have \\[\n\\Delta \\mathbf{x}^\\mathrm{T} H \\Delta \\mathbf{x} \\gt 0\n\\]",
    "crumbs": [
      "About me",
      "Optimization",
      "Fundamentals of Optimization"
    ]
  },
  {
    "objectID": "Optimization/fundamentals_of_optimization.html#optimization-problems",
    "href": "Optimization/fundamentals_of_optimization.html#optimization-problems",
    "title": "Fundamentals of Optimization",
    "section": "",
    "text": "An Optimization problem in standard form is given by:\n\\[\n\\begin{aligned}\n\\text{minimize} &\\quad f(\\mathbf{x}) \\\\\n\\text{s.t.} \\quad\n\\mathbf{h}(\\mathbf{x}) &= 0 \\\\\n\\mathbf{g}(\\mathbf{x}) &\\leq 0\n\\end{aligned}\n\\]\n. . .\nWe call \\(\\mathbf{x}^\\ast\\) an optimal point if it solves the optimization problem, and \\(p^\\ast\\) is the corresponding optimal value.\n. . .\nExamples: (see notes 1)\n\nbox constraints\nmaximization problems\nequivalence of optimization problems\n\n\n\nWe can transform the optimization problem from the standard form to the epigraph form:\n\\[\n\\begin{aligned}\n\\text{minimize} \\quad &t \\\\\n\\text{s.t.}  \\quad\nf(\\mathbf{x}) - t &\\leq 0 \\\\\n\\qquad \\mathbf{g}(\\mathbf{x}) &\\leq \\mathbf{0} \\\\\n\\qquad \\mathbf{h}(\\mathbf{x}) &= \\mathbf{0}\n\\end{aligned}\n\\]\n. . .\nGeometrically, we can interpret this as an optimisation problem in ‘graph space’. Find \\(x\\) and \\(t\\) such that \\((x, t)\\) belongs to the epigraph of \\(f\\), and such that \\(x\\) belongs to the feasible region.\n\n\nCode\nusing Plots\nusing LaTeXStrings\ntheme(:dark)\n\n#default(size = (800, 600))  # set default plot size\n\n# Define the function f(x)\nf(x) = - 0.0457x^3 + 0.7886x^2 - 3.0857x + 5.5\n\n# Define the x-range\nx_range = 0:0.01:6\n\n# Find the minimum point (x*, f(x*)) for the visualization\nx_star = 2.5\n\n# Create the plot\nplot(x_range, f.(x_range),\n    label = \"f(x)\",\n    linewidth = 4,\n    color = :black,\n    xlabel = \"x\",\n    ylabel = \"t\",\n    title = \"Optimization Problem in Epigraph Form\",\n    ylim = (0, 5.5),\n    legend = false,\n)\n\n# Fill the area above the graph in blue to represent epi(f)\nplot!(x_range, f.(x_range),\n  fillrange = 5.5, fillalpha = 0.2, c = :blue, linealpha = 0)\n\n# Add the label \"epi(f)\" in the middle of the blue area\nannotate!(2.5, 4, text(\"epi(f)\", :center, 20, :black))\nannotate!(2.6, 1.9, text(L\"(x^\\ast, t^\\ast)\", :left, :top, :white, 20))\n\n# Add the red point at (x*, f(x*))\nscatter!([x_star], [f(x_star)],\n    markersize = 8,\n    markercolor = :red,\n)\n\n\n\n\n\n\n\nFigure 1: Optimization problem in Epigraph form\n\n\n\n\n\nConsider the following optimization problem: \\[\n\\begin{aligned}\n\\text{minimize} \\quad&f(\\mathbf{x}_1, \\mathbf{x}_2) \\\\\n\\text{subject to}\\quad &\\mathbf{g}(\\mathbf{x_1}) \\leq 0 \\\\\n&\\tilde{\\mathbf{g}}(\\mathbf{x_2}) \\leq 0\n\\end{aligned}\n\\]\n. . .\nIf we define the function \\(\\tilde{f}\\) via \\[\n\\tilde{f}(\\mathbf{x}) := \\inf \\bigl\\{ f(\\mathbf{x}, \\mathbf{z}) : \\tilde{g}(\\mathbf{z}) \\leq \\mathbf{0} \\bigr\\},\n\\]\n. . .\nthen the optimization problem is equivalent to: \\[\n\\begin{aligned}\n\\text{minimize} \\quad &\\tilde{f}(\\mathbf{x}) \\\\\n\\text{subject to} \\quad &\\mathbf{g}(\\mathbf{x}) \\leq 0\n\\end{aligned}\n\\]\n. . .\nExample: see notes 2.\n\n\n\nA convex optimization problem has the form:\n\\[\n\\begin{aligned}\n\\text{minimize}\\quad &f(\\mathbf{x}) \\\\\n\\text{s.t.} \\quad &\\mathbf{g}(\\mathbf{x}) \\leq 0 \\\\\n&\\mathbf{a}^\\mathrm{T} \\mathbf{x} = b\n\\end{aligned}\n\\]\nwhere:\n\nthe objective function \\(f\\) is convex,\nthe inequality constraints \\(\\mathbf{g}\\) are convex,\nthe equality constraints \\(\\mathbf{h}\\) are affine\n\n\n\n\nLet \\[\nX := \\bigl \\{ \\mathbf{x} \\in \\mathbb{R}^n: \\, \\mathbf{g}(\\mathbf{x}) \\leq \\mathbf{0}, \\, \\mathbf{h}(\\mathbf{x}) = \\mathbf{0} \\bigr \\}\n\\] be the feasible set.\nThen the following optimality criterion holds:\n. . .\n\n\n\n\n\n\nImportantOptimality Criterion\n\n\n\nThe point \\(x^\\ast\\) is an optimal point for the optimization problem if and only if \\[\n\\nabla f(\\mathbf{x}^\\ast) \\cdot ( \\mathbf{y} - \\mathbf{x}^\\ast ) \\geq 0 \\quad \\forall \\mathbf{y} \\in X\n\\]\n\n\n\nProof. See notes 3.\n\n\n\n\nA linear program is an optimization problem where the objective function is linear and the constraint functions are affine.\n\\[\n\\begin{aligned}\n\\text{minimize} \\quad & \\mathbf{c}^\\mathrm{T} \\mathrm{x} + \\mathbf{d} \\\\\n\\text{s.t.} \\quad& B\\mathbf{x} \\leq \\mathbf{h}, \\\\\n&A\\mathbf{x} = \\mathbf{b}\n\\end{aligned}\n\\]\n. . .\nBy introducing a slack variable \\(s\\), this can be transformed into a linear program in standard form:\n. . .\n\\[\n\\begin{aligned}\n\\text{minimize} \\quad \\mathbf{c}^\\mathrm{T} \\mathbf{x} \\\\\n\\begin{aligned}\n\\text{s.t.} \\quad\nB\\mathbf{x} + \\mathbf{s} &= \\mathbf{h} \\\\\nA\\mathbf{x} &= \\mathbf{b} \\\\\n\\mathbf{s} &\\geq \\mathbf{0}\n\\end{aligned}\n\\end{aligned}\n\\]\n\n\n\nThe convex optimization problem is called a quadratic program (QP) if the objective function is quadratic, and the constraint functions are affine.\n\\[\n\\begin{aligned}\n\\text{minimize}\\quad & \\frac{1}{2} \\mathbf{x}^\\mathrm{T} P \\mathbf{x} + \\mathbf{q}^\\mathrm{T} \\mathbf{x} + r, \\\\\n\\text{subject to} \\quad &\\quad G\\mathbf{x} \\leq \\mathbf{h} \\\\\n&\\quad A\\mathbf{x} = \\mathbf{b}\n\\end{aligned}\n\\]\n. . .\nVisually, this means we are minimizing a quadratic function over a polyhedron.\n\n\n\n\n\n\nFigure 2: Quadratic Programming\nIllustration of a quadratic program. You can see the contour lines of the objective function. The feasible set is a Polyhedron.\nauthor: Stéphane Caron\nsource: scaron.info license: CC BY 4.0\n\n\n\n. . .\nA generalization of a quadratic program is the quadratically constrained quadratic program (QCQP):\n\\[\n\\begin{aligned}\n\\text{minimize}\\quad & \\frac{1}{2} \\mathbf{x}^\\mathrm{T} P \\mathbf{x} + \\mathbf{q}^\\mathrm{T} \\mathbf{x} + r, \\\\\n\\text{subject to} \\quad& \\frac{1}{2} \\mathbf{x}^\\mathrm{T} P_i \\mathbf{x} + \\mathbf{q}_i^\\mathrm{T} \\mathbf{x} + r_i \\leq 0, \\\\\n&\\quad A\\mathbf{x} = \\mathbf{b}\n\\end{aligned}\n\\]\nwhere \\(P_i\\) are all symmetric positive definite.\n. . .\nObviously, every quadratic program is also a QCQP.\n\n\n\nLinear regression leads to an over-determined linear system of equations \\(A\\mathbf{x} = \\mathbf{b}\\).\nFinding the optimal solution is equivalent to minimizing the residual sum-of-sqares error\n\\[\nE(\\mathbf{x}) = \\frac{1}{2} \\lVert A\\mathbf{x} - b \\rVert^2.\n\\]\nThis is a quadratic program and has the simple solution\n\\[\n\\mathbf{x} = A^\\dagger \\mathbf{b},\n\\]\nwhere \\(A^\\dagger = (A^\\mathrm{T} A)^{-1} A^\\mathrm{T}\\) is the pseudo-inverse of \\(A\\).\n. . .\nSometimes additional constraints are added as a lower and upper bound for \\(x\\), making the problem more complicated:\n\\[\n\\begin{aligned}\n\\text{minimize} \\quad &\\frac{1}{2} \\lVert A \\mathbf{x} - \\mathbf{b} \\rVert^2 \\\\\n\\text{s.t.} \\quad & a_i \\leq x_i \\leq b_i\n\\end{aligned}\n\\]\nFor a quadratic program like that there is no simple analytical solution anymore.\n\n\n\n\n\n\n\nTipDistance between Polyhedra\n\n\n\nConsider two Polyhedra:\n\\[\n\\mathcal{P}_1 := \\{ x : A_1 \\mathbf{x} \\leq \\mathbf{b}_1 \\bigr\\},\n\\qquad\n\\mathcal{P}_2 := \\{ x : A_2 \\mathbf{x} \\leq \\mathbf{b}_2 \\bigr\\}\n\\]\nThe distance between those polyhedra is given by:\n\\[\n\\mathrm{dist}(\\mathcal{P}_1, \\mathcal{P}_2) = \\inf \\bigl\\{ \\lVert \\mathbf{x}_1 - \\mathbf{x}_2 \\rVert_2 : \\mathbf{x}_1 \\in \\mathcal{P}_1, \\mathbf{x}_2 \\in \\mathcal{P}_2 \\bigr\\}\n\\]\n\n\n\nComputing the distance between two polyhedra leads to a quadratic program.\nlicense: CC0 (public domain)\n\n\nThis leads to the following optimization problem: \\[\n\\begin{aligned}\n\\text{minimize} \\quad &\\lVert \\mathbf{x}_1 - \\mathbf{x}_2 \\rVert^2 \\\\\n\\text{subject to} \\quad& A_1 \\mathbf{x}_1 \\leq \\mathbf{b}_1, \\quad A_2 \\mathbf{x}_2 \\leq \\mathbf{b}_2\n\\end{aligned}\n\\]\n\n\n\n\n\nClosely related to QCQP are second order cone programs (SOCP), which have the following form:\n\\[\n\\begin{aligned}\n\\text{minimize} & \\quad f(\\mathbf{x}) \\\\\n\\text{s.t.} &\\quad \\lVert A_i \\mathbf{x} + \\mathbf{b} \\rVert \\leq \\mathbf{c}_i^\\mathrm{T} \\mathbf{x} + \\mathbf{d}_i \\\\\n&\\quad F \\mathbf{x} = \\mathbf{g}\n\\end{aligned}\n\\]\nExample: minimal surface equation (see notes 4).\n\n\n\n\n\n\nNote\n\n\n\n\n\nTaylor-approximation: \\[\nf(\\mathbf{x}^\\ast + h\\Delta \\mathbf{x}) = f(\\mathbf{x}^\\ast) + h \\underbrace{\\nabla f(\\mathbf{x}^\\ast) \\cdot \\Delta \\mathbf{x}}_{=0} + \\frac{1}{2} \\Delta \\mathbf{x}^\\mathrm{T} H \\Delta \\mathbf{x} + \\mathcal{O}(h^3)\n\\]\nSince \\(f(\\mathbf{x}^\\ast + h \\Delta \\mathbf{x}) &gt; f(\\mathbf{x}^\\ast)\\), and \\(\\nabla f(\\mathbf{x}^\\ast) = \\mathbf{0}\\), we have \\[\n\\Delta \\mathbf{x}^\\mathrm{T} H \\Delta \\mathbf{x} \\gt 0\n\\]",
    "crumbs": [
      "About me",
      "Optimization",
      "Fundamentals of Optimization"
    ]
  },
  {
    "objectID": "Optimization/fundamentals_of_optimization.html#duality",
    "href": "Optimization/fundamentals_of_optimization.html#duality",
    "title": "Fundamentals of Optimization",
    "section": "Duality",
    "text": "Duality\nConsider the non-linear optimization problem in standard form:\n\\[\n\\begin{aligned}\n\\text{minimize} \\; f(\\mathbf{x}) \\\\\n\\text{subject to } \\quad\n\\mathbf{h}(\\mathbf{x}) &= 0 \\\\\n\\mathbf{g}(\\mathbf{x}) &\\leq 0\n\\end{aligned}\n\\]\nHow do you take the constraints into account?\n. . .\nBasic idea: Add linear combination of constraint function to the objective function.\n\n\\[\nL(\\mathbf{x}, \\boldsymbol{\\lambda}, \\boldsymbol{\\nu}) :=\nf(\\mathbf{x}) + \\boldsymbol{\\lambda} \\cdot \\mathbf{h}(\\mathbf{x}) + \\boldsymbol{\\nu} \\cdot \\mathbf{g}(\\mathbf{x})\n\\]\n\n\\[\nL(\\mathbf{x}, \\boldsymbol{\\lambda}, \\boldsymbol{\\nu}) :=\nf(\\mathbf{x}) + \\sum_{i} \\mu_i g_i(\\mathbf{x}) + \\sum_j \\lambda_j h_j(\\mathbf{x})\n\\]\nThis is called the Lagrange-function.\n. . .\nThe optimization problem then transforms to:\n\\[\n\\underset{\\mathbf{x}}{\\mathrm{minimize}} \\;\n\\underset{\\boldsymbol{\\mu} \\gt 0, \\boldsymbol{\\lambda}}{\\mathrm{maximize}} \\;\nL(\\mathbf{x}, \\boldsymbol{\\mu}, \\boldsymbol{\\lambda})\n\\]\nIf we reverse the order of maximization and minization we obtain the dual form of the optimization problem:\n\\[\n\\underset{\\boldsymbol{\\mu} \\gt 0, \\boldsymbol{\\lambda}}{\\mathrm{maximize}} \\;\n\\underset{\\mathbf{x}}{\\mathrm{minimize}} \\;\nL(\\mathbf{x}, \\boldsymbol{\\mu}, \\boldsymbol{\\lambda})\n\\]\n\n\nCode\nusing Plots\nusing LaTeXStrings\ntheme(:dark)\ndefault(size = (800, 600))  # set default plot size\n\n# Define objective functions, constraint function, and Lagrangian\n# (Coefficients obtained from polynomial interpolation)\nf(x) = 0.0313178884607x^4 - 0.4376575805147x^3 + 1.9507119864263x^2 - 3.3803696303696x + 6.0\ng(x) = 1/2 * (x-3)^2 - 2\nL(x, λ) = f(x) + λ * g(x)\n\nx_range = 0:0.01:8\n\n# Plot objective function f\nfig = plot(x_range, f, label=\"f(x)\", c=:red, linewidth=2)\n\n# Vertical lines to mark the feasible region\nvline!(fig, [1], linestyle=:dash, linecolor=:white, label=\"\")\nvline!(fig, [5], linestyle=:dash, linecolor=:white, label=\"\")\n\n# Plot the feasible region\nx_feasible = x_range[1 .&lt;= x_range .&& x_range .&lt;= 5]\nf_feasible = f.(x_feasible)\nplot!(fig, x_feasible, f_feasible, label=\"Feasible Region\",\n      fillrange=0, color=:blue, alpha=0.1,\n      yrange=(0, 10), legend=:topright)\nannotate!(fig, 3.0, 1.0, \"feasible region\")\n\n\n# Function to determine the optimal x for a given Lagrange function\nx_optimal_for_lambda(λ) = x_range[argmin(L.(x_range, λ))]\n\n# Plot the Lagrangian for different lambdas\nfor λ in [0.1, 0.3, 0.5, 0.7, 0.9, 1.1, 1.3]\n    plot!(fig, x_range, L.(x_range, λ), label=\"\",\n          c=:lightblue, linewidth=1.5, linestyle=:dot)\nend\n\n# Get the optimal point of the Lagragian with given lambda\nfunction dual_function_parametric(λ)\n    x_min = x_optimal_for_lambda(λ)\n    y_min = L(x_min, λ)\n    return x_min, y_min\nend\n\nlambda_range = 0:0.01:1.3\npoints_tuple_array = dual_function_parametric.(lambda_range)\n\n# Extract x and y coordinates\nx_coords = first.(points_tuple_array)\ny_coords = last.(points_tuple_array)\n\n# Plot dual function\nplot!(fig, x_coords, y_coords, c=\"black\", linewidth=5, label=\"dual function\")\n\n# Scatter plot for the optima of the Lagrangian\nfor λ in [0.1, 0.3, 0.7, 0.9, 1.1, 1.3]\n    x_min = x_optimal_for_lambda(λ)\n    y_min = L(x_min, λ)\n    scatter!(fig, [x_min], [y_min], label=\"\", c=:black, markersize=4)\nend\n\n# Plot the optimal point\nscatter!(fig, [5], [f(5)], markersize=6, color=:green, label=\"optimal point\")\n\n# Don't forget to display the plot\ndisplay(fig)\n\n\n\n\n\n\n\nFigure 3: Plot of the Lagrange functions and the dual function\n\n\n\n\n\nExamples for the Lagrangian\n\n\n\n\n\n\nNoteExamples for the Lagrangian\n\n\n\nConsider the following optimization problem: \\[\n\\begin{aligned}\n\\text{minimize} &\\quad \\exp(x) - x \\\\\n\\text{such that} &\\quad x + 1 \\leq 0\n\\end{aligned}\n\\]\n. . .\n\n\nCode\nusing Plots\nusing LaTeXStrings\ntheme(:dark)\n\nx_range = -6:0.01:2\nf(x) = exp(x) - x\n\n# Plot objective function f\nplot(x_range, f, linewidth=3, label=L\"f(x)=e^x - x\")\n\n# Plot vertical lines to mark the boundary of the feasible region\nvline!([-1], linestyle=:dash, linecolor=:white, label=\"\")\n\n# Plot the feasible region\nx_feasible = x_range[x_range .&lt;= -1]\nf_feasible = f.(x_feasible)\nplot!(x_feasible, f_feasible, label=\"Feasible Region\",\n      fillrange=0, color=:blue, alpha=0.1,\n      legend=:topright)\nannotate!(-4.0, 2.0, \"feasible region\")\nannotate!(-4, 1.5, L\"x + 1 &lt; 0\")\n\n# Plot optimal point\nscatter!([-1], [f(-1)], c=:green, markersize=5, label=\"optimal point\")\nannotate!(-0.9, f(-1) + 0.1, text(\"optimal point\", :lightgray, :bottom, :left, 12))\n\n\n\n\n\n\n\nFigure 4: Plot of the optimization problem\n\n\n\n\n. . .\nThe Lagrangian is given by:\n\\[\n\\begin{aligned}\nL(x; \\lambda) &= f(x) + \\lambda g(x), \\qquad \\lambda \\gt 0 \\\\\n&= e^x + ( \\lambda - 1) x + \\lambda\n\\end{aligned}\n\\]\n. . .\nThe optimal \\(x\\) can be found through differentiation:\n\\[\n\\begin{aligned}\n\\frac{\\mathrm{d}}{\\mathrm{d}x} L(x; \\lambda) &= e^x + (\\lambda - 1) \\overset{\\text{!}}{=} 0 \\\\\n\\therefore \\quad x_\\text{opt}(\\lambda) &= \\ln(1 - \\lambda), \\qquad \\lambda &lt; 1\n\\end{aligned}\n\\]\n. . .\nSubstitue \\(x_\\text{opt}\\) for \\(x\\) to obtain the dual function \\(q(\\lambda)\\):\n\\[\n\\begin{aligned}\nq(\\lambda) &= L(x_\\text{opt}, \\lambda) \\\\\n&= \\exp\\bigr(\\ln( 1 - \\lambda) \\bigr) + (\\lambda - 1) \\ln( 1 - \\lambda) + \\lambda \\\\\n&= (\\lambda - 1) \\ln( 1 - \\lambda ) + 1, \\qquad 0 \\lt \\lambda \\lt 1\n\\end{aligned}\n\\]\n. . .\n\n\nCode\nusing Plots\nusing LaTeXStrings\ntheme(:dark)\n\nlambda_range = 0:0.01:0.99  # q(-1) = -Inf\nq(λ) = (λ - 1) * log(1 - λ) + 1\n\n# Plot the dual function\nplot(lambda_range, q, label=L\"q(\\lambda) = (\\lambda - 1) \\ln(1 - \\lambda) + 1\", linewidth=3)\n\n# Plot the optimum\nλ_opt = 1 - exp(-1)\nscatter!([λ_opt], [q(λ_opt)], c=:green, markersize=5, label=\"optimum\")\n\n# Title and axis labels\ntitle!(\"Dual function\")\nxlabel!(L\"\\lambda\")\nylabel!(L\"q(\\lambda)\")\n\n\n\n\n\n\n\nFigure 5: Plot of the dual function for the optimization problem\n\n\n\n\n. . .\nFind the optimal Lagrange parameter \\(\\lambda\\):\n\\[\n\\begin{aligned}\nq'(\\lambda) = 1 \\cdot \\ln( 1 - \\lambda ) + (\\lambda - 1) \\frac{1}{1-\\lambda} \\cdot (-1) \\overset{\\text{!}}{=} 0 \\\\\n\\ln(1-\\lambda) + 1 = 0 \\\\\n\\lambda_\\text{opt} = 1 - e^{-1}\n\\end{aligned}\n\\]\n. . .\nThus, the optimal point for the optimization problem in stadard form is:\n\\[\nx_\\text{opt} = \\ln(1 - \\lambda_\\text{opt}) = \\ln ( 1 - (1 - e^{-1})) = \\ln(e^{-1}) = -1\n\\]\nLooking at Figure 4, this result is exactly as expected.",
    "crumbs": [
      "About me",
      "Optimization",
      "Fundamentals of Optimization"
    ]
  },
  {
    "objectID": "Optimization/fundamentals_of_optimization.html#connection-between-the-lagrange-dual-function-and-the-conjugate-function",
    "href": "Optimization/fundamentals_of_optimization.html#connection-between-the-lagrange-dual-function-and-the-conjugate-function",
    "title": "Fundamentals of Optimization",
    "section": "Connection between the Lagrange dual function and the conjugate function",
    "text": "Connection between the Lagrange dual function and the conjugate function\nRemember that the dual function of a function \\(f\\) is defined by\n\\[\nf^\\ast (\\mathbf{y} ) := \\sup_{\\mathbf{x}} \\bigl\\{ \\mathbf{y}^\\mathrm{T} \\mathbf{x} - f(\\mathbf{x}) \\bigr\\}\n\\]\n. . .\nThe Lagrange function and the conjugate function are related.\nConsider the optimization problem\n\\[\n\\begin{aligned}\n\\text{minimize} && f(\\mathbf{x}) \\\\\n\\text{subject to} && \\mathbf{x} = 0\n\\end{aligned}\n\\]\nThen the Langrage dual function is: \\[\nq(\\boldsymbol{\\lambda} ) = \\inf_{\\mathbf{x}} \\bigl\\{ f(\\mathbf{x}) + \\boldsymbol{\\lambda}^\\mathrm{T} \\mathbf{x} \\bigr\\} = - \\inf_\\mathbf{x} \\bigl\\{ \\boldsymbol{\\lambda}^\\mathrm{T} \\mathbf{x} - f(\\mathbf{x}) \\bigr\\} = - f^\\ast(- \\boldsymbol{\\lambda})\n\\]\n\n\n\n\nClassical illustration for a positive duality gap\nsource: Dissecting the Duality Gap [1] author: Nils-Hassan Quttineh, Torbjörn Larsson\nlicense: CC BY 4.0\n\n\nTODO: Slate condition\nInterpration: Saddle Point, Game Theory",
    "crumbs": [
      "About me",
      "Optimization",
      "Fundamentals of Optimization"
    ]
  },
  {
    "objectID": "Optimization/fundamentals_of_optimization.html#todo",
    "href": "Optimization/fundamentals_of_optimization.html#todo",
    "title": "Fundamentals of Optimization",
    "section": "TODO",
    "text": "TODO\n\nEpigraph problem\nDual Problems (Boyd chapter 4)\nsufficient condition: \\(\\nabla f(\\hat{x}) = 0\\) and \\(H f(\\hat{x})\\) pos. definit, then local minimum\nOptimization algorithms: iterative. Typees: gradient based, trust-region,",
    "crumbs": [
      "About me",
      "Optimization",
      "Fundamentals of Optimization"
    ]
  },
  {
    "objectID": "Optimization/fundamentals_of_optimization-slides.html#optimization-problems",
    "href": "Optimization/fundamentals_of_optimization-slides.html#optimization-problems",
    "title": "Fundamentals of Optimization",
    "section": "Optimization Problems",
    "text": "Optimization Problems\nAn Optimization problem in standard form is given by:\n\\[\n\\begin{aligned}\n\\text{minimize} &\\quad f(\\mathbf{x}) \\\\\n\\text{s.t.} \\quad\n\\mathbf{h}(\\mathbf{x}) &= 0 \\\\\n\\mathbf{g}(\\mathbf{x}) &\\leq 0\n\\end{aligned}\n\\]\n\nWe call \\(\\mathbf{x}^\\ast\\) an optimal point if it solves the optimization problem, and \\(p^\\ast\\) is the corresponding optimal value.\n\n\nExamples: (see notes 1)\n\nbox constraints\nmaximization problems\nequivalence of optimization problems"
  },
  {
    "objectID": "Optimization/fundamentals_of_optimization-slides.html#duality",
    "href": "Optimization/fundamentals_of_optimization-slides.html#duality",
    "title": "Fundamentals of Optimization",
    "section": "Duality",
    "text": "Duality\nConsider the non-linear optimization problem in standard form:\n\\[\n\\begin{aligned}\n\\text{minimize} \\; f(\\mathbf{x}) \\\\\n\\text{subject to } \\quad\n\\mathbf{h}(\\mathbf{x}) &= 0 \\\\\n\\mathbf{g}(\\mathbf{x}) &\\leq 0\n\\end{aligned}\n\\]\nHow do you take the constraints into account?\n\nBasic idea: Add linear combination of constraint function to the objective function.\n\n\\[\nL(\\mathbf{x}, \\boldsymbol{\\lambda}, \\boldsymbol{\\nu}) :=\nf(\\mathbf{x}) + \\boldsymbol{\\lambda} \\cdot \\mathbf{h}(\\mathbf{x}) + \\boldsymbol{\\nu} \\cdot \\mathbf{g}(\\mathbf{x})\n\\]\n\n\\[\nL(\\mathbf{x}, \\boldsymbol{\\lambda}, \\boldsymbol{\\nu}) :=\nf(\\mathbf{x}) + \\sum_{i} \\mu_i g_i(\\mathbf{x}) + \\sum_j \\lambda_j h_j(\\mathbf{x})\n\\]\nThis is called the Lagrange-function.\n\n\nThe optimization problem then transforms to:\n\\[\n\\underset{\\mathbf{x}}{\\mathrm{minimize}} \\;\n\\underset{\\boldsymbol{\\mu} \\gt 0, \\boldsymbol{\\lambda}}{\\mathrm{maximize}} \\;\nL(\\mathbf{x}, \\boldsymbol{\\mu}, \\boldsymbol{\\lambda})\n\\]\nIf we reverse the order of maximization and minization we obtain the dual form of the optimization problem:\n\\[\n\\underset{\\boldsymbol{\\mu} \\gt 0, \\boldsymbol{\\lambda}}{\\mathrm{maximize}} \\;\n\\underset{\\mathbf{x}}{\\mathrm{minimize}} \\;\nL(\\mathbf{x}, \\boldsymbol{\\mu}, \\boldsymbol{\\lambda})\n\\]\n\n\nCode\nusing Plots\nusing LaTeXStrings\ntheme(:dark)\ndefault(size = (800, 600))  # set default plot size\n\n# Define objective functions, constraint function, and Lagrangian\n# (Coefficients obtained from polynomial interpolation)\nf(x) = 0.0313178884607x^4 - 0.4376575805147x^3 + 1.9507119864263x^2 - 3.3803696303696x + 6.0\ng(x) = 1/2 * (x-3)^2 - 2\nL(x, λ) = f(x) + λ * g(x)\n\nx_range = 0:0.01:8\n\n# Plot objective function f\nfig = plot(x_range, f, label=\"f(x)\", c=:red, linewidth=2)\n\n# Vertical lines to mark the feasible region\nvline!(fig, [1], linestyle=:dash, linecolor=:white, label=\"\")\nvline!(fig, [5], linestyle=:dash, linecolor=:white, label=\"\")\n\n# Plot the feasible region\nx_feasible = x_range[1 .&lt;= x_range .&& x_range .&lt;= 5]\nf_feasible = f.(x_feasible)\nplot!(fig, x_feasible, f_feasible, label=\"Feasible Region\",\n      fillrange=0, color=:blue, alpha=0.1,\n      yrange=(0, 10), legend=:topright)\nannotate!(fig, 3.0, 1.0, \"feasible region\")\n\n\n# Function to determine the optimal x for a given Lagrange function\nx_optimal_for_lambda(λ) = x_range[argmin(L.(x_range, λ))]\n\n# Plot the Lagrangian for different lambdas\nfor λ in [0.1, 0.3, 0.5, 0.7, 0.9, 1.1, 1.3]\n    plot!(fig, x_range, L.(x_range, λ), label=\"\",\n          c=:lightblue, linewidth=1.5, linestyle=:dot)\nend\n\n# Get the optimal point of the Lagragian with given lambda\nfunction dual_function_parametric(λ)\n    x_min = x_optimal_for_lambda(λ)\n    y_min = L(x_min, λ)\n    return x_min, y_min\nend\n\nlambda_range = 0:0.01:1.3\npoints_tuple_array = dual_function_parametric.(lambda_range)\n\n# Extract x and y coordinates\nx_coords = first.(points_tuple_array)\ny_coords = last.(points_tuple_array)\n\n# Plot dual function\nplot!(fig, x_coords, y_coords, c=\"black\", linewidth=5, label=\"dual function\")\n\n# Scatter plot for the optima of the Lagrangian\nfor λ in [0.1, 0.3, 0.7, 0.9, 1.1, 1.3]\n    x_min = x_optimal_for_lambda(λ)\n    y_min = L(x_min, λ)\n    scatter!(fig, [x_min], [y_min], label=\"\", c=:black, markersize=4)\nend\n\n# Plot the optimal point\nscatter!(fig, [5], [f(5)], markersize=6, color=:green, label=\"optimal point\")\n\n# Don't forget to display the plot\ndisplay(fig)\n\n\n\n\n\n\n\nFigure 3: Plot of the Lagrange functions and the dual function"
  },
  {
    "objectID": "Optimization/fundamentals_of_optimization-slides.html#connection-between-the-lagrange-dual-function-and-the-conjugate-function",
    "href": "Optimization/fundamentals_of_optimization-slides.html#connection-between-the-lagrange-dual-function-and-the-conjugate-function",
    "title": "Fundamentals of Optimization",
    "section": "Connection between the Lagrange dual function and the conjugate function",
    "text": "Connection between the Lagrange dual function and the conjugate function\nRemember that the dual function of a function \\(f\\) is defined by\n\\[\nf^\\ast (\\mathbf{y} ) := \\sup_{\\mathbf{x}} \\bigl\\{ \\mathbf{y}^\\mathrm{T} \\mathbf{x} - f(\\mathbf{x}) \\bigr\\}\n\\]\n\nThe Lagrange function and the conjugate function are related.\nConsider the optimization problem\n\\[\n\\begin{aligned}\n\\text{minimize} && f(\\mathbf{x}) \\\\\n\\text{subject to} && \\mathbf{x} = 0\n\\end{aligned}\n\\]\nThen the Langrage dual function is: \\[\nq(\\boldsymbol{\\lambda} ) = \\inf_{\\mathbf{x}} \\bigl\\{ f(\\mathbf{x}) + \\boldsymbol{\\lambda}^\\mathrm{T} \\mathbf{x} \\bigr\\} = - \\inf_\\mathbf{x} \\bigl\\{ \\boldsymbol{\\lambda}^\\mathrm{T} \\mathbf{x} - f(\\mathbf{x}) \\bigr\\} = - f^\\ast(- \\boldsymbol{\\lambda})\n\\]"
  },
  {
    "objectID": "Optimization/fundamentals_of_optimization-slides.html#todo",
    "href": "Optimization/fundamentals_of_optimization-slides.html#todo",
    "title": "Fundamentals of Optimization",
    "section": "TODO",
    "text": "TODO\n\nEpigraph problem\nDual Problems (Boyd chapter 4)\nsufficient condition: \\(\\nabla f(\\hat{x}) = 0\\) and \\(H f(\\hat{x})\\) pos. definit, then local minimum\nOptimization algorithms: iterative. Typees: gradient based, trust-region,\n\n\n\n\n\nQuttineh, Nils-Hassan, and Torbjörn Larsson. 2022. “Dissecting the Duality Gap: The Supporting Hyperplane Interpretation Revisited.” Optimization Letters 16 (3): 1093–1102. https://doi.org/10.1007/s11590-021-01764-7."
  },
  {
    "objectID": "NumLinAlg/index.html",
    "href": "NumLinAlg/index.html",
    "title": "Introduction",
    "section": "",
    "text": "Numerical linear algebra is the foundation of modern scientific computing. It deals with the numerical approximation of problems such as linear systems and eigenvalue problems. Many techniques for solving differential equations, such as the finite element method (FEM) or the finite difference method, lead to a system of linear equations; As such, numerical linear algebra has many applications: from image and signal processing to computational physics, data science and more.",
    "crumbs": [
      "About me",
      "Numerical Linear Algebra",
      "Introduction"
    ]
  },
  {
    "objectID": "NumLinAlg/index.html#why-learn-numerical-linear-algebra",
    "href": "NumLinAlg/index.html#why-learn-numerical-linear-algebra",
    "title": "Introduction",
    "section": "",
    "text": "Numerical linear algebra is the foundation of modern scientific computing. It deals with the numerical approximation of problems such as linear systems and eigenvalue problems. Many techniques for solving differential equations, such as the finite element method (FEM) or the finite difference method, lead to a system of linear equations; As such, numerical linear algebra has many applications: from image and signal processing to computational physics, data science and more.",
    "crumbs": [
      "About me",
      "Numerical Linear Algebra",
      "Introduction"
    ]
  },
  {
    "objectID": "NumLinAlg/index.html#about-this-course",
    "href": "NumLinAlg/index.html#about-this-course",
    "title": "Introduction",
    "section": "About this Course",
    "text": "About this Course\n\nTarget Audience\nThis course is primarily aimed at undergraduate students of mathematics, physics and engineering. However, it is also suitable for engineers who use these algorithms (linear solvers, multigrid methods) in commercial software and want to gain a deeper understanding of how they work.\n\n\nPrerequisites\nThis is not a linear algebra course, so a solid understanding of linear algebra is required. For the implementation of the numerical algorithms, it is also useful to have some programming skills in either MATLAB, Python or Julia. However, there will be a short introduction to Julia programming at the beginning, so basic programming skills are sufficient.\n\nTarget Audience This course is primarily aimed at undergraduate students of mathematics, physics and engineering. However, it is also suitable for engineers who use these algorithms (linear solvers, multigrid methods) in commercial software and want to gain a deeper understanding of how they work.\nPrerequisites This is not a linear algebra course, so a solid understanding of linear algebra is required. For the implementation of the numerical algorithms, it is also useful to have some programming skills in either MATLAB, Python or Julia. However, there will be a short introduction to Julia programming at the beginning, so basic programming skills are sufficient.\n\n\n\nSyllabus\n\nWeek 1 – 5: Introduction to Julia\nWeek 6 – 10: Algorithms for dense matrices\n\nPerturbation theory\nDirect solvers for linear systems\nIterative solvers for linear systems (Gauss-Seidel)\nCalculation of Eigenvalues (power method)\n\nWeek 11 – 26: Algorithms for sparse matrices\n\nSparse LU-decompostion\nSparse matrix ordering algorithms\nKrylow methods (CG, BiCGStab, GMRES)\nSpecial iteration methods (multigrid, domain decomposition)\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe exact structure of this course is subject to change and may vary.",
    "crumbs": [
      "About me",
      "Numerical Linear Algebra",
      "Introduction"
    ]
  },
  {
    "objectID": "NumLinAlg/index.html#literature",
    "href": "NumLinAlg/index.html#literature",
    "title": "Introduction",
    "section": "Literature",
    "text": "Literature\n\nTheoretical Textbooks\n\nThe standard textbook is (Golub and Van Loan 2013); it has over 1500 citations and covers basically everything. However, it is very dense and not very pleasant to read. I would recommend it more as a reference book rather than for self study.\nA good alternative is probably (Rannacher 2018), which is very readable and can be used as an introductory textbook. It is open-access.\nThe book (Meister 2015) is written by a former professor of mine. It is particularly interesting because it covers advanced Krylow-methods such as QMRCGSTAB and has a large chapter on Multigrid methods.\n\n\n\n\n\n\n\n\n(Golub and Van Loan 2013)\n\n\n\n\n\n \n\n\n\n\n\n\n(Rannacher 2018)\n\n\n\n\n\n \n\n\n\n\n\n\n(Meister 2015)\n\n\n\n\n\n \n\n\n\n\n\nPractical Textbooks\n\nThe book (Wendland 2018) is probably the best, in my opinion; it is well structured and has a good balance between theory and application. The algorithms are given in pseudocode, which makes it easy to implement them in the programming language of your choice.\nSince numerical linear algebra is a very practical subject, I think a good book should also include implementations of the actual algorithms. This is the case for (Lyche 2020), which has code in MATLAB/Octave, and for (Darve and Wootters 2021), which has implementations in Julia. The former also has a companion book containing many exercises and solutions.\n\n\n\n\n\n\n\n\n(Wendland 2018)\n\n\n\n\n\n \n\n\n\n\n\n\n(Lyche 2020)\n\n\n\n\n\n \n\n\n\n\n\n\n(Darve and Wootters 2021)\n\n\n\n\n\n \n\n\n\n\n\nAdvanced Textbooks\n\nThe books (Scott and Tůma 2023) and (Hackbusch 2016) both deal with sparse matrices, but have a very different focus. While the former covers direct methods and matrix decompositions for developing algebraic preconditioners, the latter deals with advanced iterative methods for sparse systems, such as Krylov, multigrid or domain decomposition methods. There is also (Davis 2006), which is entirely about direct methods for sparse linear systems.\nFor Eigenvalue problems, there is (Saad 2011), which focuses on Krylov methods, but also covers modern techniques such as AMLS and the Jacobi-Davidson method. The book is accompanied by MATLAB codes, and has an interesting chapter on applications in physics.\nIt is probably a good idea to look at some of these books later in this course and focus on individual chapters that are of most interest.\n\n\n\n\n\n\n\n\n(Scott and Tůma 2023)\n\n\n\n\n\n \n\n\n\n\n\n\n(Hackbusch 2016)\n\n\n\n\n\n \n\n\n\n\n\n\n(Davis 2006)\n\n\n\n\n\n \n\n\n\n\n\n\n(Saad 2011)",
    "crumbs": [
      "About me",
      "Numerical Linear Algebra",
      "Introduction"
    ]
  },
  {
    "objectID": "NumLinAlg/index.html#introduction",
    "href": "NumLinAlg/index.html#introduction",
    "title": "Introduction",
    "section": "Introduction",
    "text": "Introduction\nIn this course we will study the problem of linear systems of equations \\[\nA\\mathbf{x} = \\mathbf{b},\n\\]\nwhere \\(A \\in \\mathbb{R}^{n \\times n}\\) is an invertible matrix, \\(\\mathbf{b} \\in \\mathbb{R}^n\\) is a given vector, and \\(\\mathbf{x} \\in \\mathbb{R}^n\\) is the solution that we are looking for.\nSuch systems often come from modelling real-world problems with PDEs that are discretised with an approximation scheme, resulting in a linear system. As a result, such linear systems can be very large, making it impossible to solve them by hand. We are therefore interested in finding algorithms that can solve these linear systems efficiently. However, since we cannot represent real numbers accurately with a computer, such algorithms can only approximate the solution. Therefore, we also want to estimate the errors that arise from computing the solution numerically.\nDuring the study of numerical methods, we are interested in the following questions:\n\nTime complexity: How expensive is the algorithm, i.e. how much time does it take to compute?\nStability/Error estimation: How does perturbation of the input affect the solution?\nStructure: Can we exploit the structure of the matrix (e.g. symmetric and positive definite)?\nWhat if the system is over- or underdetermined, i.e. does not have a unique solution?",
    "crumbs": [
      "About me",
      "Numerical Linear Algebra",
      "Introduction"
    ]
  },
  {
    "objectID": "NumLinAlg/index.html#examples-for-linear-systems",
    "href": "NumLinAlg/index.html#examples-for-linear-systems",
    "title": "Introduction",
    "section": "Examples for Linear Systems",
    "text": "Examples for Linear Systems\nLinear equations appear almost everywhere. Here are some examples of applications where such linear systems are used.\nSee also: (Meister 2015, chap. 1), (Rannacher 2018, sec. 0.4) and (Wendland 2018, sec. 1.1)",
    "crumbs": [
      "About me",
      "Numerical Linear Algebra",
      "Introduction"
    ]
  },
  {
    "objectID": "NumLinAlg/index.html#partial-differential-equations",
    "href": "NumLinAlg/index.html#partial-differential-equations",
    "title": "Introduction",
    "section": "1. Partial Differential Equations",
    "text": "1. Partial Differential Equations\nThe Poisson equation is one of the simplest differential equations. It describes the electric potential in a capacitor with a given charge density.\n\\[\n\\begin{aligned}\n- \\Delta u &= f, && \\text{in $\\Omega$}, \\\\\nu &= 0, && \\text{on $\\partial\\Omega$}\n\\end{aligned}\n\\]\n. . .\nHere, \\(\\Omega := [a, b]^2 \\subseteq \\mathbb{R}^2\\) is the domain of the problem, and \\(u  = 0\\) is the (Dirichlet) boundary condition.\n. . .\nTo solve this equation using the finite difference method, we must first discretise the domain. A simple approach would be to use a regular grid as shown in the figure below.\n\n\nCode\n#\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nx = np.linspace(0, 1, num=11)\ny = np.linspace(0, 1, num=11)\nX, Y = np.meshgrid(x, y)\n\n# Plot the FDM mesh\nplt.plot(X, Y, color=\"lightgray\")\nplt.plot(X.T, Y.T, color=\"lightgray\")\n\n# Annotations\nplt.text(0.41, 0.51, \"$u_{i-1,j}$\")\nplt.text(0.51, 0.51, \"$u_{i,j}$\")\nplt.text(0.61, 0.51, \"$u_{i+1,j}$\")\nplt.text(0.51, 0.41, \"$u_{i,j-1}$\")\nplt.text(0.51, 0.61, \"$u_{i,j+1}$\")\n\n# Plot stencil\nplt.plot([0.4, 0.5, 0.6, 0.5, 0.5], [0.5, 0.5, 0.5, 0.4, 0.6], \".b\")\n\n# Remove axes and spines\nax = plt.gca()\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\nax.spines['bottom'].set_visible(False)\nax.spines['left'].set_visible(False)\n\nax.get_xaxis().set_ticks([])\nax.get_yaxis().set_ticks([])\n\n\n\n\n\nRegular grid for the Poisson equation\n\n\n\n\n. . .\nThat way, we can approximate the derivatices via \\[\n\\begin{aligned}\n\\frac{\\partial^2 u}{\\partial  x^2} (x_i, y_i)\n&\\approx\n\\frac{1}{h}\n\\left(\n  \\frac{u_{i+1, j} - u_{i,j}}{h} - \\frac{u_{i,j} - u_{i-1, j}}{h}\n  \\right) \\\\\n&= \\frac{1}{h^2} \\bigl( u_{i+1, j} - 2 u_{ij} + u_{i-1,j} \\bigr)\n\\end{aligned}\n\\]\n. . .\nand for the Laplacian we obtain: \\[\n- \\Delta u \\approx \\frac{1}{h^2}\n\\bigl(\n  4 u_{i,j} - u_{i+1,j} - u_{i-1, j} - u_{i,j+1} - u_{i,j-1}\n  \\bigr)\n\\]\n. . .\nNow we regroup \\(u\\) row-wise into a single vector:\n\\[\n\\begin{aligned}\nU_1 &:= u_{1,1},\n& U_2 &:= u_{1,2},\n&\\dotsc&\n& U_N &:= u_{1,N}, \\\\\nU_{N+1} &:= u_{2, 1},\n& U_{N+2} &:= u_{2,2},\n&\\dotsc&\n& U_{N^2} &:= u_{N, N}\n\\end{aligned}\n\\]\n. . .\nThis leads to the linear system\n\\[\nA =\n\\begin{pmatrix}\nB & -I \\\\\n-I & \\ddots & \\ddots \\\\\n  & \\ddots & \\ddots & -I \\\\\n  & & -I & B\n\\end{pmatrix}\n\\in \\mathbb{R}^{N^2 \\times N^2}\n\\]\nwhere\n\\[\nB =\n\\begin{pmatrix}\n4 & -1 \\\\\n-1 &  \\ddots & \\ddots \\\\\n&\\ddots &\\ddots & -1 \\\\\n&  & -1 & 4\n\\end{pmatrix}\n\\in \\mathbb{R}^{N \\times N}\n%\n\\quad \\text{and}  \\quad\n%\nI =\n\\begin{pmatrix}\n1 \\\\\n& \\ddots \\\\\n& & \\ddots \\\\\n& & & 1\n\\end{pmatrix}\n\\]\n. . .\nThis linear system is symmetric, positive definite and sparse.",
    "crumbs": [
      "About me",
      "Numerical Linear Algebra",
      "Introduction"
    ]
  },
  {
    "objectID": "NumLinAlg/index.html#linear-regression",
    "href": "NumLinAlg/index.html#linear-regression",
    "title": "Introduction",
    "section": "Linear Regression",
    "text": "Linear Regression\nA classic problem in astronomy is the method of least squares, used by Carl Friedrich Gauss to predict the position of the newly discovered asteroid Ceres.\n. . .\n\n\nCode\n# \nimport numpy as np\nimport matplotlib.pyplot as plt\n\nN = 31\nsigma = 0.1\n\n# Generate synthetic data\nrng = np.random.default_rng(2025)\neps = sigma * rng.standard_normal((N,))\nx = np.linspace(0, 2*np.pi, num=N)\ny = np.sin(x) + eps\n\n# Compute Polynomial regression (order 3)\np = np.polyfit(x, y, 3)\n\n# Plot data, polyfit and confidence interval\nxx = np.linspace(0, 2*np.pi, num=100)\nsolution = np.sin(xx)\nreg_fit = np.polyval(p, xx)\n\nplt.plot(x, y, \".r\", label=\"data\")\nplt.plot(xx, reg_fit, \"k-\", label=\"polynomial regression\")\nplt.fill_between(xx, solution - 2*sigma, solution + 2*sigma, color=\"red\", alpha=0.2)\n\nplt.legend()\nplt.show()\n\n\n\n\n\nPolynomial Regression yields in a linear system of equations\n\n\n\n\n. . .\nGiven \\(N\\) measurements \\((x_n, y_n)\\), \\(1 \\leq n \\leq N\\), the goal is to find a function\n\\[\nu(x) = \\sum_{k=1}^N c_k x^k\n\\]\n. . .\nsuch that the mean square error\n\\[\nE := \\left( \\sum_{n=1}^N \\lvert u(x_n) - y_n \\rvert^2 \\right)^2\n\\]\nbecomes minimal.\n. . .\nThis minimum can be obtained by solving the normal equation\n\\[\nA^\\top A \\mathbf{c} = A^\\top \\mathbf{y}.\n\\]\n. . .\nFor the special case of interpolation, this matrix becomes the Vandermonde matrix:\n\\[\n\\begin{bmatrix}\n1 & x_1 & x_1^2 & \\dots & x_1^n \\\\\n1 & x_2 & x_2^2 & \\dots & x_2^n \\\\\n1 & x_3 & x_3^2 & \\dots & x_3^n \\\\\n\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n1 & x_n &  x_n^2 & \\dots & x_n^n\n\\end{bmatrix}\n\\]\n. . .\nThis is a full matrix, meaning each entry is non-zero.",
    "crumbs": [
      "About me",
      "Numerical Linear Algebra",
      "Introduction"
    ]
  },
  {
    "objectID": "NumLinAlg/index.html#convex-optimization",
    "href": "NumLinAlg/index.html#convex-optimization",
    "title": "Introduction",
    "section": "Convex Optimization",
    "text": "Convex Optimization\nThe example above can be generalised to more general optimisation problems.\nLet’s say we are given a non-linear objective function \\(f\\) to minimise.\n\\[\nf(x) \\overset{\\text{!}}{=} \\min.\n\\]\n. . .\n\n\n\n\nnonlinear optimization\nsource: arXiv:1805.04829\n\n\n\n. . .\nSince \\(f\\) is minimal in \\(x\\) implies \\(f'(x) = 0\\), finding the minimum of a convex function is equivalent to finding the roots of it’s derivative, so we can use the Newton-Raphson method:\n. . .\n\\[\nx_{n+1} = x_n - \\alpha \\frac{f'(x_n)}{f''(x_n)}\n\\]\nwhere \\(\\alpha\\) is the step size (also called learning rate).\n. . .\nBut what if we are dealing with a multi-dimensional optimisation problem?\nThen the second derivative of \\(f\\) becomes the Hessian matrix, and the iteration formula is:\n. . .\n\\[\n\\begin{aligned}\nH_f \\Delta \\mathbf{x} = - \\nabla f(\\mathbf{x}_n) \\\\\n\\mathbf{x}_{n+1} = \\mathbf{x}_n + \\alpha \\Delta \\mathbf{x}\n\\end{aligned}\n\\]\n. . .\nThis means that with the Newton-Raphson method we have to solve a linear system for each step.",
    "crumbs": [
      "About me",
      "Numerical Linear Algebra",
      "Introduction"
    ]
  },
  {
    "objectID": "NumLinAlg/index.html#references",
    "href": "NumLinAlg/index.html#references",
    "title": "Introduction",
    "section": "References",
    "text": "References\n\n\nDarve, Eric, and Mary Wootters. 2021. Numerical Linear Algebra with Julia. Philadelphia: Society for Industrial; Applied Mathematics.\n\n\nDavis, Timothy A. 2006. Direct Methods for Sparse Linear Systems. SIAM.\n\n\nGolub, Gene H., and Charles F. Van Loan. 2013. Matrix Computations. 4th ed. Baltimore, MD: The Johns Hopkins University Press.\n\n\nHackbusch, Wolfgang. 2016. Iterative Solution of Large Sparse Systems of Equations. 2nd ed. Springer.\n\n\nLyche, Tom. 2020. Numerical Linear Algebra and Matrix Factorizations. Cham, Switzerland: Springer.\n\n\nMeister, Andreas. 2015. Numerik linearer Gleichungssysteme. 5th ed. Springer Spektrum.\n\n\nRannacher, Rolf. 2018. Numerical Linear Algebra. Heidelberg University Publ. https://doi.org/10.17885/heiup.407.\n\n\nSaad, Yousef. 2011. Numerical Methods for Large Eigenvalue Problems. 2nd ed. SIAM.\n\n\nScott, Jennifer, and Miroslav Tůma. 2023. Algorithms for Sparse Linear Systems. Cham, Switzerland: Birkhäuser. https://doi.org/10.1007/978-3-031-25820-6.\n\n\nWendland, Holger. 2018. Numerical Linear Algebra: An Introduction. Cambridge University Press.",
    "crumbs": [
      "About me",
      "Numerical Linear Algebra",
      "Introduction"
    ]
  },
  {
    "objectID": "NumLinAlg/index-slides.html#why-learn-numerical-linear-algebra",
    "href": "NumLinAlg/index-slides.html#why-learn-numerical-linear-algebra",
    "title": "Introduction",
    "section": "Why learn Numerical Linear Algebra?",
    "text": "Why learn Numerical Linear Algebra?\n\nNumerical linear algebra is the foundation of modern scientific computing. It deals with the numerical approximation of problems such as linear systems and eigenvalue problems. Many techniques for solving differential equations, such as the finite element method (FEM) or the finite difference method, lead to a system of linear equations; As such, numerical linear algebra has many applications: from image and signal processing to computational physics, data science and more.\n\n\nNumerical linear algebra is the foundation of scientific computing\nit deals with numerical approximation of linear systems and Eigenvalue problems\ntechniques for solving PDEs often lead to a system of linear equations\nmany applications: signal processing, computational physics, data science, …"
  },
  {
    "objectID": "NumLinAlg/index-slides.html#about-this-course",
    "href": "NumLinAlg/index-slides.html#about-this-course",
    "title": "Introduction",
    "section": "About this Course",
    "text": "About this Course\nTarget Audience:\n\nStudents in math/physics/engineering\nEngineers who want to gain a deeper understanding of numerical algorithms\nanyone who is interested in scientific computing\n\n\nPrerequisites:\n\nsolid knowledge of Linear Algebra\nbasic programming skills (Julia/Python/MATLAB)\n\n\nTarget Audience This course is primarily aimed at undergraduate students of mathematics, physics and engineering. However, it is also suitable for engineers who use these algorithms (linear solvers, multigrid methods) in commercial software and want to gain a deeper understanding of how they work.\nPrerequisites This is not a linear algebra course, so a solid understanding of linear algebra is required. For the implementation of the numerical algorithms, it is also useful to have some programming skills in either MATLAB, Python or Julia. However, there will be a short introduction to Julia programming at the beginning, so basic programming skills are sufficient."
  },
  {
    "objectID": "NumLinAlg/index-slides.html#introduction",
    "href": "NumLinAlg/index-slides.html#introduction",
    "title": "Introduction",
    "section": "Introduction",
    "text": "Introduction\nIn this course we will study the problem of linear systems of equations \\[\nA\\mathbf{x} = \\mathbf{b},\n\\]\nwhere \\(A \\in \\mathbb{R}^{n \\times n}\\) is an invertible matrix, \\(\\mathbf{b} \\in \\mathbb{R}^n\\) is a given vector, and \\(\\mathbf{x} \\in \\mathbb{R}^n\\) is the solution that we are looking for.\nDuring the study of numerical methods, we are interested in the following questions:\n\nTime complexity: How expensive is the algorithm, i.e. how much time does it take to compute?\nStability/Error estimation: How does perturbation of the input affect the solution?\nStructure: Can we exploit the structure of the matrix (e.g. symmetric and positive definite)?\nWhat if the system is over- or underdetermined, i.e. does not have a unique solution?"
  },
  {
    "objectID": "NumLinAlg/index-slides.html#examples-for-linear-systems",
    "href": "NumLinAlg/index-slides.html#examples-for-linear-systems",
    "title": "Introduction",
    "section": "Examples for Linear Systems",
    "text": "Examples for Linear Systems\nLinear equations appear almost everywhere. Here are some examples of applications where such linear systems are used.\nSee also: (Meister 2015, chap. 1), (Rannacher 2018, sec. 0.4) and (Wendland 2018, sec. 1.1)"
  },
  {
    "objectID": "NumLinAlg/index-slides.html#partial-differential-equations",
    "href": "NumLinAlg/index-slides.html#partial-differential-equations",
    "title": "Introduction",
    "section": "1. Partial Differential Equations",
    "text": "1. Partial Differential Equations\nThe Poisson equation is one of the simplest differential equations. It describes the electric potential in a capacitor with a given charge density.\n\\[\n\\begin{aligned}\n- \\Delta u &= f, && \\text{in $\\Omega$}, \\\\\nu &= 0, && \\text{on $\\partial\\Omega$}\n\\end{aligned}\n\\]\n\nHere, \\(\\Omega := [a, b]^2 \\subseteq \\mathbb{R}^2\\) is the domain of the problem, and \\(u  = 0\\) is the (Dirichlet) boundary condition.\n\n\nTo solve this equation using the finite difference method, we must first discretise the domain. A simple approach would be to use a regular grid as shown in the figure below.\n\n\nCode\n#\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nx = np.linspace(0, 1, num=11)\ny = np.linspace(0, 1, num=11)\nX, Y = np.meshgrid(x, y)\n\n# Plot the FDM mesh\nplt.plot(X, Y, color=\"lightgray\")\nplt.plot(X.T, Y.T, color=\"lightgray\")\n\n# Annotations\nplt.text(0.41, 0.51, \"$u_{i-1,j}$\")\nplt.text(0.51, 0.51, \"$u_{i,j}$\")\nplt.text(0.61, 0.51, \"$u_{i+1,j}$\")\nplt.text(0.51, 0.41, \"$u_{i,j-1}$\")\nplt.text(0.51, 0.61, \"$u_{i,j+1}$\")\n\n# Plot stencil\nplt.plot([0.4, 0.5, 0.6, 0.5, 0.5], [0.5, 0.5, 0.5, 0.4, 0.6], \".b\")\n\n# Remove axes and spines\nax = plt.gca()\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\nax.spines['bottom'].set_visible(False)\nax.spines['left'].set_visible(False)\n\nax.get_xaxis().set_ticks([])\nax.get_yaxis().set_ticks([])\n\n\n\n\n\nRegular grid for the Poisson equation\n\n\n\n\n\n\nThat way, we can approximate the derivatices via \\[\n\\begin{aligned}\n\\frac{\\partial^2 u}{\\partial  x^2} (x_i, y_i)\n&\\approx\n\\frac{1}{h}\n\\left(\n  \\frac{u_{i+1, j} - u_{i,j}}{h} - \\frac{u_{i,j} - u_{i-1, j}}{h}\n  \\right) \\\\\n&= \\frac{1}{h^2} \\bigl( u_{i+1, j} - 2 u_{ij} + u_{i-1,j} \\bigr)\n\\end{aligned}\n\\]\n\n\nand for the Laplacian we obtain: \\[\n- \\Delta u \\approx \\frac{1}{h^2}\n\\bigl(\n  4 u_{i,j} - u_{i+1,j} - u_{i-1, j} - u_{i,j+1} - u_{i,j-1}\n  \\bigr)\n\\]\n\n\nNow we regroup \\(u\\) row-wise into a single vector:\n\\[\n\\begin{aligned}\nU_1 &:= u_{1,1},\n& U_2 &:= u_{1,2},\n&\\dotsc&\n& U_N &:= u_{1,N}, \\\\\nU_{N+1} &:= u_{2, 1},\n& U_{N+2} &:= u_{2,2},\n&\\dotsc&\n& U_{N^2} &:= u_{N, N}\n\\end{aligned}\n\\]\n\n\nThis leads to the linear system\n\\[\nA =\n\\begin{pmatrix}\nB & -I \\\\\n-I & \\ddots & \\ddots \\\\\n  & \\ddots & \\ddots & -I \\\\\n  & & -I & B\n\\end{pmatrix}\n\\in \\mathbb{R}^{N^2 \\times N^2}\n\\]\nwhere\n\\[\nB =\n\\begin{pmatrix}\n4 & -1 \\\\\n-1 &  \\ddots & \\ddots \\\\\n&\\ddots &\\ddots & -1 \\\\\n&  & -1 & 4\n\\end{pmatrix}\n\\in \\mathbb{R}^{N \\times N}\n%\n\\quad \\text{and}  \\quad\n%\nI =\n\\begin{pmatrix}\n1 \\\\\n& \\ddots \\\\\n& & \\ddots \\\\\n& & & 1\n\\end{pmatrix}\n\\]\n\n\nThis linear system is symmetric, positive definite and sparse."
  },
  {
    "objectID": "NumLinAlg/index-slides.html#linear-regression",
    "href": "NumLinAlg/index-slides.html#linear-regression",
    "title": "Introduction",
    "section": "Linear Regression",
    "text": "Linear Regression\nA classic problem in astronomy is the method of least squares, used by Carl Friedrich Gauss to predict the position of the newly discovered asteroid Ceres.\n\n\n\nCode\n# \nimport numpy as np\nimport matplotlib.pyplot as plt\n\nN = 31\nsigma = 0.1\n\n# Generate synthetic data\nrng = np.random.default_rng(2025)\neps = sigma * rng.standard_normal((N,))\nx = np.linspace(0, 2*np.pi, num=N)\ny = np.sin(x) + eps\n\n# Compute Polynomial regression (order 3)\np = np.polyfit(x, y, 3)\n\n# Plot data, polyfit and confidence interval\nxx = np.linspace(0, 2*np.pi, num=100)\nsolution = np.sin(xx)\nreg_fit = np.polyval(p, xx)\n\nplt.plot(x, y, \".r\", label=\"data\")\nplt.plot(xx, reg_fit, \"k-\", label=\"polynomial regression\")\nplt.fill_between(xx, solution - 2*sigma, solution + 2*sigma, color=\"red\", alpha=0.2)\n\nplt.legend()\nplt.show()\n\n\n\n\n\nPolynomial Regression yields in a linear system of equations\n\n\n\n\n\n\nGiven \\(N\\) measurements \\((x_n, y_n)\\), \\(1 \\leq n \\leq N\\), the goal is to find a function\n\\[\nu(x) = \\sum_{k=1}^N c_k x^k\n\\]\n\n\nsuch that the mean square error\n\\[\nE := \\left( \\sum_{n=1}^N \\lvert u(x_n) - y_n \\rvert^2 \\right)^2\n\\]\nbecomes minimal.\n\n\nThis minimum can be obtained by solving the normal equation\n\\[\nA^\\top A \\mathbf{c} = A^\\top \\mathbf{y}.\n\\]\n\n\nFor the special case of interpolation, this matrix becomes the Vandermonde matrix:\n\\[\n\\begin{bmatrix}\n1 & x_1 & x_1^2 & \\dots & x_1^n \\\\\n1 & x_2 & x_2^2 & \\dots & x_2^n \\\\\n1 & x_3 & x_3^2 & \\dots & x_3^n \\\\\n\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n1 & x_n &  x_n^2 & \\dots & x_n^n\n\\end{bmatrix}\n\\]\n\n\nThis is a full matrix, meaning each entry is non-zero."
  },
  {
    "objectID": "NumLinAlg/index-slides.html#convex-optimization",
    "href": "NumLinAlg/index-slides.html#convex-optimization",
    "title": "Introduction",
    "section": "Convex Optimization",
    "text": "Convex Optimization\nThe example above can be generalised to more general optimisation problems.\nLet’s say we are given a non-linear objective function \\(f\\) to minimise.\n\\[\nf(x) \\overset{\\text{!}}{=} \\min.\n\\]\n\n\n\n\n\nnonlinear optimization\nsource: arXiv:1805.04829\n\n\n\n\n\nSince \\(f\\) is minimal in \\(x\\) implies \\(f'(x) = 0\\), finding the minimum of a convex function is equivalent to finding the roots of it’s derivative, so we can use the Newton-Raphson method:\n\n\n\\[\nx_{n+1} = x_n - \\alpha \\frac{f'(x_n)}{f''(x_n)}\n\\]\nwhere \\(\\alpha\\) is the step size (also called learning rate).\n\n\nBut what if we are dealing with a multi-dimensional optimisation problem?\nThen the second derivative of \\(f\\) becomes the Hessian matrix, and the iteration formula is:\n\n\n\\[\n\\begin{aligned}\nH_f \\Delta \\mathbf{x} = - \\nabla f(\\mathbf{x}_n) \\\\\n\\mathbf{x}_{n+1} = \\mathbf{x}_n + \\alpha \\Delta \\mathbf{x}\n\\end{aligned}\n\\]\n\n\nThis means that with the Newton-Raphson method we have to solve a linear system for each step."
  },
  {
    "objectID": "NumLinAlg/index-slides.html#references",
    "href": "NumLinAlg/index-slides.html#references",
    "title": "Introduction",
    "section": "References",
    "text": "References\n\n\nDarve, Eric, and Mary Wootters. 2021. Numerical Linear Algebra with Julia. Philadelphia: Society for Industrial; Applied Mathematics.\n\n\nDavis, Timothy A. 2006. Direct Methods for Sparse Linear Systems. SIAM.\n\n\nGolub, Gene H., and Charles F. Van Loan. 2013. Matrix Computations. 4th ed. Baltimore, MD: The Johns Hopkins University Press.\n\n\nHackbusch, Wolfgang. 2016. Iterative Solution of Large Sparse Systems of Equations. 2nd ed. Springer.\n\n\nLyche, Tom. 2020. Numerical Linear Algebra and Matrix Factorizations. Cham, Switzerland: Springer.\n\n\nMeister, Andreas. 2015. Numerik linearer Gleichungssysteme. 5th ed. Springer Spektrum.\n\n\nRannacher, Rolf. 2018. Numerical Linear Algebra. Heidelberg University Publ. https://doi.org/10.17885/heiup.407.\n\n\nSaad, Yousef. 2011. Numerical Methods for Large Eigenvalue Problems. 2nd ed. SIAM.\n\n\nScott, Jennifer, and Miroslav Tůma. 2023. Algorithms for Sparse Linear Systems. Cham, Switzerland: Birkhäuser. https://doi.org/10.1007/978-3-031-25820-6.\n\n\nWendland, Holger. 2018. Numerical Linear Algebra: An Introduction. Cambridge University Press."
  },
  {
    "objectID": "NumLinAlg/basics_of_linalg.html",
    "href": "NumLinAlg/basics_of_linalg.html",
    "title": "Basics of Linear Algebra",
    "section": "",
    "text": "Concepts such as distance, orthogonality and convergence are based on a scalar product and its induced metrics. As such, we’ll introduce the definitions of these concepts.\n. . .\n\n\n\n\n\n\nNoteDefinition 1: Norm\n\n\n\nLet \\(V\\) be a real (or complex) vector space. A mapping \\[\n\\lVert \\,\\cdot\\,\\rVert : V \\to [0, \\infty)\n\\]\nwith the properties\n\n\\(\\lVert \\mathbf{x} \\rVert = 0 \\iff \\mathbf{x} = 0\\) (definiteness)\n\\(\\lVert \\alpha \\mathbf{x} \\rVert = \\lvert \\alpha \\rvert \\, \\cdot \\, \\lVert \\mathbf{x} \\rVert\\) (homogeneity)\n\\(\\lVert \\mathbf{x} + \\mathbf{y} \\rVert \\leq \\lVert \\mathbf{x} \\rVert + \\lVert \\mathbf{y} \\rVert\\) (triangle inequality)\n\nis called a norm on \\(V\\).\n\n\n. . .\nExamples for norms on \\(\\mathbb{R}^n\\) are the 1-norm, the maximum-norm and the Euclidean norm.\n\\[\n\\begin{aligned}\n\\lVert \\mathbf{x} \\rVert_1 &= \\sum_{i=1}^n \\lvert x_i \\rvert,\n&\n\\lVert \\mathbf{x} \\rVert_2\n&=\n\\left( \\sum_{i=1}^n x_i^2 \\right)^{1/2} \\\\\n\\lVert \\mathbf{x} \\rVert_\\infty &= \\max_{1 \\leq i \\leq n} \\lvert x_i \\rvert\n&\n\\lVert \\mathbf{x} \\rVert_p\n&=\n\\left( \\sum_{i=1}^n \\lvert x_i \\rvert^p \\right)^{1/p}\n\\end{aligned}\n\\]\n. . .\nGraphing the p-Norm Unit Ball in 3 Dimensions is not trivial; For more info, read this post by Kayden Mimmack, 2019.\n\n\n\n\n\n\n\nNoteDefinition 2: Convergence\n\n\n\nA sequence \\((\\mathbf{x}_n)_{n \\in \\mathbb{N}} \\subseteq V\\) is called a Cauchy-sequence, if for all \\(\\varepsilon \\gt 0\\) there exists an \\(N \\in \\mathbb{N}\\), such that \\[\n\\lVert \\mathbf{x}_n - \\mathbf{x}_m \\rVert \\lt \\varepsilon \\qquad \\forall n,m\\gt N.\n\\]\nIt is called convergent to the limit \\(\\mathbf{x} \\in V\\) if:\n\\[\n\\lVert \\mathbf{x}_n - \\mathbf{x} \\rVert \\to 0\n\\]\n\n\nA space in which all Cauchy sequences converge is called complete.\n. . .\nA completely normed space is called a Banach space.\n\n\n\n\n\n\n\nNoteEquivalence of Norms\n\n\n\nTwo norms \\(\\lVert \\cdot \\rVert_a\\) and \\(\\lVert \\cdot \\rVert_b\\) are called equivalent, if there exist constants \\(\\alpha, \\beta \\gt 0\\) such that \\[\n\\alpha \\lVert \\mathbf{x} \\rVert_a \\leq \\lVert \\mathbf{x} \\rVert_b \\leq \\beta \\lVert \\mathbf{x} \\rVert_a\n\\qquad \\forall \\mathbf{x} \\in V.\n\\]\n\n\nIf two norms are equivalent, then any sequence that is convergent with respect to \\(\\lVert \\cdot \\rVert_a\\) is also convergent with respect to \\(\\lVert \\cdot \\rVert_b\\).\n. . .\n\n\n\n\n\n\nImportantTheorem\n\n\n\nIn a finite-dimensional vector space, all norms are equivalent.\n\n\n\nProof. See handwritten notes 1\n\n. . .\n\n\n\n\n\n\nImportantTheorem\n\n\n\nAny finite dimensional normed space is a Banach space.\n\n\n\nProof. See handwritten notes 2.",
    "crumbs": [
      "About me",
      "Numerical Linear Algebra",
      "Basics of Linear Algebra"
    ]
  },
  {
    "objectID": "NumLinAlg/basics_of_linalg.html#normed-spaces",
    "href": "NumLinAlg/basics_of_linalg.html#normed-spaces",
    "title": "Basics of Linear Algebra",
    "section": "",
    "text": "Concepts such as distance, orthogonality and convergence are based on a scalar product and its induced metrics. As such, we’ll introduce the definitions of these concepts.\n. . .\n\n\n\n\n\n\nNoteDefinition 1: Norm\n\n\n\nLet \\(V\\) be a real (or complex) vector space. A mapping \\[\n\\lVert \\,\\cdot\\,\\rVert : V \\to [0, \\infty)\n\\]\nwith the properties\n\n\\(\\lVert \\mathbf{x} \\rVert = 0 \\iff \\mathbf{x} = 0\\) (definiteness)\n\\(\\lVert \\alpha \\mathbf{x} \\rVert = \\lvert \\alpha \\rvert \\, \\cdot \\, \\lVert \\mathbf{x} \\rVert\\) (homogeneity)\n\\(\\lVert \\mathbf{x} + \\mathbf{y} \\rVert \\leq \\lVert \\mathbf{x} \\rVert + \\lVert \\mathbf{y} \\rVert\\) (triangle inequality)\n\nis called a norm on \\(V\\).\n\n\n. . .\nExamples for norms on \\(\\mathbb{R}^n\\) are the 1-norm, the maximum-norm and the Euclidean norm.\n\\[\n\\begin{aligned}\n\\lVert \\mathbf{x} \\rVert_1 &= \\sum_{i=1}^n \\lvert x_i \\rvert,\n&\n\\lVert \\mathbf{x} \\rVert_2\n&=\n\\left( \\sum_{i=1}^n x_i^2 \\right)^{1/2} \\\\\n\\lVert \\mathbf{x} \\rVert_\\infty &= \\max_{1 \\leq i \\leq n} \\lvert x_i \\rvert\n&\n\\lVert \\mathbf{x} \\rVert_p\n&=\n\\left( \\sum_{i=1}^n \\lvert x_i \\rvert^p \\right)^{1/p}\n\\end{aligned}\n\\]\n. . .\nGraphing the p-Norm Unit Ball in 3 Dimensions is not trivial; For more info, read this post by Kayden Mimmack, 2019.\n\n\n\n\n\n\n\nNoteDefinition 2: Convergence\n\n\n\nA sequence \\((\\mathbf{x}_n)_{n \\in \\mathbb{N}} \\subseteq V\\) is called a Cauchy-sequence, if for all \\(\\varepsilon \\gt 0\\) there exists an \\(N \\in \\mathbb{N}\\), such that \\[\n\\lVert \\mathbf{x}_n - \\mathbf{x}_m \\rVert \\lt \\varepsilon \\qquad \\forall n,m\\gt N.\n\\]\nIt is called convergent to the limit \\(\\mathbf{x} \\in V\\) if:\n\\[\n\\lVert \\mathbf{x}_n - \\mathbf{x} \\rVert \\to 0\n\\]\n\n\nA space in which all Cauchy sequences converge is called complete.\n. . .\nA completely normed space is called a Banach space.\n\n\n\n\n\n\n\nNoteEquivalence of Norms\n\n\n\nTwo norms \\(\\lVert \\cdot \\rVert_a\\) and \\(\\lVert \\cdot \\rVert_b\\) are called equivalent, if there exist constants \\(\\alpha, \\beta \\gt 0\\) such that \\[\n\\alpha \\lVert \\mathbf{x} \\rVert_a \\leq \\lVert \\mathbf{x} \\rVert_b \\leq \\beta \\lVert \\mathbf{x} \\rVert_a\n\\qquad \\forall \\mathbf{x} \\in V.\n\\]\n\n\nIf two norms are equivalent, then any sequence that is convergent with respect to \\(\\lVert \\cdot \\rVert_a\\) is also convergent with respect to \\(\\lVert \\cdot \\rVert_b\\).\n. . .\n\n\n\n\n\n\nImportantTheorem\n\n\n\nIn a finite-dimensional vector space, all norms are equivalent.\n\n\n\nProof. See handwritten notes 1\n\n. . .\n\n\n\n\n\n\nImportantTheorem\n\n\n\nAny finite dimensional normed space is a Banach space.\n\n\n\nProof. See handwritten notes 2.",
    "crumbs": [
      "About me",
      "Numerical Linear Algebra",
      "Basics of Linear Algebra"
    ]
  },
  {
    "objectID": "NumLinAlg/basics_of_linalg.html#hilbert-spaces",
    "href": "NumLinAlg/basics_of_linalg.html#hilbert-spaces",
    "title": "Basics of Linear Algebra",
    "section": "Hilbert spaces",
    "text": "Hilbert spaces\n\n\n\n\n\n\nNoteDefinition 3: Hilbert-space\n\n\n\nA mapping \\(\\langle \\cdot, \\cdot \\rangle : V \\times V \\to \\mathbb{R}\\) is called scalar product, if it has the following properties:\n\nsymmetry: \\(\\langle \\mathbf{x}, \\mathbf{y} \\rangle = \\langle \\mathbf{y}, \\mathbf{x} \\rangle\\)\npositive definiteness: \\(\\langle \\mathbf{x}, \\mathbf{x} \\rangle \\gt 0\\) for all \\(\\mathbf{x} \\in V\\)\nbilinear: \\(\\langle \\alpha \\mathbf{x} + \\beta \\mathbf{y}, \\mathbf{z} \\rangle = \\alpha \\langle \\mathbf{x}, \\mathbf{z} \\rangle + \\beta \\langle \\mathbf{y}, \\mathbf{z} \\rangle\\)\n\nA vector space equipped with a scalar product is called a pre-Hilbert space.\n\n\n. . .\nFor a scalar product there holds the Cauchy-Schwarz inequality:\n\\[\n\\lvert \\langle \\mathbf{x}, \\mathbf{y} \\rangle \\lvert \\leq \\lVert \\mathbf{x} \\rVert \\, \\lVert \\mathbf{y} \\rVert\n\\]\n. . .\nEvery pre-Hilbert space is a normed space with canonical norm \\(\\lVert \\mathbf{x} \\rVert := \\sqrt{ \\langle \\mathbf{x}, \\mathbf{x} \\rangle}\\). If the vector space is complete with respect to this norm, it is called a Hilbert space.\n. . .\nThe dot product can be used to measure the angle between two vector in \\(\\mathbb{R}^n\\):\n\\[\n\\lvert \\langle \\mathbf{x}, \\mathbf{y} \\rangle \\rvert =\n\\lVert \\mathbf{x} \\rVert \\, \\lVert \\mathbf{y} \\rVert \\cos(\\alpha)\n\\]\n\n\n\nDot product in 2D\nThis figure was created with Geogebra and is hereby released to the public domain (CC0 1.0)\n\n\n. . .\nTwo vectors are orthogonal, in symbols \\(\\mathbf{x} \\perp \\mathbf{y}\\), if their dot product is 0.\n. . .\nThe orthogonal projection \\(P\\mathbf{x}\\) of a vector \\(\\mathbf{x}\\) to a subspace \\(M \\subseteq V\\) is determined by \\[\n\\lVert \\mathbf{x} - P \\mathbf{x} \\rVert = \\min_{y \\in M} \\lVert \\mathbf{x} - \\mathbf{y} \\rVert.\n\\]\n\n\n\nOrthogonal projection\n\n\nThis is often called best approximation property and is equivalent to the relation \\[\n\\langle \\mathbf{x} - P \\mathbf{x}, \\mathbf{y} \\rangle = 0 \\quad \\forall \\mathbf{y} \\in M.\n\\]\n\nProof. See [1], Proposition 1.17 (p. 23).\n\n\nAnother useful inequality is the Hölder inequality, a generalization of the Cauchy-Schwarz inequality:\n\n\n\n\n\n\nImportantHölder inequality\n\n\n\nFor any vectors \\(\\mathbf{x}, \\mathbf{y}\\) and positive numbers \\(p, q\\) with \\(1/p + 1/q = 1\\), it is \\[\n\\lvert \\langle \\mathbf{x}, \\mathbf{y} \\rangle \\rvert \\leq \\lVert \\mathbf{x} \\rVert^p + \\lVert \\mathbf{y} \\rVert^q\n\\]\n\n\n\nLet \\(\\{ \\mathbf{q}_1, \\dotsc, \\mathbf{q}_n \\}\\) be a Orthonormalbasis (ONB) of \\(V\\). Then each vector \\(\\mathbf{x} \\in V\\) possesses a representation of the form \\[\n\\mathbf{x} = \\sum_{i=1}^n \\langle \\mathbf{x}, \\mathbf{q}_i \\rangle \\, \\mathbf{q}_i\n\\]\n. . .\nand there holds the Parseval identity:\n\\[\n\\lVert \\mathbf{x} \\rVert_2^2 = \\sum_{i=1}^n \\lvert \\langle \\mathbf{x}, \\mathbf{q}_i \\rangle \\rvert^2\n\\]\n. . .\nThe Gram-Schmidt-algorithm can be used to construct an ONB from an arbitrary basis:\n. . .\n\n\n\n\n\n\nImportantTheorem: Gram-Schmidt-algorithm\n\n\n\nLet \\(\\{\\mathbf{v}_1, \\dotsc, \\mathbf{v}_n\\}\\) be an arbitrary basis of \\(V\\). Then the following algorithm results in a ONB \\(\\{\\mathbf{u}_1, \\dotsc, \\mathbf{u}_n\\}\\):\n\\[\n\\begin{aligned}\n%\\mathbf{u}_1 &= \\frac{\\mathbf{v}_1}{\\lVert \\mathbf{v}_1 \\rVert}, \\\\\n\\widetilde{\\mathbf{u}}_k &= \\mathbf{v}_k - \\sum_{j=1}^{k-1} \\frac{\\langle \\mathbf{v}_k, \\mathbf{u}_j \\rangle}{ \\lVert \\mathbf{u}_j \\rVert^2} \\mathbf{u}_j \\\\\n\\mathbf{u}_k &:= \\frac{\\widetilde{\\mathbf{u}}_k}{\\lVert \\widetilde{\\mathbf{u}}_k \\rVert}\n\\end{aligned}\n\\]",
    "crumbs": [
      "About me",
      "Numerical Linear Algebra",
      "Basics of Linear Algebra"
    ]
  },
  {
    "objectID": "NumLinAlg/basics_of_linalg.html#linear-operators-and-matrices",
    "href": "NumLinAlg/basics_of_linalg.html#linear-operators-and-matrices",
    "title": "Basics of Linear Algebra",
    "section": "Linear Operators and Matrices",
    "text": "Linear Operators and Matrices\nA mappinng \\(\\varphi: \\mathbb{R}^n \\to \\mathbb{R}^m\\) is called linear, if: \\[\n\\varphi(a\\mathbf{x} + b \\mathbf{y})  = a \\varphi(\\mathbf{x}) + b \\varphi(\\mathbf{y})\n\\]\nWe can describe a linear mapping with a matrix \\(A\\) and the usual rules for matrix-vector multiplication. \\[\nA =\n\\begin{pmatrix}\na_{11} & \\dots & a_{1n} \\\\\n\\vdots  & & \\vdots \\\\\na_{m1} & \\dots & a_{mn}\n\\end{pmatrix}\n, \\qquad\n(A\\mathbf{x})_i\n=\n\\sum_{j=1}^n A_{ij} x_j\n\\]\n. . .\nA linear operator \\(A: X \\to Y\\) is called bounded, if there is a constant \\(C \\gt 0\\) such that \\[\n\\lVert A \\mathbf{x} \\rVert_Y \\leq C \\lVert  \\mathbf{x} \\rVert_X .\n\\]\nFor any bounded operator we can define the operator norm via \\[\n\\lVert A \\rVert := \\sup_{\\lVert \\mathbf{x} \\rVert = 1} \\lVert A \\mathbf{x} \\rVert.\n\\] The operator norm is the smalles possible bound and we have \\(\\lVert A \\mathbf{x} \\rVert \\leq \\lVert A \\rVert \\, \\lVert \\mathbf{x} \\rVert\\) for any \\(\\mathbf{x}\\).\n\nFor a given a matrix \\(A\\) we can define the transposed matrix \\(A^\\intercal\\): \\[\nA^\\intercal\n:=\n\\begin{pmatrix}\na_{11} & \\dots & a_{m1} \\\\\n\\vdots  & & \\vdots \\\\\na_{1n} & \\dots & a_{mn}\n\\end{pmatrix},\n\\]\nA matrix \\(A \\in \\mathbb{R}^{n\\times n}\\) is called\n\nsymmetric, if \\(A^\\intercal = A\\), and\northogonal, if \\(A^\\intercal A = I\\),\npositive definite, if \\(\\mathbf{x}^\\intercal A \\mathbf{x} \\gt 0 \\; \\forall \\mathbf{x} \\in V\\).\n\nOrthogonal matrices \\(Q\\) are the mapping matrices of isomatric transformations, i.e. they do not change the norm of a vector under transformation:\n\\[\n\\lVert Q \\mathbf{x} \\rVert = \\lVert \\mathbf{x} \\rVert\n\\]\nThis can be seen via: \\[\n\\lVert Q\\mathbf{x} \\rVert^2 = \\langle Q\\mathbf{x}, Q\\mathbf{x} \\rangle = (Q \\mathbf{x})^\\intercal Q\\mathbf{x} = \\mathbf{x}^\\intercal Q^\\intercal Q \\mathbf{x} = \\lVert \\mathbf{x} \\rVert^2\n\\]\nWe can think of orthogonal transformations as rotations and reflections. For example, \\[\nQ_\\alpha =\n\\begin{pmatrix}\n1 & 0 & 0 & 0 & 0 \\\\\n0 & \\cos(\\alpha) & 0 & -\\sin(\\alpha) & 0 \\\\\n0 & 0 & 1 & 0 & 0 \\\\\n0 & \\sin(\\alpha) & 0 & -\\cos(\\alpha) & 0 \\\\\n0 & 0 & 0 & 0 & 1\n\\end{pmatrix}\n\\] is a rotation matrix in the \\(\\mathbf{x}_i\\,\\mathbf{x}_j\\) plane and angle \\(\\alpha\\).\n\nAs already mentioned, a matrix norm can be induced from a given vector norm; in this sense we define \\[\n\\begin{align*}\n\\lVert A \\rVert_1 &:= \\max_{j=1, \\dotsc, n} \\sum_{i=1}^n \\lvert a_{ij} \\rvert, \\\\\n\\lVert A \\rVert_\\infty &:= \\max_{i=1,\\dotsc,n} \\sum_{j=1}^n \\lvert a_{ij} \\rvert\n\\end{align*}\n\\]\nComputing the 2-norm of a matrix is not that simple. As it turns out, it is related to the spectral radius of the matrix: \\(\\lVert A \\rVert_2 = \\rho(A)\\). However, we can get an upper bound on the 2-norm by using the Frobenius norm.\n\\[\n\\lVert A \\rVert_2 \\leq \\lVert A \\rVert_F = \\sum_{i,j=1}^n \\lvert a_{ij} \\rvert^2\n\\]\n\n\n\n\n\n\nTipExercise\n\n\n\nShow that the matrix norms above are indeed induced by their given vector norms; i.e., show that \\[\n\\sup_{\\lVert \\mathbf{x} \\rVert_\\infty = 1} \\lVert A \\mathbf{x} \\rVert_\\infty\n=\n\\max_{i=1,\\dotsc,n} \\sum_{j=1}^n \\lvert a_{ij} \\rvert\n\\]",
    "crumbs": [
      "About me",
      "Numerical Linear Algebra",
      "Basics of Linear Algebra"
    ]
  },
  {
    "objectID": "NumLinAlg/basics_of_linalg.html#matrix-decompositions",
    "href": "NumLinAlg/basics_of_linalg.html#matrix-decompositions",
    "title": "Basics of Linear Algebra",
    "section": "Matrix decompositions",
    "text": "Matrix decompositions\n\n\n\n\n\n\nNoteTheorem: Schur decomposition\n\n\n\nFor every matrix \\(A \\in \\mathbb{R}^{n\\times n}\\) with real Eigenvalues, there exists an orthogonal matrix \\(U\\) such that \\[\nU^\\intercal A U\n\\] is an upper triangle matrix.\n\n\n. . .\n\nProof. The proof is a bit technical. I refer to the standard literature on linear algebra:\n\nSchur decomposition by Marco Tobago (2021), Lectures on matrix algebra.\nLinear Algebra Done Right by Sheldon Axler, Springer (2025), Theorem 6.38 (p. 204)\n\n\n\nAs a direct result, we obtain the spectral decomposition for symmetric matrices:\n\n\n\n\n\n\nNoteTheorem: Spectral decomposition\n\n\n\nIf \\(A \\in \\mathbb{R}^{n \\times n}\\) is symmetric, then there is an orthogonal matrix \\(U\\) such that \\[\nU^\\intercal A U = D\n\\] is a diagonal matrix with the Eigenvalues of \\(A\\) as diagonal entries.\n\n\n. . .\n\nProof. (draw on slides)\n\n\nNote that \\(A^\\mathrm{T} A\\) is symmetric for any matrix A. This means that by applying the previous theorem to \\(A^\\intercal A\\) we can get a generalisation for non-symmetric matrices:\n. . .\n\n\n\n\n\n\nNoteTheorem: The Singular Value Decomposition (SVD)\n\n\n\nLet \\(A \\in \\mathbb{K}^{n \\times n}\\) be arbitrary real or complex. Then, there exist unitary matrices \\(V \\in \\mathbb{K}^{n \\times n}\\) and \\(U \\in \\mathbb{K}^{m \\times m}\\) such that \\[\nA = U \\Sigma V^\\ast, \\quad \\Sigma = \\mathrm{diag}(\\sigma_1, \\dotsc, \\sigma_p) \\in \\mathbb{R}^{m \\times n}, \\quad p = \\min(m, n)\n\\] where \\(\\sigma_1 \\geq \\sigma_2 \\geq \\dotso \\sigma_p \\geq 0\\).\nDepending on whether \\(m \\leq n\\) or \\(m \\geq n\\) the matrix \\(\\Sigma\\) has the form \\[\n\\left(\n\\begin{array}{ccc|c}\n\\sigma_1 \\\\\n&\\ddots & & 0\\\\\n& & \\sigma_m\n\\end{array}\n\\right)\n\\qquad\n\\text{or}\n\\quad\n\\left(\n\\begin{array}{ccc}\n\\sigma_1 \\\\\n&\\ddots \\\\\n& & \\sigma_m \\\\\n\\hline\n& 0\n\\end{array}\n\\right)\n\\]\n\n\n. . .\n\nProof. See Linear Algebra Done Right by Sheldon Axler, Springer (2025), Section 7.E.\n\n. . .\nFrom a visual point of view, the SVD can be thought of as a decomposition into a shear and two rotations.\n\n\n\nSingular Value Decomposition\nAuthor: Georg-Johann source: wikimedia.org license: CC BY-SA 3.0\n\n\n. . .\nThe Singular value decomposition has applications in machine learning, where it is often used for dimensionality reduction.\n. . .\nSee also: A Singularly Valuable Decomposition: The SVD of a Matrix",
    "crumbs": [
      "About me",
      "Numerical Linear Algebra",
      "Basics of Linear Algebra"
    ]
  },
  {
    "objectID": "NumLinAlg/basics_of_linalg.html#banach-fixed-point-theorem",
    "href": "NumLinAlg/basics_of_linalg.html#banach-fixed-point-theorem",
    "title": "Basics of Linear Algebra",
    "section": "Banach fixed-point theorem",
    "text": "Banach fixed-point theorem\n\n\n\n\n\n\nNoteDefinition: Contraction\n\n\n\nAn operator \\(A: V \\to V\\) is called a contraction, if there exists a number \\(0 \\le q \\leq 1\\) such that \\[\n\\lVert F(\\mathbf{x}) - F(\\mathbf{y}) \\rVert \\leq q \\lVert \\mathbf{x} - \\mathbf{y} \\rVert.\n\\]",
    "crumbs": [
      "About me",
      "Numerical Linear Algebra",
      "Basics of Linear Algebra"
    ]
  },
  {
    "objectID": "NumLinAlg/basics_of_linalg.html#todo",
    "href": "NumLinAlg/basics_of_linalg.html#todo",
    "title": "Basics of Linear Algebra",
    "section": "TODO",
    "text": "TODO\n\nVector norm\nHilber space (scalar product), Cauchy-Schwarz\nequivalence of norms\nlinear operator, matrix norm\nMatrixen , pos. definitheit\nSchur decomposition, spectral decomposition\nSingular Value Decomposition\nBanach fixed point theorem",
    "crumbs": [
      "About me",
      "Numerical Linear Algebra",
      "Basics of Linear Algebra"
    ]
  },
  {
    "objectID": "NumLinAlg/basics_of_linalg.html#references",
    "href": "NumLinAlg/basics_of_linalg.html#references",
    "title": "Basics of Linear Algebra",
    "section": "References",
    "text": "References\n\n\n[1] H. Wendland, Numerical Linear Algebra: An Introduction. Cambridge University Press, 2018.\n\n\n[2] A. Meister, Numerik linearer Gleichungssysteme, 5th ed. Springer Spektrum, 2015.\n\n\n[3] R. Rannacher, Numerical Linear Algebra. Heidelberg University Publ., 2018. doi: 10.17885/heiup.407.",
    "crumbs": [
      "About me",
      "Numerical Linear Algebra",
      "Basics of Linear Algebra"
    ]
  },
  {
    "objectID": "NumLinAlg/basics_of_linalg-slides.html#normed-spaces",
    "href": "NumLinAlg/basics_of_linalg-slides.html#normed-spaces",
    "title": "Basics of Linear Algebra",
    "section": "Normed Spaces",
    "text": "Normed Spaces\nConcepts such as distance, orthogonality and convergence are based on a scalar product and its induced metrics. As such, we’ll introduce the definitions of these concepts.\n\n\n\n\n\n\n\nDefinition 1: Norm\n\n\nLet \\(V\\) be a real (or complex) vector space. A mapping \\[\n\\lVert \\,\\cdot\\,\\rVert : V \\to [0, \\infty)\n\\]\nwith the properties\n\n\\(\\lVert \\mathbf{x} \\rVert = 0 \\iff \\mathbf{x} = 0\\) (definiteness)\n\\(\\lVert \\alpha \\mathbf{x} \\rVert = \\lvert \\alpha \\rvert \\, \\cdot \\, \\lVert \\mathbf{x} \\rVert\\) (homogeneity)\n\\(\\lVert \\mathbf{x} + \\mathbf{y} \\rVert \\leq \\lVert \\mathbf{x} \\rVert + \\lVert \\mathbf{y} \\rVert\\) (triangle inequality)\n\nis called a norm on \\(V\\).\n\n\n\n\n\nExamples for norms on \\(\\mathbb{R}^n\\) are the 1-norm, the maximum-norm and the Euclidean norm.\n\\[\n\\begin{aligned}\n\\lVert \\mathbf{x} \\rVert_1 &= \\sum_{i=1}^n \\lvert x_i \\rvert,\n&\n\\lVert \\mathbf{x} \\rVert_2\n&=\n\\left( \\sum_{i=1}^n x_i^2 \\right)^{1/2} \\\\\n\\lVert \\mathbf{x} \\rVert_\\infty &= \\max_{1 \\leq i \\leq n} \\lvert x_i \\rvert\n&\n\\lVert \\mathbf{x} \\rVert_p\n&=\n\\left( \\sum_{i=1}^n \\lvert x_i \\rvert^p \\right)^{1/p}\n\\end{aligned}\n\\]\n\n\nGraphing the p-Norm Unit Ball in 3 Dimensions is not trivial; For more info, read this post by Kayden Mimmack, 2019."
  },
  {
    "objectID": "NumLinAlg/basics_of_linalg-slides.html#hilbert-spaces",
    "href": "NumLinAlg/basics_of_linalg-slides.html#hilbert-spaces",
    "title": "Basics of Linear Algebra",
    "section": "Hilbert spaces",
    "text": "Hilbert spaces\n\n\n\n\n\n\nDefinition 3: Hilbert-space\n\n\nA mapping \\(\\langle \\cdot, \\cdot \\rangle : V \\times V \\to \\mathbb{R}\\) is called scalar product, if it has the following properties:\n\nsymmetry: \\(\\langle \\mathbf{x}, \\mathbf{y} \\rangle = \\langle \\mathbf{y}, \\mathbf{x} \\rangle\\)\npositive definiteness: \\(\\langle \\mathbf{x}, \\mathbf{x} \\rangle \\gt 0\\) for all \\(\\mathbf{x} \\in V\\)\nbilinear: \\(\\langle \\alpha \\mathbf{x} + \\beta \\mathbf{y}, \\mathbf{z} \\rangle = \\alpha \\langle \\mathbf{x}, \\mathbf{z} \\rangle + \\beta \\langle \\mathbf{y}, \\mathbf{z} \\rangle\\)\n\nA vector space equipped with a scalar product is called a pre-Hilbert space.\n\n\n\n\nFor a scalar product there holds the Cauchy-Schwarz inequality:\n\\[\n\\lvert \\langle \\mathbf{x}, \\mathbf{y} \\rangle \\lvert \\leq \\lVert \\mathbf{x} \\rVert \\, \\lVert \\mathbf{y} \\rVert\n\\]\n\n\nEvery pre-Hilbert space is a normed space with canonical norm \\(\\lVert \\mathbf{x} \\rVert := \\sqrt{ \\langle \\mathbf{x}, \\mathbf{x} \\rangle}\\). If the vector space is complete with respect to this norm, it is called a Hilbert space.\n\n\nThe dot product can be used to measure the angle between two vector in \\(\\mathbb{R}^n\\):\n\\[\n\\lvert \\langle \\mathbf{x}, \\mathbf{y} \\rangle \\rvert =\n\\lVert \\mathbf{x} \\rVert \\, \\lVert \\mathbf{y} \\rVert \\cos(\\alpha)\n\\]\n\n\n\nDot product in 2D\nThis figure was created with Geogebra and is hereby released to the public domain (CC0 1.0)\n\n\n\n\nTwo vectors are orthogonal, in symbols \\(\\mathbf{x} \\perp \\mathbf{y}\\), if their dot product is 0.\n\n\nThe orthogonal projection \\(P\\mathbf{x}\\) of a vector \\(\\mathbf{x}\\) to a subspace \\(M \\subseteq V\\) is determined by \\[\n\\lVert \\mathbf{x} - P \\mathbf{x} \\rVert = \\min_{y \\in M} \\lVert \\mathbf{x} - \\mathbf{y} \\rVert.\n\\]\n\n\n\nOrthogonal projection\n\n\nThis is often called best approximation property and is equivalent to the relation \\[\n\\langle \\mathbf{x} - P \\mathbf{x}, \\mathbf{y} \\rangle = 0 \\quad \\forall \\mathbf{y} \\in M.\n\\]\n\nProof. See (Wendland 2018, Proposition 1.17 (p. 23))."
  },
  {
    "objectID": "NumLinAlg/basics_of_linalg-slides.html#linear-operators-and-matrices",
    "href": "NumLinAlg/basics_of_linalg-slides.html#linear-operators-and-matrices",
    "title": "Basics of Linear Algebra",
    "section": "Linear Operators and Matrices",
    "text": "Linear Operators and Matrices\nA mappinng \\(\\varphi: \\mathbb{R}^n \\to \\mathbb{R}^m\\) is called linear, if: \\[\n\\varphi(a\\mathbf{x} + b \\mathbf{y})  = a \\varphi(\\mathbf{x}) + b \\varphi(\\mathbf{y})\n\\]\nWe can describe a linear mapping with a matrix \\(A\\) and the usual rules for matrix-vector multiplication. \\[\nA =\n\\begin{pmatrix}\na_{11} & \\dots & a_{1n} \\\\\n\\vdots  & & \\vdots \\\\\na_{m1} & \\dots & a_{mn}\n\\end{pmatrix}\n, \\qquad\n(A\\mathbf{x})_i\n=\n\\sum_{j=1}^n A_{ij} x_j\n\\]\n\nA linear operator \\(A: X \\to Y\\) is called bounded, if there is a constant \\(C \\gt 0\\) such that \\[\n\\lVert A \\mathbf{x} \\rVert_Y \\leq C \\lVert  \\mathbf{x} \\rVert_X .\n\\]\nFor any bounded operator we can define the operator norm via \\[\n\\lVert A \\rVert := \\sup_{\\lVert \\mathbf{x} \\rVert = 1} \\lVert A \\mathbf{x} \\rVert.\n\\] The operator norm is the smalles possible bound and we have \\(\\lVert A \\mathbf{x} \\rVert \\leq \\lVert A \\rVert \\, \\lVert \\mathbf{x} \\rVert\\) for any \\(\\mathbf{x}\\)."
  },
  {
    "objectID": "NumLinAlg/basics_of_linalg-slides.html#matrix-decompositions",
    "href": "NumLinAlg/basics_of_linalg-slides.html#matrix-decompositions",
    "title": "Basics of Linear Algebra",
    "section": "Matrix decompositions",
    "text": "Matrix decompositions\n\n\n\n\n\n\nTheorem: Schur decomposition\n\n\nFor every matrix \\(A \\in \\mathbb{R}^{n\\times n}\\) with real Eigenvalues, there exists an orthogonal matrix \\(U\\) such that \\[\nU^\\intercal A U\n\\] is an upper triangle matrix.\n\n\n\n\n\nProof. The proof is a bit technical. I refer to the standard literature on linear algebra:\n\nSchur decomposition by Marco Tobago (2021), Lectures on matrix algebra.\nLinear Algebra Done Right by Sheldon Axler, Springer (2025), Theorem 6.38 (p. 204)"
  },
  {
    "objectID": "NumLinAlg/basics_of_linalg-slides.html#banach-fixed-point-theorem",
    "href": "NumLinAlg/basics_of_linalg-slides.html#banach-fixed-point-theorem",
    "title": "Basics of Linear Algebra",
    "section": "Banach fixed-point theorem",
    "text": "Banach fixed-point theorem\n\n\n\n\n\n\nDefinition: Contraction\n\n\nAn operator \\(A: V \\to V\\) is called a contraction, if there exists a number \\(0 \\le q \\leq 1\\) such that \\[\n\\lVert F(\\mathbf{x}) - F(\\mathbf{y}) \\rVert \\leq q \\lVert \\mathbf{x} - \\mathbf{y} \\rVert.\n\\]"
  },
  {
    "objectID": "NumLinAlg/basics_of_linalg-slides.html#todo",
    "href": "NumLinAlg/basics_of_linalg-slides.html#todo",
    "title": "Basics of Linear Algebra",
    "section": "TODO",
    "text": "TODO\n\nVector norm\nHilber space (scalar product), Cauchy-Schwarz\nequivalence of norms\nlinear operator, matrix norm\nMatrixen , pos. definitheit\nSchur decomposition, spectral decomposition\nSingular Value Decomposition\nBanach fixed point theorem"
  },
  {
    "objectID": "NumLinAlg/basics_of_linalg-slides.html#references",
    "href": "NumLinAlg/basics_of_linalg-slides.html#references",
    "title": "Basics of Linear Algebra",
    "section": "References",
    "text": "References\n\n\nMeister, Andreas. 2015. Numerik linearer Gleichungssysteme. 5th ed. Springer Spektrum.\n\n\nRannacher, Rolf. 2018. Numerical Linear Algebra. Heidelberg University Publ. https://doi.org/10.17885/heiup.407.\n\n\nWendland, Holger. 2018. Numerical Linear Algebra: An Introduction. Cambridge University Press."
  },
  {
    "objectID": "NumLinAlg/julias_type_system.html",
    "href": "NumLinAlg/julias_type_system.html",
    "title": "Julias Type System",
    "section": "",
    "text": "There are two types of programming languages: Statically typed systems such as C++, where each variable must be of a particular type before execution, and dynamically typed systems, where the type is not known until runtime. Julia is a dynamically typed language, but still has the ability to specify certain types for better efficiency.\n. . .\nRecall that you can specify the type of a variable either by calling its constructor, or via using the :: operator:\njulia&gt; x::Float64 = 8\n8\n\njulia&gt; typeof(x)\nFloat64\nWe can determine the type of a variable with the typeof() function.\n\nTypes in Julia are organised in a hierarchy, which is very similar to inheritance in object-oriented languages such as C++, except that it also works for primitive types. Each type has exactly one parent type and possibly several child types, which can be determined using the supertype and subtype cmmands.\n. . .\njulia&gt; subtypes(Real)\n4-element Vector{Any}:\n AbstractFloat\n AbstractIrrational\n Integer\n Rational\n\njulia&gt; supertype(Float64)\nAbstractFloat\nFor example, Real is an abstract type representing real numbers, which has subtypes for rational, integer, and floating-point types.\n\nThis way we can display the complete type tree:\n\n\n\nTypes in Julia.\nThis figure was created with draw.io and is hereby licensed under Public Domain (CC0 1.0)\n\n\n\nAs you can see, each type is a subtype of the type Any. We can check whether a type is a subtype of another using the &lt;: operator.\njulia&gt; Float64 &lt;: Any\ntrue\n. . .\nConcrete types such as Float64 or Int64 can be instantiated, whereas abstract types exist only in the type hierarchy.\njulia&gt; isconcretetype(Float64)\ntrue\n\njulia&gt; isabstracttype(AbstractFloat)\ntrue\n. . .\nThere are also composite types, which are made up of many smaller types.\nstruct Person\n  name::String\n  age::Int\n  married::Bool\nend\n. . .\n\n\n\n\n\n\nImportantImportant\n\n\n\nComposite types in Julia are not the same as classes in other languages. They don’t support inheritance and can’t have member functions.\n\n\n. . .\nTo instantiate a variable of that type, we call it’s constructor.\njulia&gt; author = Person(\"Marcel\", 29, false)\nPerson(\"Marcel\", 29, false)\n\njulia&gt; typeof(author)\nPerson\nAs usual, we can access the member variables of a composite type using the . notation.\njulia&gt; author.name\n\"Marcel\"\n\njulia&gt; author.age\n29\n\njulia&gt; author.married\nfalse\n. . .\nBy default, composite types are immutable, meaning they cannot be changed. However, an immutable object can contain mutable fields, such as arrays, which remain mutable.\nTo define a mutable type, use the mutable keyword. If you want to ensure that a particular field remains constant in an otherwise mutable object, you can do this using the const keyword.\nmutable struct Triple\n  a::Int\n  b::Real\n  const c::Char\nend\n\njulia&gt; X = Triple(8, 3.7, 'K')\nTriple(8, 3.7, 'K')\n\njulia&gt; X.a = 5\n5\n\njulia&gt; X.c = 'M'\nERROR: setfield!: const field .c of type Triple cannot be changed\nStacktrace:\n[...]\n\nTODO: Ist das wichtig?\nAbstract, primitive and composite types are all instances of the same concept, DataType, which is the type of these types.\njulia&gt; typeof(Real)\nDataType\n\njulia&gt; typeof(Person)\nDataType\n\njulia&gt; typeof(DataType)\nDataType",
    "crumbs": [
      "About me",
      "Numerical Linear Algebra",
      "Julias Type System"
    ]
  },
  {
    "objectID": "NumLinAlg/julias_type_system.html#types-in-julia",
    "href": "NumLinAlg/julias_type_system.html#types-in-julia",
    "title": "Julias Type System",
    "section": "",
    "text": "There are two types of programming languages: Statically typed systems such as C++, where each variable must be of a particular type before execution, and dynamically typed systems, where the type is not known until runtime. Julia is a dynamically typed language, but still has the ability to specify certain types for better efficiency.\n. . .\nRecall that you can specify the type of a variable either by calling its constructor, or via using the :: operator:\njulia&gt; x::Float64 = 8\n8\n\njulia&gt; typeof(x)\nFloat64\nWe can determine the type of a variable with the typeof() function.\n\nTypes in Julia are organised in a hierarchy, which is very similar to inheritance in object-oriented languages such as C++, except that it also works for primitive types. Each type has exactly one parent type and possibly several child types, which can be determined using the supertype and subtype cmmands.\n. . .\njulia&gt; subtypes(Real)\n4-element Vector{Any}:\n AbstractFloat\n AbstractIrrational\n Integer\n Rational\n\njulia&gt; supertype(Float64)\nAbstractFloat\nFor example, Real is an abstract type representing real numbers, which has subtypes for rational, integer, and floating-point types.\n\nThis way we can display the complete type tree:\n\n\n\nTypes in Julia.\nThis figure was created with draw.io and is hereby licensed under Public Domain (CC0 1.0)\n\n\n\nAs you can see, each type is a subtype of the type Any. We can check whether a type is a subtype of another using the &lt;: operator.\njulia&gt; Float64 &lt;: Any\ntrue\n. . .\nConcrete types such as Float64 or Int64 can be instantiated, whereas abstract types exist only in the type hierarchy.\njulia&gt; isconcretetype(Float64)\ntrue\n\njulia&gt; isabstracttype(AbstractFloat)\ntrue\n. . .\nThere are also composite types, which are made up of many smaller types.\nstruct Person\n  name::String\n  age::Int\n  married::Bool\nend\n. . .\n\n\n\n\n\n\nImportantImportant\n\n\n\nComposite types in Julia are not the same as classes in other languages. They don’t support inheritance and can’t have member functions.\n\n\n. . .\nTo instantiate a variable of that type, we call it’s constructor.\njulia&gt; author = Person(\"Marcel\", 29, false)\nPerson(\"Marcel\", 29, false)\n\njulia&gt; typeof(author)\nPerson\nAs usual, we can access the member variables of a composite type using the . notation.\njulia&gt; author.name\n\"Marcel\"\n\njulia&gt; author.age\n29\n\njulia&gt; author.married\nfalse\n. . .\nBy default, composite types are immutable, meaning they cannot be changed. However, an immutable object can contain mutable fields, such as arrays, which remain mutable.\nTo define a mutable type, use the mutable keyword. If you want to ensure that a particular field remains constant in an otherwise mutable object, you can do this using the const keyword.\nmutable struct Triple\n  a::Int\n  b::Real\n  const c::Char\nend\n\njulia&gt; X = Triple(8, 3.7, 'K')\nTriple(8, 3.7, 'K')\n\njulia&gt; X.a = 5\n5\n\njulia&gt; X.c = 'M'\nERROR: setfield!: const field .c of type Triple cannot be changed\nStacktrace:\n[...]\n\nTODO: Ist das wichtig?\nAbstract, primitive and composite types are all instances of the same concept, DataType, which is the type of these types.\njulia&gt; typeof(Real)\nDataType\n\njulia&gt; typeof(Person)\nDataType\n\njulia&gt; typeof(DataType)\nDataType",
    "crumbs": [
      "About me",
      "Numerical Linear Algebra",
      "Julias Type System"
    ]
  },
  {
    "objectID": "NumLinAlg/julias_type_system.html#type-unions",
    "href": "NumLinAlg/julias_type_system.html#type-unions",
    "title": "Julias Type System",
    "section": "Type Unions",
    "text": "Type Unions\nWhat if you want to specify that a function accepts signed and unsigned integers, but not bool? You can use a union type.\nThe concept is similar in other programming languages.\n\nJuliaC++\n\n\nIntOrString = Union{Int, AbstractString}\n\nx = 8::IntOrString\nx = \"Hello!\"\n\nprintln(x)\n\n\nusing IntOrString = std::variant&lt;int, std::string&gt;;\n\nauto x = IntOrString(8);\nx = \"Hello!\";\n\nstd::println(std::get&lt;std::string&gt;(x));\n\n\n\nA particularly useful case of a Union type is Union{T, Nothing}, which would be equivalent to std::optional in C++.",
    "crumbs": [
      "About me",
      "Numerical Linear Algebra",
      "Julias Type System"
    ]
  },
  {
    "objectID": "NumLinAlg/julias_type_system.html#parametric-types",
    "href": "NumLinAlg/julias_type_system.html#parametric-types",
    "title": "Julias Type System",
    "section": "Parametric Types",
    "text": "Parametric Types\nTypes in Julia can take parameters, so type declarations introduce a whole family of types. This concept is known in other programming languages as generic programming.\n\nJuliaC++\n\n\nstruct Point{T}\n    x::T\n    y::T\nend\n\nP = Point{Float64}(5, 8)\n\n\ntemplate &lt;typename T&gt;\nstuct Point {\n  T x;\n  T y;\n}\n\nauto P = Point&lt;double&gt;(5, 8)\n\n\n\n\n\n\n\n\n\nWarningWarning\n\n\n\nNote that although Float64 is a subtype of Real, we do NOT have:\njulia&gt; Point{Float64} &lt;: Point{Real}\nfalse\n\n\nIn other words, Julia’s type parameters are invariant.\n. . .\nLet’s say we want to write a generic function that can take Point{Float64} as an argument. The following method won’t work:\nfunction norm(p::Point{Real})\n    sqrt(p.x^2 + p.y^2)\nend\nSince Point{Float64} is not a subtype of Point{Real}, the function can’t take Point{Float64} as an argument.\n. . .\n\n\n\n\n\n\nImportant\n\n\n\nThe correct way to define a method that accepts all arguments of type Point{T} where T is a subtype of Real is:\nfunction norm(p::Point{T}) where T&lt;:Real;\n    sqrt(p.x^2 + p.y^2)\nend\n\n\nAlternatively, one could also write\nfunction norm(p::Point{&lt;:Real})\n    sqrt(p.x^2 + p.y^2)\nend\n. . .\n\n\n\n\n\n\nNoteExercise\n\n\n\nImplement a parametric type for rational numbers.\n\n\n\n\n\n\n\n\nNoteSolution\n\n\n\n\n\nstruct Rational{T&lt;:Integer} &lt;: Real\n    num::T\n    den::T\nend",
    "crumbs": [
      "About me",
      "Numerical Linear Algebra",
      "Julias Type System"
    ]
  },
  {
    "objectID": "NumLinAlg/julias_type_system.html#arrays",
    "href": "NumLinAlg/julias_type_system.html#arrays",
    "title": "Julias Type System",
    "section": "Arrays",
    "text": "Arrays\nArrays are data structures that allow random access to elements. Arrays often represent vectors and matrices. Julia has built-in support for arrays, with indexing and slicing syntax similar to Python or MATLAB. A (column)-vector in Julia can be constructed directly using square brackets and a comma (or semicolon) as separators.\njulia&gt; v = [4, 8, 15, 16, 23, 42]\n6-element Vector{Int64}:\n  4\n  8\n 15\n 16\n 23\n 42\n. . .\nThere are built-in functions for constructing common matrices:\n\nJuliaPython\n\n\njulia&gt; zeros(Int8, (2, 3))\n2×3 Matrix{Int8}:\n 0  0  0\n 0  0  0\n\njulia&gt; A = rand(2, 2)\n×2 Matrix{Float64}:\n0.380141  0.81997\n0.93474   0.0321379\n\njulia&gt; Matrix{Float64}(I, 3, 3)\n3×3 Matrix{Float64}:\n 1.0  0.0  0.0\n 0.0  1.0  0.0\n 0.0  0.0  1.0\n\n\n&gt;&gt;&gt; A = np.zeros( (2, 3), dtype=int)\narray([[0, 0, 0],\n       [0, 0, 0]])\n\n&gt;&gt;&gt; np.random.rand( 2, 2)\narray([[0.46581219, 0.93757536],\n       [0.97690228, 0.72186734]])\n\n&gt;&gt;&gt; np.identity(3)\narray([[1., 0., 0.],\n       [0., 1., 0.],\n       [0., 0., 1.]])\n\n\n\n. . .\nNote that ranges in Julia are closed, i.e. they include the endpoint.\n\nJuliaPython\n\n\njulia&gt; collect(range(1, 5))\n1:5\n\njulia&gt; range(0, 2*pi, length=10)\n0.0:0.6981317007977318:6.283185307179586\n\n\n&gt;&gt;&gt; np.arange(0, 5)\narray([0, 1, 2, 3, 4])\n&gt;&gt;&gt; np.linspace(0, 2*np.pi, num=10, endpoint=True)\narray([0.        , 0.6981317 , 1.3962634 , 2.0943951 , 2.7925268 ,\n       3.4906585 , 4.1887902 , 4.88692191, 5.58505361, 6.28318531])\n\n\n\n. . .\nYou can basic information about the data type, dimension and size of the matrix:\n\nJuliaPython\n\n\njulia&gt; eltype(A)\nFloat64\n\njulia&gt; ndims(A)\n2\n\njulia&gt; size(A)\n(2, 2)\n\njulia&gt; length(A)\n4\n\n\n&gt;&gt;&gt; A.dtype\ndtype('int64')\n&gt;&gt;&gt; A.ndim\n2\n&gt;&gt;&gt; A.shape\n(2, 3)\n&gt;&gt;&gt; A.size\n6\n\n\n\n\nIndexing and Slicing works very similar to MATLAB/Python:\n\n\n\nArray Slicing in Julia\nThis image was created using draw.io and is hereby released into the public domain (CC0 1.0)\n\n\n\nJuliaPython\n\n\nA = transpose(reshape(1:25, 5, 5))\n\nred = A[:, 2:2:end]\nblue = A[2:2:end, 1:2:3]\nyellow = A[end, :]\n\n\nA = np.arange(1, 26).reshape((5,5))\n\nred = A[:, 1::2]\nblue = A[1::2, 0:3:2]\nyellow = A[-1, :]\n\n\n\nBy default, indexing and slicing return copies of the array. For performance reasons, it may sometimes be better to just get a view:\n\nJuliaPython\n\n\njulia&gt; B = @view A[2, :]\n3-element view(::Matrix{Int64}, 2, :) with eltype Int64:\n  8\n 42\n 69\n\njulia&gt; B[2] = -5\n-5\n\njulia&gt; A\n3×3 Matrix{Int64}:\n 1   2    3\n 8  -5   69\n 5  25  100\n\n\n&gt;&gt;&gt; B = A[:, 1]\n&gt;&gt;&gt; B[1] = -5\n\n&gt;&gt;&gt; A\narray([[  1,   2,   3],\n       [  8,  -5,  69],\n       [  5,  25, 100]])\n\n\n\nAs you can see, changing the second element of B causes the corresponding element of A to change as well.\n\nTo use logical indexing (masking) in Julia, you must first map a lambda function to each element to create a mask. Alternatively, you can use dot syntax to vectorise a particular function.\n\nJuliaPython\n\n\njulia&gt; mask = map( x -&gt; (x &gt; 3), A)\n3×3 Matrix{Bool}:\n 0  0  0\n 1  0  1\n 1  1  1\n\njulia&gt; A[mask]\n5-element Vector{Int64}:\n   8\n   5\n  25\n  69\n 100\n\njulia&gt; A[A.&gt;3]\n5-element Vector{Int64}:\n   8\n   5\n  25\n  69\n 100\n\n\n&gt;&gt;&gt; A &gt; 3\narray([[False, False, False],\n       [ True, False,  True],\n       [ True,  True,  True]])\n\n&gt;&gt;&gt; A[A&gt;3]\narray([  8,  69,   5,  25, 100])\n\n\n\n\nYou can use hcat and to combine multiple arrays:\n\n\n\nArray concatenation in Julia\nThis image was created with draw.io and is hereby release into the public domain (CC0 1.0).\n\n\n\nJuliaPython\n\n\njulia&gt; hcat(A, B)\n2×6 Matrix{Int64}:\n 1  2  3  42  69  100\n 4  5  6  73  13   25\n\njulia&gt; vcat(A, B)\n4×3 Matrix{Int64}:\n  1   2    3\n  4   5    6\n 42  69  100\n 73  13   25\n\n\n&gt;&gt;&gt; np.hstack( (A, B) )\narray([[  1,   2,   3,  42,  69, 100],\n       [  4,   5,   6,  73,  13,  25]])\n&gt;&gt;&gt; np.vstack( (A,B) )\narray([[  1,   2,   3],\n       [  4,   5,   6],\n       [ 42,  69, 100],\n       [ 73,  13,  25]])\n\n\n\n\nBroadcasting also works in Julia, but you have to explicitly use the broadcast function, so the syntax is a bit more verbose. That way, broadcasting cannot happen by accident.\n\nJuliaPython\n\n\njulia&gt; A = randn(2,2)\n2×2 Matrix{Float64}:\n -0.805994   0.887138\n  0.630169  -0.70303\n\njulia&gt; b = [5; 3]\n2-element Vector{Int64}:\n 5\n 3\n\njulia&gt; broadcast(+, A, b)\n2×2 Matrix{Float64}:\n 4.19401  5.88714\n 3.63017  2.29697\n\n\n&gt;&gt;&gt; A = np.random.randn(2, 2)\n&gt;&gt;&gt; A\narray([[ 0.22867558,  0.50563247],\n       [-0.21137373, -1.31592931]])\n&gt;&gt;&gt; b = np.array([[5, 3]]).T\n&gt;&gt;&gt; b\narray([[5],\n       [3]])\n&gt;&gt;&gt; A + b\narray([[5.22867558, 5.50563247],\n       [2.78862627, 1.68407069]])",
    "crumbs": [
      "About me",
      "Numerical Linear Algebra",
      "Julias Type System"
    ]
  },
  {
    "objectID": "NumLinAlg/julias_type_system.html#constructors",
    "href": "NumLinAlg/julias_type_system.html#constructors",
    "title": "Julias Type System",
    "section": "Constructors",
    "text": "Constructors\nConstructors are functions that create new instances of composite types. When a user defines a new composite type, Julia creates the default constructors. However, in some cases constructors need additional functionality, for example to enforce constraints (called invariants) through argument checking or transformation.\nHere’s a simple example illustrating the use of constructors in Julia:\nstruct Rectangle{T &lt;: Real}\n   width::T\n   height::T\n\n   # Inner constructor\n   function Rectangle(width::Real, height::Real)\n       @assert width &gt;= 0 \"Width must be non-negative!\"\n       @assert height &gt;= 0 \"Height must be non-negative!\"\n       promoted_type = promote_type(typeof(width), typeof(height))\n       new{promoted_type}(width, height)\n   end\n\n   # Default Constructor\n   Rectangle() = Rectangle(1.0, 1.0)\nend\n. . .\nThat way, you can construct a Rectangle via\nrect1 = Rectangle(5.0, 3.0)     # Float64\nrect2 = Rectangle(5, 3)         # Int64\nrect3 = Rectangle(5.0, 3)       # Float64 (via type promotion)\nrect4 = Rectangle()             # default: Float64\nbut calling it with negative arguments results in an error:\nrect = Rectangle(5.0, -3.0)    # error\n\nSometimes it can be useful to define a struct with some default values. This can be achieved either by using default arguments in the constructor,\nstruct MyType\n        a::Int # required keyword\n        b::Float64 # optional\n        \n        MyType(a::Int) = new(a, 2.3)\n        MyType(a::Int, b::Float64) = new(a, b)\nend \n. . .\nor by using the Base.@kwdef macro:\nBase.@kwdef struct MyType\n    a::Int # required keyword\n    b::Float64 = 2.3\n    c::String = \"hello\"\nend\n. . .\nIf you omit any of the optional parameters, the values must be passed as keyword arguments:\njulia&gt; MyType(1, 2.3, \"aaa\")\nMyType(1, 2.3, \"aaa\")\n\njulia&gt; MyType(; a = 3)\nMyType(3, 2.3, \"hello\")\n\nTODO: Explain functors, make comparison with C++\nBase.@kwdef struct Gauss\n    μ::Float64 = 0.0\n    σ::Float64 = 1.0\n    \n    function Gauss(mu::Real, sigma::Real)\n        @assert sigma &gt; 0 \"sigma must be positive\"\n        new(mu, sigma)\n    end\nend     \n\n# Function to compute the normal distribution\n(d::Gauss)(x::Real) = 1/(d.σ * sqrt(2π)) * exp(-1/2((x-d.μ)/d.σ)^2)",
    "crumbs": [
      "About me",
      "Numerical Linear Algebra",
      "Julias Type System"
    ]
  },
  {
    "objectID": "NumLinAlg/julias_type_system.html#method-overloading",
    "href": "NumLinAlg/julias_type_system.html#method-overloading",
    "title": "Julias Type System",
    "section": "Method Overloading",
    "text": "Method Overloading\nA function in Julia can consist of multiple methods. When a user calls a function, the method that is actually executed depends on the type and number of arguments. This is very similar to function overloading in C++.\n\nJuliaC++\n\n\njulia&gt; f(x::Float64, y::Float64) = 2x - y\nf (generic function with 2 methods)\n\njulia&gt; f(x::Int64, y::Int64) = 2x - y\nf (generic function with 2 methods)\n\n\ndouble f(double x, double y) {\n    return 2*x - y;\n}\n\nlong f(long x, long y) {\n    return 2*x - y;\n}\n\n\n\n. . .\nYou can use the methods function to get a list of the methods for a given function.\njulia&gt; methods(f)\n# 2 methods for generic function \"f\" from Main:\n [1] f(x::Int64, y::Int64)\n     @ REPL[5]:1\n [2] f(x::Float64, y::Float64)\n     @ REPL[4]:1\n\nWe can call this function in the usual way:\njulia&gt; f(2, 3)\n1\n\njulia&gt; f(2.0, 3.0)\n1.0\n. . .\nIf there is no method available for the given arguments, this will result in a MethodError:\njulia&gt; f(2, 3.7)\nERROR: MethodError: no method matching f(::Int64, ::Float64)\nThe function `f` exists, but no method is defined for this combination of argument types.\n\nClosest candidates are:\n  f(::Int64, ::Int64)\n   @ Main REPL[5]:1\n  f(::Float64, ::Float64)\n   @ Main REPL[4]:1\n\nStacktrace:\n[...]\n\nProviding a method for every possible combination of types can quickly get out of hand; it is more useful to define general methods where the parameters are abstract:\njulia&gt; f(x::Number, y::Number) = 2x - y\nf (generic function with 2 methods)\n\njulia&gt; f(2.0, 3)\n1.0\nThis function will work for any numeric type; non-numeric types will throw an error as expected.\njulia&gt; f(2, 3)\n7\n\njulia&gt; f(2.0, 3.0)\n7.0\n\njulia&gt; f(2.0, 3)\n7.0\n\njulia&gt; f(\"2.0\", 3)\nERROR: MethodError: no method matching f(::String, ::Int64)\n\nCare should be taken to ensure that there are no conflicting methods for the same function. If more than one method is applicable to a particular combination of arguments, the function call is ambiguous and an error will occur.\njulia&gt; g(x::Float64, y) = 2x + y\ng (generic function with 1 method)\n\njulia&gt; g(x, y::Float64) = x + 2y\ng (generic function with 2 methods)\n\njulia&gt; g(2.0, 3)\n7.0\n\njulia&gt; g(2, 3.0)\n8.0\n\njulia&gt; g(2.0, 3.0)\nERROR: MethodError: g(::Float64, ::Float64) is ambiguous.\n[...]",
    "crumbs": [
      "About me",
      "Numerical Linear Algebra",
      "Julias Type System"
    ]
  },
  {
    "objectID": "NumLinAlg/julias_type_system.html#polymorphism",
    "href": "NumLinAlg/julias_type_system.html#polymorphism",
    "title": "Julias Type System",
    "section": "Polymorphism",
    "text": "Polymorphism\nIn order to understand Multiple Dispatch, we first need to talk about Polymorphism.\n. . .\nPolymorphism, meaning “many forms,” is a fundamental concept in object-oriented programming (OOP) that allows objects of different classes to be treated as objects of a common type. It enables you to design code that is more flexible, extensible, and reusable.\n. . .\n\nC++C#\n\n\n#include &lt;vector&gt;\n#include &lt;iostream&gt;\n#include &lt;memory&gt;\n\nclass Animal {\n  public:\n    virtual void sound() const {\n      std::cout &lt;&lt; \"FALLBACK\\n\" &lt;&lt; std::endl;\n    }\n    virtual ~Animal() = default;\n};\n\nclass Dog : public Animal {\n  public:\n    void sound() const override {\n      std::cout &lt;&lt; \"bark\\n\";\n    }\n};\n\nclass Cat : public Animal {\n  public:\n    void sound() const override {\n      std::cout &lt;&lt; \"miau\\n\";\n    }\n};\n\n\n\nint main()\n{\n  auto ein = std::make_unique&lt;Dog&gt;();\n  auto sphinx = std::make_unique&lt;Cat&gt;();\n\n  ein-&gt;sound();\n  sphinx-&gt;sound();\n}\n\n\nusing System;\n\npublic class Animal\n{\n  public virtual void Sound()\n  {\n    Console.WriteLine(\"FALLBACK\");\n  }\n}\n\npublic class Dog : Animal\n{\n  public override void Sound()\n  {\n    Console.WriteLine(\"bark\");\n  }\n}\n\npublic class Cat : Animal\n{\n  public override void Sound()\n  {\n    Console.WriteLine(\"miau\");\n  }\n}\n\npublic class Program\n{\n  public static void Main(string[] args)\n  {\n    Animal ein = new Dog();\n    Animal sphinx = new Cat();\n\n    ein.Sound();\n    sphinx.Sound();\n  }\n}\n\n\n\nAs Julia is not an object-oriented language, the only way to achieve something similar is as follows:\nabstract type Animal end\nstruct Cat &lt;: Animal end\nstruct Dog &lt;: Animal end\nstruct Bird &lt;: Animal end\n\nmake_sound(cat::Cat) = println(\"miau!\")\nmake_sound(dog::Dog) = println(\"wuff!\")\nmake_sound(bird::Bird) = println(\"chierp!\")\n\nein = Dog()\nshinx = Cat()\n\nmake_sound(ein)\nmake_sound(cat)\nThis isn’t very spectacular yet; it looks like normal operator overloading. Things get more interesting when the functions have more arguments.",
    "crumbs": [
      "About me",
      "Numerical Linear Algebra",
      "Julias Type System"
    ]
  },
  {
    "objectID": "NumLinAlg/julias_type_system.html#multiple-dispatch",
    "href": "NumLinAlg/julias_type_system.html#multiple-dispatch",
    "title": "Julias Type System",
    "section": "Multiple Dispatch",
    "text": "Multiple Dispatch\nMulti-dispatch is the ability to choose which version of a function to call based on the runtime type of all arguments passed to the function call.\n\nJuliaC++\n\n\nabstract type Pet end\nstruct Dog &lt;: Pet; name::String end\nstruct Cat &lt;: Pet; name::String end\n\nfunction encounter(a::Pet, b::Pet)\n    verb = meets(a, b)\n    println(\"$(a.name) meets $(b.name) and $verb\")\nend\n\nmeets(a::Dog, b::Dog) = \"sniffs\"\nmeets(a::Dog, b::Cat) = \"chases\"\nmeets(a::Cat, b::Dog) = \"hisses\"\nmeets(a::Cat, b::Cat) = \"slinks\"\n\nfido = Dog(\"Fido\")\nrex = Dog(\"Rex\")\nwhiskers = Cat(\"Whiskers\")\nspots = Cat(\"Spots\")\n\nencounter(fido, rex)\nencounter(fido, whiskers)\nencounter(whiskers, rex)\nencounter(whiskers, spots)\nFido meets Rex and sniffs\nFido meets Whiskers and chases\nWhiskers meets Rex and hisses\nWhiskers meets Spots and slinks\n\n\n#include &lt;iostream&gt;\n#include &lt;string&gt;\n\nclass Pet {\n    public:\n        std::string name{};\n};\n\nclass Dog : public Pet{};\nclass Cat : public Pet{};\n\nstd::string meets(Dog a, Dog b) { return \"sniffs\"; }\nstd::string meets(Dog a, Cat b) { return \"chases\"; }\nstd::string meets(Cat a, Dog b) { return \"hisses\"; }\nstd::string meets(Cat a, Cat b) { return \"slinks\"; }\n\nstd::string meets(Pet a, Pet b) {\n    return \"FALLBACK\";\n}\n\nvoid encounter(Pet a, Pet b) {\n    auto verb = meets(a, b);\n    std::cout &lt;&lt; a.name &lt;&lt; \" meets \"\n        &lt;&lt; b.name &lt;&lt; \" and \" &lt;&lt; verb &lt;&lt; std::endl;\n}\n\nint main() {\n    Dog fido{\"Fido\"};\n    Dog rex{\"Rex\"};\n    Cat whiskers{\"whiskers\"};\n    Cat spots{\"spots\"};\n\n    encounter(fido, rex);\n    encounter(fido, whiskers);\n    encounter(whiskers, rex);\n    encounter(whiskers, spots);\n}\nFido meets Rex and FALLBACK\nFido meets whiskers and FALLBACK\nwhiskers meets Rex and FALLBACK\nwhiskers meets spots and FALLBACK\n\n\n\nDoing something like this in C++ is not possible.\n. . .\nSee also:\n\nThe Unreasonable Effectiveness of Multiple Dispatch by Stefan Karpinski, JuliaCon 2019\nMultiple Dispatch in C++ on StackOverflow\nA polyglot’s guide to multiple dispatch by Eli Bendersky (permalink)",
    "crumbs": [
      "About me",
      "Numerical Linear Algebra",
      "Julias Type System"
    ]
  },
  {
    "objectID": "NumLinAlg/julias_type_system.html#functional-programming",
    "href": "NumLinAlg/julias_type_system.html#functional-programming",
    "title": "Julias Type System",
    "section": "Functional Programming",
    "text": "Functional Programming\nFunctional programming is a programming paradigm where programs are constructed by applying and composing functions. It’s a declarative style of programming, meaning you describe what you want to achieve rather than how to achieve it (which is more typical of imperative programming)\n. . .\nThe core concepts and characteristics of functional programming are as follows:\n\nFunctions are first-class objects, meaning they can be passed around and stored like variables.\nHigher order functions: functions can take other functions as arguments, or return a function as a result\nImmutability: Data, once created, cannot be changed. Instead of modifying existing data structures, you create new ones with the desired changes.\nDeclarative style programming: Using map, filter and reduce instead of for loops to iterate over an array.\n\n\nMap, Filter, Reduce\n\nmap: Transforms each element in a collection by applying a function to it, returning a new collection of the same size.\nfilter: Creates a new collection containing only elements that satisfy a given predicate function.\nreduce: Reduces a collection to a single value by iteratively applying a function that combines elements.\n\n\n\nNormal Distribution\n\\[\n\\mathcal{N}(x | \\mu, \\sigma) = \\frac{1}{\\sqrt{2\\pi}\\sigma} \\exp\\left({- \\frac{1}{2} \\biggl( \\frac{x - \\mu}{\\sigma} \\biggr)^2 }\\right)\n\\] \\[\n\\mathcal{N}(x | \\mu, \\sigma) = \\frac{1}{\\sqrt{2\\pi}\\sigma} \\, e^{- \\frac{1}{2} \\left( \\frac{x - \\mu}{\\sigma} \\right)^2 }\n\\]\nClosure:\n\nJuliaC++\n\n\nfunction normal_distribution(μ::Real = 0, σ::Real = 1)\n  return x -&gt; 1 / (sqrt(2π) * σ) * exp(-1/2 * ((x - μ)/σ)^2) \nend\n\nf = normal_distribution(5, 2)\nprintln(f(7.5))\n\n\n#include &lt;cmath&gt;\n#include &lt;functional&gt;\n#include &lt;iostream&gt;\n#include &lt;numbers&gt;\n\nstd::function&lt;double(double)&gt; normal_distribution(double mu=0.0, double sigma=1.0) {\n  return [=](double x) {\n    return 1 / (std::sqrt(2 * std::numbers::pi) * sigma) * std::exp( -1/2 * std::pow( (x - mu) / sigma, 2));\n  };\n}\n\nint main()\n{\n  auto f = normal_distribution(5.0, 2.0);\n  std::cout &lt;&lt; f(7.5) &lt;&lt; std::endl;\n}\n\n\n\n\n\nLeetCode Example\nLet’s say we want to solve LeetCode problem 557 (Reverse Words in a String III). Given a string str, reverse the characters in each word while still preserving the initial word order.\nExample:\nstr = \"The quick brown fox jumps over the lazy dog\"\n--&gt; \"ehT kciuq nworb xof spmuj revo eht yzal god\"\n. . .\nThis problem can be solved in a very elegant way using functional programming:\n\nsplit the string at the space (’ ’) character\nmap the reverse function to each element\njoin everything back together\n\n. . .\n\nJuliaC++\n\n\nfunction reverse_word(str::String)\n  return join(map(reverse, split(str, \" \")), \" \")\nend\n\n\n#include &lt;string&gt;\n#include &lt;ranges&gt;\n#include &lt;string_view&gt;\n\nstd::string reverseWords(std::string_view str) {\n  return str | std::views::split(' ')\n             | std::views::transform([](auto&& word) {\n                  return word | std::views::reverse;\n                })\n              | std::views::join_with(' ')\n              | std::ranges::to&lt;std::string&gt;();\n}\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nAlternatively, you can do this with the pipe operator:\nfunction reverse_word(str::String)\n  return str |&gt; x -&gt; split(x, \" \") |&gt;\n  x -&gt; map(reverse, x) |&gt;\n  x -&gt; join(x, \" \")\nend",
    "crumbs": [
      "About me",
      "Numerical Linear Algebra",
      "Julias Type System"
    ]
  },
  {
    "objectID": "NumLinAlg/julias_type_system.html#todo",
    "href": "NumLinAlg/julias_type_system.html#todo",
    "title": "Julias Type System",
    "section": "TODO:",
    "text": "TODO:\n\nConstructors\nMethod overloading\nPolymorphism, Multiple Dispatch\nFunctional Programming (map, reduce; …)\nExample for FP vs OOP: normal distribution\nSets\nDictionaries\nDifference Arrays vs. Tuples (named tuples as intro to DataFrames)",
    "crumbs": [
      "About me",
      "Numerical Linear Algebra",
      "Julias Type System"
    ]
  },
  {
    "objectID": "NumLinAlg/julias_type_system-slides.html#types-in-julia",
    "href": "NumLinAlg/julias_type_system-slides.html#types-in-julia",
    "title": "Julias Type System",
    "section": "Types in Julia",
    "text": "Types in Julia\nThere are two types of programming languages: Statically typed systems such as C++, where each variable must be of a particular type before execution, and dynamically typed systems, where the type is not known until runtime. Julia is a dynamically typed language, but still has the ability to specify certain types for better efficiency.\n\nRecall that you can specify the type of a variable either by calling its constructor, or via using the :: operator:\njulia&gt; x::Float64 = 8\n8\n\njulia&gt; typeof(x)\nFloat64\nWe can determine the type of a variable with the typeof() function."
  },
  {
    "objectID": "NumLinAlg/julias_type_system-slides.html#type-unions",
    "href": "NumLinAlg/julias_type_system-slides.html#type-unions",
    "title": "Julias Type System",
    "section": "Type Unions",
    "text": "Type Unions\nWhat if you want to specify that a function accepts signed and unsigned integers, but not bool? You can use a union type.\nThe concept is similar in other programming languages.\n\nJuliaC++\n\n\nIntOrString = Union{Int, AbstractString}\n\nx = 8::IntOrString\nx = \"Hello!\"\n\nprintln(x)\n\n\nusing IntOrString = std::variant&lt;int, std::string&gt;;\n\nauto x = IntOrString(8);\nx = \"Hello!\";\n\nstd::println(std::get&lt;std::string&gt;(x));\n\n\n\nA particularly useful case of a Union type is Union{T, Nothing}, which would be equivalent to std::optional in C++."
  },
  {
    "objectID": "NumLinAlg/julias_type_system-slides.html#parametric-types",
    "href": "NumLinAlg/julias_type_system-slides.html#parametric-types",
    "title": "Julias Type System",
    "section": "Parametric Types",
    "text": "Parametric Types\nTypes in Julia can take parameters, so type declarations introduce a whole family of types. This concept is known in other programming languages as generic programming.\n\nJuliaC++\n\n\nstruct Point{T}\n    x::T\n    y::T\nend\n\nP = Point{Float64}(5, 8)\n\n\ntemplate &lt;typename T&gt;\nstuct Point {\n  T x;\n  T y;\n}\n\nauto P = Point&lt;double&gt;(5, 8)\n\n\n\n\n\n\n\n\n\nWarning\n\n\nNote that although Float64 is a subtype of Real, we do NOT have:\njulia&gt; Point{Float64} &lt;: Point{Real}\nfalse\n\n\n\nIn other words, Julia’s type parameters are invariant.\n\nLet’s say we want to write a generic function that can take Point{Float64} as an argument. The following method won’t work:\nfunction norm(p::Point{Real})\n    sqrt(p.x^2 + p.y^2)\nend\nSince Point{Float64} is not a subtype of Point{Real}, the function can’t take Point{Float64} as an argument.\n\n\n\n\n\n\n\n\nImportant\n\n\nThe correct way to define a method that accepts all arguments of type Point{T} where T is a subtype of Real is:\nfunction norm(p::Point{T}) where T&lt;:Real;\n    sqrt(p.x^2 + p.y^2)\nend\n\n\n\nAlternatively, one could also write\nfunction norm(p::Point{&lt;:Real})\n    sqrt(p.x^2 + p.y^2)\nend\n\n\n\n\n\n\n\n\nExercise\n\n\nImplement a parametric type for rational numbers.\n\n\n\n\n\n\n\n\n\nSolution\n\n\nstruct Rational{T&lt;:Integer} &lt;: Real\n    num::T\n    den::T\nend"
  },
  {
    "objectID": "NumLinAlg/julias_type_system-slides.html#arrays",
    "href": "NumLinAlg/julias_type_system-slides.html#arrays",
    "title": "Julias Type System",
    "section": "Arrays",
    "text": "Arrays\nArrays are data structures that allow random access to elements. Arrays often represent vectors and matrices. Julia has built-in support for arrays, with indexing and slicing syntax similar to Python or MATLAB. A (column)-vector in Julia can be constructed directly using square brackets and a comma (or semicolon) as separators.\njulia&gt; v = [4, 8, 15, 16, 23, 42]\n6-element Vector{Int64}:\n  4\n  8\n 15\n 16\n 23\n 42\n\nThere are built-in functions for constructing common matrices:\n\nJuliaPython\n\n\njulia&gt; zeros(Int8, (2, 3))\n2×3 Matrix{Int8}:\n 0  0  0\n 0  0  0\n\njulia&gt; A = rand(2, 2)\n×2 Matrix{Float64}:\n0.380141  0.81997\n0.93474   0.0321379\n\njulia&gt; Matrix{Float64}(I, 3, 3)\n3×3 Matrix{Float64}:\n 1.0  0.0  0.0\n 0.0  1.0  0.0\n 0.0  0.0  1.0\n\n\n&gt;&gt;&gt; A = np.zeros( (2, 3), dtype=int)\narray([[0, 0, 0],\n       [0, 0, 0]])\n\n&gt;&gt;&gt; np.random.rand( 2, 2)\narray([[0.46581219, 0.93757536],\n       [0.97690228, 0.72186734]])\n\n&gt;&gt;&gt; np.identity(3)\narray([[1., 0., 0.],\n       [0., 1., 0.],\n       [0., 0., 1.]])\n\n\n\n\n\nNote that ranges in Julia are closed, i.e. they include the endpoint.\n\nJuliaPython\n\n\njulia&gt; collect(range(1, 5))\n1:5\n\njulia&gt; range(0, 2*pi, length=10)\n0.0:0.6981317007977318:6.283185307179586\n\n\n&gt;&gt;&gt; np.arange(0, 5)\narray([0, 1, 2, 3, 4])\n&gt;&gt;&gt; np.linspace(0, 2*np.pi, num=10, endpoint=True)\narray([0.        , 0.6981317 , 1.3962634 , 2.0943951 , 2.7925268 ,\n       3.4906585 , 4.1887902 , 4.88692191, 5.58505361, 6.28318531])\n\n\n\n\n\nYou can basic information about the data type, dimension and size of the matrix:\n\nJuliaPython\n\n\njulia&gt; eltype(A)\nFloat64\n\njulia&gt; ndims(A)\n2\n\njulia&gt; size(A)\n(2, 2)\n\njulia&gt; length(A)\n4\n\n\n&gt;&gt;&gt; A.dtype\ndtype('int64')\n&gt;&gt;&gt; A.ndim\n2\n&gt;&gt;&gt; A.shape\n(2, 3)\n&gt;&gt;&gt; A.size\n6"
  },
  {
    "objectID": "NumLinAlg/julias_type_system-slides.html#constructors",
    "href": "NumLinAlg/julias_type_system-slides.html#constructors",
    "title": "Julias Type System",
    "section": "Constructors",
    "text": "Constructors\nConstructors are functions that create new instances of composite types. When a user defines a new composite type, Julia creates the default constructors. However, in some cases constructors need additional functionality, for example to enforce constraints (called invariants) through argument checking or transformation.\nHere’s a simple example illustrating the use of constructors in Julia:\nstruct Rectangle{T &lt;: Real}\n   width::T\n   height::T\n\n   # Inner constructor\n   function Rectangle(width::Real, height::Real)\n       @assert width &gt;= 0 \"Width must be non-negative!\"\n       @assert height &gt;= 0 \"Height must be non-negative!\"\n       promoted_type = promote_type(typeof(width), typeof(height))\n       new{promoted_type}(width, height)\n   end\n\n   # Default Constructor\n   Rectangle() = Rectangle(1.0, 1.0)\nend\n\nThat way, you can construct a Rectangle via\nrect1 = Rectangle(5.0, 3.0)     # Float64\nrect2 = Rectangle(5, 3)         # Int64\nrect3 = Rectangle(5.0, 3)       # Float64 (via type promotion)\nrect4 = Rectangle()             # default: Float64\nbut calling it with negative arguments results in an error:\nrect = Rectangle(5.0, -3.0)    # error"
  },
  {
    "objectID": "NumLinAlg/julias_type_system-slides.html#method-overloading",
    "href": "NumLinAlg/julias_type_system-slides.html#method-overloading",
    "title": "Julias Type System",
    "section": "Method Overloading",
    "text": "Method Overloading\nA function in Julia can consist of multiple methods. When a user calls a function, the method that is actually executed depends on the type and number of arguments. This is very similar to function overloading in C++.\n\nJuliaC++\n\n\njulia&gt; f(x::Float64, y::Float64) = 2x - y\nf (generic function with 2 methods)\n\njulia&gt; f(x::Int64, y::Int64) = 2x - y\nf (generic function with 2 methods)\n\n\ndouble f(double x, double y) {\n    return 2*x - y;\n}\n\nlong f(long x, long y) {\n    return 2*x - y;\n}\n\n\n\n\nYou can use the methods function to get a list of the methods for a given function.\njulia&gt; methods(f)\n# 2 methods for generic function \"f\" from Main:\n [1] f(x::Int64, y::Int64)\n     @ REPL[5]:1\n [2] f(x::Float64, y::Float64)\n     @ REPL[4]:1"
  },
  {
    "objectID": "NumLinAlg/julias_type_system-slides.html#polymorphism",
    "href": "NumLinAlg/julias_type_system-slides.html#polymorphism",
    "title": "Julias Type System",
    "section": "Polymorphism",
    "text": "Polymorphism\nIn order to understand Multiple Dispatch, we first need to talk about Polymorphism.\n\nPolymorphism, meaning “many forms,” is a fundamental concept in object-oriented programming (OOP) that allows objects of different classes to be treated as objects of a common type. It enables you to design code that is more flexible, extensible, and reusable.\n\n\n\nC++C#\n\n\n#include &lt;vector&gt;\n#include &lt;iostream&gt;\n#include &lt;memory&gt;\n\nclass Animal {\n  public:\n    virtual void sound() const {\n      std::cout &lt;&lt; \"FALLBACK\\n\" &lt;&lt; std::endl;\n    }\n    virtual ~Animal() = default;\n};\n\nclass Dog : public Animal {\n  public:\n    void sound() const override {\n      std::cout &lt;&lt; \"bark\\n\";\n    }\n};\n\nclass Cat : public Animal {\n  public:\n    void sound() const override {\n      std::cout &lt;&lt; \"miau\\n\";\n    }\n};\n\n\n\nint main()\n{\n  auto ein = std::make_unique&lt;Dog&gt;();\n  auto sphinx = std::make_unique&lt;Cat&gt;();\n\n  ein-&gt;sound();\n  sphinx-&gt;sound();\n}\n\n\nusing System;\n\npublic class Animal\n{\n  public virtual void Sound()\n  {\n    Console.WriteLine(\"FALLBACK\");\n  }\n}\n\npublic class Dog : Animal\n{\n  public override void Sound()\n  {\n    Console.WriteLine(\"bark\");\n  }\n}\n\npublic class Cat : Animal\n{\n  public override void Sound()\n  {\n    Console.WriteLine(\"miau\");\n  }\n}\n\npublic class Program\n{\n  public static void Main(string[] args)\n  {\n    Animal ein = new Dog();\n    Animal sphinx = new Cat();\n\n    ein.Sound();\n    sphinx.Sound();\n  }\n}\n\n\n\nAs Julia is not an object-oriented language, the only way to achieve something similar is as follows:\nabstract type Animal end\nstruct Cat &lt;: Animal end\nstruct Dog &lt;: Animal end\nstruct Bird &lt;: Animal end\n\nmake_sound(cat::Cat) = println(\"miau!\")\nmake_sound(dog::Dog) = println(\"wuff!\")\nmake_sound(bird::Bird) = println(\"chierp!\")\n\nein = Dog()\nshinx = Cat()\n\nmake_sound(ein)\nmake_sound(cat)\nThis isn’t very spectacular yet; it looks like normal operator overloading. Things get more interesting when the functions have more arguments."
  },
  {
    "objectID": "NumLinAlg/julias_type_system-slides.html#multiple-dispatch",
    "href": "NumLinAlg/julias_type_system-slides.html#multiple-dispatch",
    "title": "Julias Type System",
    "section": "Multiple Dispatch",
    "text": "Multiple Dispatch\nMulti-dispatch is the ability to choose which version of a function to call based on the runtime type of all arguments passed to the function call.\n\nJuliaC++\n\n\nabstract type Pet end\nstruct Dog &lt;: Pet; name::String end\nstruct Cat &lt;: Pet; name::String end\n\nfunction encounter(a::Pet, b::Pet)\n    verb = meets(a, b)\n    println(\"$(a.name) meets $(b.name) and $verb\")\nend\n\nmeets(a::Dog, b::Dog) = \"sniffs\"\nmeets(a::Dog, b::Cat) = \"chases\"\nmeets(a::Cat, b::Dog) = \"hisses\"\nmeets(a::Cat, b::Cat) = \"slinks\"\n\nfido = Dog(\"Fido\")\nrex = Dog(\"Rex\")\nwhiskers = Cat(\"Whiskers\")\nspots = Cat(\"Spots\")\n\nencounter(fido, rex)\nencounter(fido, whiskers)\nencounter(whiskers, rex)\nencounter(whiskers, spots)\nFido meets Rex and sniffs\nFido meets Whiskers and chases\nWhiskers meets Rex and hisses\nWhiskers meets Spots and slinks\n\n\n#include &lt;iostream&gt;\n#include &lt;string&gt;\n\nclass Pet {\n    public:\n        std::string name{};\n};\n\nclass Dog : public Pet{};\nclass Cat : public Pet{};\n\nstd::string meets(Dog a, Dog b) { return \"sniffs\"; }\nstd::string meets(Dog a, Cat b) { return \"chases\"; }\nstd::string meets(Cat a, Dog b) { return \"hisses\"; }\nstd::string meets(Cat a, Cat b) { return \"slinks\"; }\n\nstd::string meets(Pet a, Pet b) {\n    return \"FALLBACK\";\n}\n\nvoid encounter(Pet a, Pet b) {\n    auto verb = meets(a, b);\n    std::cout &lt;&lt; a.name &lt;&lt; \" meets \"\n        &lt;&lt; b.name &lt;&lt; \" and \" &lt;&lt; verb &lt;&lt; std::endl;\n}\n\nint main() {\n    Dog fido{\"Fido\"};\n    Dog rex{\"Rex\"};\n    Cat whiskers{\"whiskers\"};\n    Cat spots{\"spots\"};\n\n    encounter(fido, rex);\n    encounter(fido, whiskers);\n    encounter(whiskers, rex);\n    encounter(whiskers, spots);\n}\nFido meets Rex and FALLBACK\nFido meets whiskers and FALLBACK\nwhiskers meets Rex and FALLBACK\nwhiskers meets spots and FALLBACK\n\n\n\nDoing something like this in C++ is not possible.\n\nSee also:\n\nThe Unreasonable Effectiveness of Multiple Dispatch by Stefan Karpinski, JuliaCon 2019\nMultiple Dispatch in C++ on StackOverflow\nA polyglot’s guide to multiple dispatch by Eli Bendersky (permalink)"
  },
  {
    "objectID": "NumLinAlg/julias_type_system-slides.html#functional-programming",
    "href": "NumLinAlg/julias_type_system-slides.html#functional-programming",
    "title": "Julias Type System",
    "section": "Functional Programming",
    "text": "Functional Programming\nFunctional programming is a programming paradigm where programs are constructed by applying and composing functions. It’s a declarative style of programming, meaning you describe what you want to achieve rather than how to achieve it (which is more typical of imperative programming)\n\nThe core concepts and characteristics of functional programming are as follows:\n\nFunctions are first-class objects, meaning they can be passed around and stored like variables.\nHigher order functions: functions can take other functions as arguments, or return a function as a result\nImmutability: Data, once created, cannot be changed. Instead of modifying existing data structures, you create new ones with the desired changes.\nDeclarative style programming: Using map, filter and reduce instead of for loops to iterate over an array."
  },
  {
    "objectID": "NumLinAlg/julias_type_system-slides.html#todo",
    "href": "NumLinAlg/julias_type_system-slides.html#todo",
    "title": "Julias Type System",
    "section": "TODO:",
    "text": "TODO:\n\nConstructors\nMethod overloading\nPolymorphism, Multiple Dispatch\nFunctional Programming (map, reduce; …)\nExample for FP vs OOP: normal distribution\nSets\nDictionaries\nDifference Arrays vs. Tuples (named tuples as intro to DataFrames)"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "I like math."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Mavoorts Notes",
    "section": "",
    "text": "Welcome to my Blog!\nThis site is currently under construction. I plan to write regular posts about applied mathematics."
  },
  {
    "objectID": "NumLinAlg/julia_basics-slides.html#why-julia",
    "href": "NumLinAlg/julia_basics-slides.html#why-julia",
    "title": "Julia Basics",
    "section": "Why Julia?",
    "text": "Why Julia?\n\n\n\n\n\n\nJulia Logo \nauthor: Stefan Karpinski\nsource: github.com\nlicense: CC BY-NC-SA 4.0\n\n\n\n\n \n\n\nJulia is a modern programming language that is commonly used for numerical analysis and scientific computing. It combines the speed of languages like C++ or Fortran with the ease of use of Matlab or Python. This is because Julia was designed to solve the “two-language problem”: A lot of software is often developed in a dynamic language like Python and then re-implemented in a statically typed language for better performance. With Julia, you get the best of both worlds:\n\nJulia walks like Python, and runs like C++."
  },
  {
    "objectID": "NumLinAlg/julia_basics-slides.html#literature",
    "href": "NumLinAlg/julia_basics-slides.html#literature",
    "title": "Julia Basics",
    "section": "Literature",
    "text": "Literature"
  },
  {
    "objectID": "NumLinAlg/julia_basics-slides.html#getting-started",
    "href": "NumLinAlg/julia_basics-slides.html#getting-started",
    "title": "Julia Basics",
    "section": "Getting Started",
    "text": "Getting Started\nLet’s start with a simple hello-world. The print function works exactly like it does in Python:\nprint(\"Hello World!\")\nprint(\"The answer is \", 42)\nThere is also the println() command, which is exactly the same except that it ends with a newline character.\nprintln(\"Hello World!\")"
  },
  {
    "objectID": "NumLinAlg/julia_basics-slides.html#basic-math",
    "href": "NumLinAlg/julia_basics-slides.html#basic-math",
    "title": "Julia Basics",
    "section": "Basic Math",
    "text": "Basic Math\nOf course, you can use Julia like a calculator:\njulia&gt; 5 + 3\n8\n\njulia&gt; 4 * 5\n20\n\njulia&gt; 0.5 * (4 + 7)\n5.5\n\nNote that division implicitly converts the input into float; if you want to do integer division, use div(n, m).\n\nJuliaPython\n\n\njulia&gt; 11 / 7\n1.5714285714285714\n\njulia&gt; div(11, 7)\n1\n\n\n&gt;&gt;&gt; 11 / 7\n1.5714285714285714\n\n&gt;&gt;&gt; 11 // 7\n1\n\n\n\n\n\nTo calculate the power of a number, use the ^ operator (similar to Matlab):\n\nJuliaMatlabPython\n\n\njulia&gt; 2^4\n16\n\n\n&gt;&gt; 2^4\n16\n\n\n&gt;&gt;&gt; 2**4\n16"
  },
  {
    "objectID": "NumLinAlg/julia_basics-slides.html#dynamic-binding",
    "href": "NumLinAlg/julia_basics-slides.html#dynamic-binding",
    "title": "Julia Basics",
    "section": "Dynamic Binding",
    "text": "Dynamic Binding\nLike Python, Julia is a dynamically typed language. This means that variables do not have a fixed data type like in C++, but can point to different data via dynamic binding.\nConsider two variables, x and y. After assigning y to x, both variables point to the same memory location; no data is being copied.\n\nDynamic Variable Binding\nThis figure was created with draw.io and is hereby licensed under Public Domain (CC0 1.0)"
  },
  {
    "objectID": "NumLinAlg/julia_basics-slides.html#numbers-in-julia",
    "href": "NumLinAlg/julia_basics-slides.html#numbers-in-julia",
    "title": "Julia Basics",
    "section": "Numbers in Julia",
    "text": "Numbers in Julia\nYou can see the type of a variable with the typeof() operator:\n\nJuliaPythonMATLAB\n\n\njulia&gt; x = 42\n42\n\njulia&gt; typeof(x)\nInt64\n\njulia&gt; typeof(3.7)\nFloat64\n\n\n&gt;&gt;&gt; x = 42\n&gt;&gt;&gt; type(x)\n&lt;class 'int'&gt;\n&gt;&gt;&gt; type(3.7)\n&lt;class 'float'&gt;\n\n\n&gt;&gt; x = int64(42)\nx = 42\n&gt;&gt; y = 3.7\ny =              3.7\n&gt;&gt; whos\nVariables visible from the current scope:\n\nvariables in scope: top scope\n\n  Attr   Name        Size                     Bytes  Class\n  ====   ====        ====                     =====  ===== \n         x           1x1                          8  int64\n         y           1x1                          8  double\n\nTotal is 2 elements using 16 bytes\n\n\n\n\nJulia uses 64 bits for integers and floats by default. Other types available are:\nInt8, Int16, Int32, Int64, Int128, BigInt\nUInt8, UInt16, UInt32, UInt64, UInt128\nFloat16, Float32, Float64, BigFloat\n\n\nTo define a variable of a given size, use x = int16(100). For example, to define an integer of arbitrary length, use\nx = BigInt(1606938044258990275541962092341162602522202993782792835301376)\n\n\nAs specified in the IEEE754 standard, floating point numbers support inf and NaN values.\n\nJuliaPythonMATLAB\n\n\njulia&gt; -5 / 0\n-Inf\n\njulia&gt; 0 * Inf\nNaN\n\njulia&gt; NaN == NaN\nfalse\n\n\n&gt;&gt;&gt; -5 / 0\nTraceback (most recent call last):\n  File \"&lt;input&gt;\", line 1, in &lt;module&gt;\n    -5 / 0\n     ~~~^~~\nZeroDivisionError: division by zero\n&gt;&gt;&gt; 0 * np.Inf\nnan\n&gt;&gt;&gt; np.nan == np.nan\nFalse\n\n\n&gt;&gt; -5 / 0\nans =             -Inf\n&gt;&gt; 0 * Inf\nans =              NaN\n&gt;&gt; NaN == NaN\nans = 0\n\n\n\n\n\nFloating point numbers can only be approximated, so a direct comparison using a==b may give unexpected results:\n\nJuliaPythonMATLAB\n\n\njulia&gt; 0.2 + 0.1 == 0.3\nfalse\n\njulia&gt; 0.2 + 0.1\n0.30000000000000004\n\n\n&gt;&gt;&gt; 0.2 + 0.1 == 0.3\nFalse\n&gt;&gt;&gt; 0.2 + 0.1\n0.30000000000000004\n\n\n&gt;&gt; 0.2 + 0.1 == 0.3\nans = 0\n&gt;&gt; 0.2 + 0.1\nans =              0.3\n\n\n\nThis is a general problem with floating point numbers, and exists in other programming languages as well.\n\n\nThe machine precision can be obtained with eps(), which gives the distance between 1.0 and the next larger representable floating-point value:\n\nJuliaMATLAB\n\n\njulia&gt; eps(Float64)\n2.220446049250313e-16\n\n\n&gt;&gt; eps\nans = 2.220446049250313e-16\n\n\n\n\n\nUsing that, we can implement a function isapprox(a, b) to test whether to numbers are approximately equal:\nfunction isapprox(x::Real, y::Real; atol::Real=1e-14, rtol::Real=10*eps())\n        return abs(x - y) &lt;= atol + rtol * max(abs(x), abs(y))\nend\n\n\nFortunately, such a function already exists in the standard library:\n\nJuliaPython\n\n\njulia&gt; isapprox(0.2 + 0.1, 0.3)\ntrue\n\njulia&gt; 0.2 + 0.1 ≈ 0.3\ntrue\n\n\n&gt;&gt;&gt; np.allclose(0.2 + 0.1, 0.3)\nTrue"
  },
  {
    "objectID": "NumLinAlg/julia_basics-slides.html#control-flow",
    "href": "NumLinAlg/julia_basics-slides.html#control-flow",
    "title": "Julia Basics",
    "section": "Control Flow",
    "text": "Control Flow\nControl structures such as branches and loops are easy to implement in Julia; the syntax is very similar to MATLAB:\n\nJuliaMATLABPythonC++\n\n\nif x &gt; 0\n  println(\"x is positive\")\nelseif x &lt; 0\n  println(\"x is negative\")\nelse \n  println(\"x is zero\")\nend\n\n\nif x &gt; 0\n  disp(\"x is positive\")\nelseif x &lt; 0\n  disp(\"x is negative\")\nelse\n  disp(\"x is zero\")\nend\n\n\nif x &gt; 0:\n    print(\"x is positive\")\nelif x &lt; 0:\n    print(\"x is negative\")\nelse:\n    print(\"x is zero\")\n\n\nif (x &gt; 0) {\n  std::println(\"x is positive\");\n} else if (x &lt; 0) {\n  std::println(\"x is negative\");\n} else {\n  std::println(\"x is zero\");\n}\n\n\n\n\nJust as in C++, Julia supports the ternary if statement:\n\nJuliaC++\n\n\nprintln(x &lt; y ? \"less than\" : \"greater or equal\")\n\n\nstd::println(x &lt; y ? \"less than\" : \"not less than\");\n\n\n\n\n\nMultiple logical conditions can be combined with basic comparison operators:\nA && B    # A and B\nA || B    # A or B\nA != B    # A XOR B\n\n\nOf course, logical operations do short-circuit evaluation:\n\nJuliaPythonMATLAB\n\n\njulia&gt; n = 2;\n\njulia&gt; n == 1 && println(\"n is one\")\nfalse\n\n\n&gt;&gt;&gt; n = 2\n&gt;&gt;&gt; n == 1 and print(\"n is one\")\nFalse\n\n\n&gt;&gt; n = 2;\n&gt;&gt; n == 1 && disp(\"n is one\")\nans = 0"
  },
  {
    "objectID": "NumLinAlg/julia_basics-slides.html#functions",
    "href": "NumLinAlg/julia_basics-slides.html#functions",
    "title": "Julia Basics",
    "section": "Functions",
    "text": "Functions\nSimple functions can be defined via:\n\nJuliaPythonC++\n\n\nf(x) = x^2\n\n\nf = lambda x: x**2\n\n\nauto f = [](auto x){ return x*x; };\n\n\n\n\nMore advanced functions are defined using the function keyword:\n\nJuliaPython\n\n\nfunction fac(n::Integer)\n  @assert n &gt; 0 \"n must be positive\"\n\n  if n ≤ 1\n    return 1\n  else\n    return n * fac(n-1)\n  end\nend\n\n\ndef fac(n: int) -&gt; int:\n    assert n &gt; 0, \"n must be positive!\"\n\n    if (n &lt;= 1):\n        return 1\n    else:\n        return n * fac(n - 1)\n\n\n\nNote that we use the @assert macro to ensure that the arguments are positive.\n\n\nFunctions can be applied element-wise to arrays using the dot notation, f.(x):\n\nJuliaPythonMATLAB\n\n\njulia&gt; x = [0, 1, 2, 3, 4, 5];\njulia&gt; f(x) = x^2;\njulia&gt; f.(x)\n6-element Vector{Int64}:\n  0\n  1\n  4\n  9\n 16\n 25\n\n\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; x = np.array([-11, 1, 2, 3, 4, 5])\n&gt;&gt;&gt; f = lambda x: x**2\n&gt;&gt;&gt; f(x)\narray([ 0,  1,  4,  9, 16, 25])\n\n\n&gt;&gt; x = [0, 1, 2, 3, 4, 5];\n&gt;&gt; f = @(x) x.^2\nf =\n\n@(x) x .^ 2\n\n&gt;&gt; f(x)\nans = 0   1   4   9   16    25\n\n\n\n\n\nThe same can be achieved with the map(f, arr) function:\njulia&gt; map(f, x)\n6-element Vector{Int64}:\n  0\n  1\n  4\n  9\n 16\n 25\n\n\nThe advantage of the map command is that it can also be applied to anonymous functions:\njulia&gt; map(x -&gt; x^2, [0, 1, 2, 3, 4, 5])\n6-element Vector{Int64}:\n  0\n  1\n  4\n  9\n 16\n 25"
  },
  {
    "objectID": "NumLinAlg/julia_basics-slides.html#strings",
    "href": "NumLinAlg/julia_basics-slides.html#strings",
    "title": "Julia Basics",
    "section": "Strings",
    "text": "Strings\nOne can think of a String as an array of characters with some convenience functions. Julia supports Unicode characters via the UTF-8 encoding.\n\nAs in Java and Python, strings are immutable. The value of a string object cannot be changed.\njulia&gt; name = \"Markus\"\n\"Markus\"\n\njulia&gt; pointer_from_objref(name)\nPtr{Nothing} @0x000072d21dee95b8\n\njulia&gt; name = \"Aurelius\"\n\"Aurelius\"\n\njulia&gt; pointer_from_objref(name)\nPtr{Nothing} @0x000072d21deea6c8\n\n\nTo change a character in a string, you have to first convert the string to an array, modify the desired character, and then join the array back into a string:\n\nJuliaPython\n\n\nstr = \"hello world\"\nchars = collect(str)\nchars[6] = '_'\nnew_str = join(chars)  # hello_world\n\n\nstr = \"hello world\"\nchar_list = list(str)\nchar_list[5] = '_'\nnew_str = ''.join(char_list)\nprint(new_str)  # hello_world"
  },
  {
    "objectID": "NumLinAlg/julia_basics-slides.html#pretty-output",
    "href": "NumLinAlg/julia_basics-slides.html#pretty-output",
    "title": "Julia Basics",
    "section": "Pretty Output",
    "text": "Pretty Output"
  },
  {
    "objectID": "NumLinAlg/julia_basics-slides.html#symbols",
    "href": "NumLinAlg/julia_basics-slides.html#symbols",
    "title": "Julia Basics",
    "section": "Symbols",
    "text": "Symbols\nSymbols are a special type of immutable data that represent identifiers or names. They are denoted by a colon (:) followed by the name, such as :example.\nThe advantage of symbols over strings is that they offer very efficient comparisons:\njulia&gt; @btime \"abcd\" == \"abcd\"\n  5.632 ns (0 allocations: 0 bytes)\ntrue\n\njulia&gt; @btime :abcd == :abcd\n  0.025 ns (0 allocations: 0 bytes)\ntrue\nIn this sense, symbols are very similar to enums, except that they do not provide type safety: all symbols are of type “symbol”, whereas enums have their own distinct types.\nSymbols are also used for meta-programming, which we will learn more about later."
  },
  {
    "objectID": "NumLinAlg/julia_basics-slides.html#fixed-width-strings",
    "href": "NumLinAlg/julia_basics-slides.html#fixed-width-strings",
    "title": "Julia Basics",
    "section": "Fixed-width Strings",
    "text": "Fixed-width Strings\nIn many data science applications we have to deal with strings that are only a few characters long. For example, city names are usually very short, and country codes are only two characters long.\nFor better performance, it is advantageous to store such data using a fixed-width string. This can be done using the InlineStrings.jl package, which provides eight fixed-width string types of up to 255 bytes.\njulia&gt; using InlineStrings\n\njulia&gt; country = InlineString(\"South-Korea\")\n\"South-Korea\"\n\njulia&gt; typeof(country)\nString15\nTODO: Move this to chapter 5."
  },
  {
    "objectID": "NumLinAlg/julia_basics-slides.html#annotated-strings",
    "href": "NumLinAlg/julia_basics-slides.html#annotated-strings",
    "title": "Julia Basics",
    "section": "Annotated Strings",
    "text": "Annotated Strings\nIs is possible to store additional information inside a string by\njulia&gt; printstyled(\"WARNING!\", color=:red, bold=true, blink=true)\nWARNING!\n\njulia&gt; str = styled\"{green:Avocados} are {bold:green}\"\n\"Avocados are green\""
  },
  {
    "objectID": "NumLinAlg/julia_basics-slides.html#references",
    "href": "NumLinAlg/julia_basics-slides.html#references",
    "title": "Julia Basics",
    "section": "References",
    "text": "References\n\n\nEngheim, Erik. 2023. Julia as a Second Language. Manning Publ.\n\n\nKamiński, Bogumił. 2022. Julia for Data Analysis. Manning Publ.\n\n\nLauwens, Ben, and Allen B. Downey. 2019. Think Julia. O’Reilly Media. https://benlauwens.github.io/ThinkJulia.jl/latest/book.\n\n\nStoropoli, Jose, Rik Huijzer, and Lazaro Alonso. 2021. Julia Data Science. https://juliadatascience.io."
  },
  {
    "objectID": "NumLinAlg/julia_basics.html",
    "href": "NumLinAlg/julia_basics.html",
    "title": "Julia Basics",
    "section": "",
    "text": "Julia Logo \nauthor: Stefan Karpinski\nsource: github.com\nlicense: CC BY-NC-SA 4.0\n\n\n\n\n \n\n\nJulia is a modern programming language that is commonly used for numerical analysis and scientific computing. It combines the speed of languages like C++ or Fortran with the ease of use of Matlab or Python. This is because Julia was designed to solve the “two-language problem”: A lot of software is often developed in a dynamic language like Python and then re-implemented in a statically typed language for better performance. With Julia, you get the best of both worlds:\n\nJulia walks like Python, and runs like C++.",
    "crumbs": [
      "About me",
      "Numerical Linear Algebra",
      "Julia Basics"
    ]
  },
  {
    "objectID": "NumLinAlg/julia_basics.html#why-julia",
    "href": "NumLinAlg/julia_basics.html#why-julia",
    "title": "Julia Basics",
    "section": "",
    "text": "Julia Logo \nauthor: Stefan Karpinski\nsource: github.com\nlicense: CC BY-NC-SA 4.0\n\n\n\n\n \n\n\nJulia is a modern programming language that is commonly used for numerical analysis and scientific computing. It combines the speed of languages like C++ or Fortran with the ease of use of Matlab or Python. This is because Julia was designed to solve the “two-language problem”: A lot of software is often developed in a dynamic language like Python and then re-implemented in a statically typed language for better performance. With Julia, you get the best of both worlds:\n\nJulia walks like Python, and runs like C++.",
    "crumbs": [
      "About me",
      "Numerical Linear Algebra",
      "Julia Basics"
    ]
  },
  {
    "objectID": "NumLinAlg/julia_basics.html#literature",
    "href": "NumLinAlg/julia_basics.html#literature",
    "title": "Julia Basics",
    "section": "Literature",
    "text": "Literature\n\nRecommended Textbooks\nJulia is still a relatively new programming language, so there are few good books about it, and most of them are completely out of date. However, I can recommend the books “Julia as a Second Language” and “Julia for Data Analysis”, both of which give a really good introduction to Julia programming. The latter also has a large chapter on dataframes, which is definitely useful in data science. The book “Think Julia” also seems to be good, although a little less comprehensive.\n\n\n\n\n\n\n\n[1]\n\n\n\n\n\n \n\n\n\n\n\n\n[2]\n\n\n\n\n\n \n\n\n\n\n\n\n[3]\n\n\n\n\n\n \n\n\n\n\n\n\n[4]\n\n\n\n\n\n\nThe best resources for learning Julia is definitely the Official Documentation, which is freely available on the Internet. Another course that is really really great is Julia for Optimization and Learning by the university of Prague. It gives a good introduction to Julia with examples from optimization and machine learning.\nThere is also a free Course on Coursera that should be mentioned. However, since I haven’t taken it, I can’t say whether it’s good or bad. It’s kinda okay; not good, not bad.\n\n\nOther Resources:\n\nOfficial Documentation\nCourse Julia for Optimization and Learning by the University of Prague\nQuantitative Economics with Julia by Jesse Perla, Thomas J. Sargent, and John Stachurski\nLecture Computational Thinking, MIT 18.S191/6.S083\nIntroducing Julia on WikiBooks\n\n\n\n\n\n\n\n\nWarning\n\n\n\nThis course is fairly fast-paced.\nIt is assumed that the reader is already familiar with a programming language such as MATLAB, Python or C++.\n\n\nI will be making comparisons to these languages throughout the course.",
    "crumbs": [
      "About me",
      "Numerical Linear Algebra",
      "Julia Basics"
    ]
  },
  {
    "objectID": "NumLinAlg/julia_basics.html#getting-started",
    "href": "NumLinAlg/julia_basics.html#getting-started",
    "title": "Julia Basics",
    "section": "Getting Started",
    "text": "Getting Started\nLet’s start with a simple hello-world. The print function works exactly like it does in Python:\nprint(\"Hello World!\")\nprint(\"The answer is \", 42)\nThere is also the println() command, which is exactly the same except that it ends with a newline character.\nprintln(\"Hello World!\")",
    "crumbs": [
      "About me",
      "Numerical Linear Algebra",
      "Julia Basics"
    ]
  },
  {
    "objectID": "NumLinAlg/julia_basics.html#basic-math",
    "href": "NumLinAlg/julia_basics.html#basic-math",
    "title": "Julia Basics",
    "section": "Basic Math",
    "text": "Basic Math\nOf course, you can use Julia like a calculator:\njulia&gt; 5 + 3\n8\n\njulia&gt; 4 * 5\n20\n\njulia&gt; 0.5 * (4 + 7)\n5.5\n. . .\nNote that division implicitly converts the input into float; if you want to do integer division, use div(n, m).\n\nJuliaPython\n\n\njulia&gt; 11 / 7\n1.5714285714285714\n\njulia&gt; div(11, 7)\n1\n\n\n&gt;&gt;&gt; 11 / 7\n1.5714285714285714\n\n&gt;&gt;&gt; 11 // 7\n1\n\n\n\n. . .\nTo calculate the power of a number, use the ^ operator (similar to Matlab):\n\nJuliaMatlabPython\n\n\njulia&gt; 2^4\n16\n\n\n&gt;&gt; 2^4\n16\n\n\n&gt;&gt;&gt; 2**4\n16\n\n\n\n\nJulia provides a very flexible system for naming variables. In the Julia REPL, you can write mathematical symbols and other characters with a tab; for example, the Greek letter π can be typed via \\pi&lt;TAB&gt;.\nThis makes it possible to translate mathematical formulas into code in a very elegant way.\njulia&gt; sin(π) ≠ 1/2\ntrue\n\njulia&gt; √25\n5.0\n\nThere are alot of built-in math functions:\n\nJuliaMatlabPython\n\n\njulia&gt; cos(pi)\n-1.0\n\njulia&gt; sqrt(25)\n5.0\n\njulia&gt; exp(3)\n20.085536923187668\n\njulia&gt; rand()\n0.8421147919589432\n\n\n&gt;&gt; cos(pi)\nans =               -1\n\n&gt;&gt; sqrt(25)\nans =                5\n\n&gt;&gt; exp(3)\nans = 20.08553692318767\n\n&gt;&gt; rand()\nans = 0.2162824594661559\n\n\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; np.cos(np.pi)\n-1.0\n\n&gt;&gt;&gt; np.sqrt(25)\n5.0\n\n&gt;&gt;&gt; np.exp(3)\n20.085536923187668\n\n&gt;&gt;&gt; np.random.rand()\n0.8839348951868577\n\n\n\n. . .\nYou might be wondering what happens when you try to overwrite a built-in function or symbol:\njulia&gt; pi\nπ = 3.1415926535897...\n\njulia&gt; pi = 3\nERROR: cannot assign a value to imported variable Base.pi from module Main\n\njulia&gt; sqrt(100)\n10.0\n\njulia&gt; sqrt = 4\nERROR: cannot assign a value to imported variable Base.sqrt from module Main",
    "crumbs": [
      "About me",
      "Numerical Linear Algebra",
      "Julia Basics"
    ]
  },
  {
    "objectID": "NumLinAlg/julia_basics.html#dynamic-binding",
    "href": "NumLinAlg/julia_basics.html#dynamic-binding",
    "title": "Julia Basics",
    "section": "Dynamic Binding",
    "text": "Dynamic Binding\nLike Python, Julia is a dynamically typed language. This means that variables do not have a fixed data type like in C++, but can point to different data via dynamic binding.\nConsider two variables, x and y. After assigning y to x, both variables point to the same memory location; no data is being copied.\n\n\n\nDynamic Variable Binding\nThis figure was created with draw.io and is hereby licensed under Public Domain (CC0 1.0)\n\n\n\nIn Python you can use the id() operator to see what’s actually going on:\n\nPythonC++\n\n\n&gt;&gt;&gt; x = 42\n&gt;&gt;&gt; y = 3.7\n&gt;&gt;&gt; id(x)\n11755208\n&gt;&gt;&gt; id(y)\n134427599166672\n&gt;&gt;&gt; x = y\n&gt;&gt;&gt; x\n3.7\n&gt;&gt;&gt; id(x)\n134427599166672\n\n\nint x = 42;\nstd::string str = \"Hello!\";\nx = str;    // Compile error!\n\n\n\nAs you can see, after the assignment, both variables have the same memory address. Something like that would not be possible in C++.1\n\nThis distinction may seem trivial, but has some important implications when dealing with mutable types, whose contents can be changed:\n\nJuliaPython\n\n\na = [1, 2, 3]\nb = a\na[2] = 42\njulia&gt; b\n3-element Vector{Int64}:\n  1\n 42\n  3\n\n\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; a = np.array([1, 2, 3])\n&gt;&gt;&gt; b = a\n&gt;&gt;&gt; a[1] = 42\n&gt;&gt;&gt; b\narray([ 1, 42,  3])\n\n\n\n. . .\nAs no copy is being made, any change to variable a will also affect variable b. To actually make a deep copy, use the deepcopy() command2:\n\nJuliaPython\n\n\nb = deepcopy(a)\n\n\nb = a.copy()\n\n\n\n. . .\n\n\n\n\n\n\nWarning\n\n\n\nFor performance reasons, avoid binding values of different types to the same variable.\nCode that avoids changing the type of a variable is called type stable.",
    "crumbs": [
      "About me",
      "Numerical Linear Algebra",
      "Julia Basics"
    ]
  },
  {
    "objectID": "NumLinAlg/julia_basics.html#numbers-in-julia",
    "href": "NumLinAlg/julia_basics.html#numbers-in-julia",
    "title": "Julia Basics",
    "section": "Numbers in Julia",
    "text": "Numbers in Julia\nYou can see the type of a variable with the typeof() operator:\n\nJuliaPythonMATLAB\n\n\njulia&gt; x = 42\n42\n\njulia&gt; typeof(x)\nInt64\n\njulia&gt; typeof(3.7)\nFloat64\n\n\n&gt;&gt;&gt; x = 42\n&gt;&gt;&gt; type(x)\n&lt;class 'int'&gt;\n&gt;&gt;&gt; type(3.7)\n&lt;class 'float'&gt;\n\n\n&gt;&gt; x = int64(42)\nx = 42\n&gt;&gt; y = 3.7\ny =              3.7\n&gt;&gt; whos\nVariables visible from the current scope:\n\nvariables in scope: top scope\n\n  Attr   Name        Size                     Bytes  Class\n  ====   ====        ====                     =====  ===== \n         x           1x1                          8  int64\n         y           1x1                          8  double\n\nTotal is 2 elements using 16 bytes\n\n\n\n. . .\nJulia uses 64 bits for integers and floats by default. Other types available are:\nInt8, Int16, Int32, Int64, Int128, BigInt\nUInt8, UInt16, UInt32, UInt64, UInt128\nFloat16, Float32, Float64, BigFloat\n. . .\nTo define a variable of a given size, use x = int16(100). For example, to define an integer of arbitrary length, use\nx = BigInt(1606938044258990275541962092341162602522202993782792835301376)\n. . .\nAs specified in the IEEE754 standard, floating point numbers support inf and NaN values.\n\nJuliaPythonMATLAB\n\n\njulia&gt; -5 / 0\n-Inf\n\njulia&gt; 0 * Inf\nNaN\n\njulia&gt; NaN == NaN\nfalse\n\n\n&gt;&gt;&gt; -5 / 0\nTraceback (most recent call last):\n  File \"&lt;input&gt;\", line 1, in &lt;module&gt;\n    -5 / 0\n     ~~~^~~\nZeroDivisionError: division by zero\n&gt;&gt;&gt; 0 * np.Inf\nnan\n&gt;&gt;&gt; np.nan == np.nan\nFalse\n\n\n&gt;&gt; -5 / 0\nans =             -Inf\n&gt;&gt; 0 * Inf\nans =              NaN\n&gt;&gt; NaN == NaN\nans = 0\n\n\n\n. . .\nFloating point numbers can only be approximated, so a direct comparison using a==b may give unexpected results:\n\nJuliaPythonMATLAB\n\n\njulia&gt; 0.2 + 0.1 == 0.3\nfalse\n\njulia&gt; 0.2 + 0.1\n0.30000000000000004\n\n\n&gt;&gt;&gt; 0.2 + 0.1 == 0.3\nFalse\n&gt;&gt;&gt; 0.2 + 0.1\n0.30000000000000004\n\n\n&gt;&gt; 0.2 + 0.1 == 0.3\nans = 0\n&gt;&gt; 0.2 + 0.1\nans =              0.3\n\n\n\nThis is a general problem with floating point numbers, and exists in other programming languages as well.\n. . .\nThe machine precision can be obtained with eps(), which gives the distance between 1.0 and the next larger representable floating-point value:\n\nJuliaMATLAB\n\n\njulia&gt; eps(Float64)\n2.220446049250313e-16\n\n\n&gt;&gt; eps\nans = 2.220446049250313e-16\n\n\n\n. . .\nUsing that, we can implement a function isapprox(a, b) to test whether to numbers are approximately equal:\nfunction isapprox(x::Real, y::Real; atol::Real=1e-14, rtol::Real=10*eps())\n        return abs(x - y) &lt;= atol + rtol * max(abs(x), abs(y))\nend\n. . .\nFortunately, such a function already exists in the standard library:\n\nJuliaPython\n\n\njulia&gt; isapprox(0.2 + 0.1, 0.3)\ntrue\n\njulia&gt; 0.2 + 0.1 ≈ 0.3\ntrue\n\n\n&gt;&gt;&gt; np.allclose(0.2 + 0.1, 0.3)\nTrue\n\n\n\n\nNumerical Literal Coefficients\nWhen multiplying variables with a coefficient, you can omit the multiplication symbol *.\njulia&gt; x = 3\n3\n\njulia&gt; 2x^2 - 5x + 1\n4\n. . .\nAs a consequence, coefficients have a higher priority than other operations (“multiplications via juxtaposition”):\njulia&gt; 6 / 2x\n1.0\n. . .\n\n\n\nJulia does it the Casio way. source: commons.wikimedia.org, license: CC By-SA 3.0\n\n\n\n\nOverflow Behaviour\nAs in other programming languages, exceeding the maximum representable value of a given type results in wraparound behaviour:\njulia&gt; n = typemax(Int64)\n9223372036854775807\n\njulia&gt; n + 1\n-9223372036854775808\nIn this sense, calculating with integers is always a form of modulo arithmetic.",
    "crumbs": [
      "About me",
      "Numerical Linear Algebra",
      "Julia Basics"
    ]
  },
  {
    "objectID": "NumLinAlg/julia_basics.html#control-flow",
    "href": "NumLinAlg/julia_basics.html#control-flow",
    "title": "Julia Basics",
    "section": "Control Flow",
    "text": "Control Flow\nControl structures such as branches and loops are easy to implement in Julia; the syntax is very similar to MATLAB:\n\nJuliaMATLABPythonC++\n\n\nif x &gt; 0\n  println(\"x is positive\")\nelseif x &lt; 0\n  println(\"x is negative\")\nelse \n  println(\"x is zero\")\nend\n\n\nif x &gt; 0\n  disp(\"x is positive\")\nelseif x &lt; 0\n  disp(\"x is negative\")\nelse\n  disp(\"x is zero\")\nend\n\n\nif x &gt; 0:\n    print(\"x is positive\")\nelif x &lt; 0:\n    print(\"x is negative\")\nelse:\n    print(\"x is zero\")\n\n\nif (x &gt; 0) {\n  std::println(\"x is positive\");\n} else if (x &lt; 0) {\n  std::println(\"x is negative\");\n} else {\n  std::println(\"x is zero\");\n}\n\n\n\n. . .\nJust as in C++, Julia supports the ternary if statement:\n\nJuliaC++\n\n\nprintln(x &lt; y ? \"less than\" : \"greater or equal\")\n\n\nstd::println(x &lt; y ? \"less than\" : \"not less than\");\n\n\n\n. . .\nMultiple logical conditions can be combined with basic comparison operators:\nA && B    # A and B\nA || B    # A or B\nA != B    # A XOR B\n. . .\nOf course, logical operations do short-circuit evaluation:\n\nJuliaPythonMATLAB\n\n\njulia&gt; n = 2;\n\njulia&gt; n == 1 && println(\"n is one\")\nfalse\n\n\n&gt;&gt;&gt; n = 2\n&gt;&gt;&gt; n == 1 and print(\"n is one\")\nFalse\n\n\n&gt;&gt; n = 2;\n&gt;&gt; n == 1 && disp(\"n is one\")\nans = 0\n\n\n\n\nLoops\nTo iterate over a range or an array, use a for-each loop:\n\nJuliaPythonC++\n\n\narr = [\"Coffee\", \"Cocoa\", \"Avocado\", \"Math!\"];\n\nfor item in arr\n  println(item)\nend\n\n\narr = [\"Coffee\", \"Cocoa\", \"Avocado\", \"Math!\"]\n\nfor item in arr:\n  print(item)\n\n\nauto arr = std::vector&lt;std::string&gt;{\"Coffee\", \"Cocoa\", \"Avocado\", \"Math!\"};\n\nfor (const auto& item : arr){\n  std::println(item);\n}\n\n\n\n. . .\nThis can be used to iterate over a specific range:\n\nJuliaC++MATLABPython\n\n\nfor i in 1:4\n  println(i)\nend\n\n\nfor (int i = 1; i &lt;= 4; ++i){\n  std::println(i);\n}\n\n\nfor i = 1:4\n  disp(i)\nend\n\n\nfor i in range(1, 5):\n  print(i)\n\n\n\n. . .\nOf course, the same can be achieved with a while-loop:\n\nJuliaPythonMATLAB\n\n\ni = 1\n\nwhile i ≤ 4\n  println(i)\n  i += 1\nend\n\n\ni = 1\n\nwhile i &lt;= 4:\n  print(i)\n  i += 1\n\n\ni = 1\n\nwhile i &lt;= 4\n  disp(i)\n  i += 1;\nend\n\n\n\n\n\nException Handling\nExceptions are a way of dealing with unexpected errors. When such an error occurs, it is best to deal with the problem as early as possible. By throwing an exception, you skip the entire function call until it reaches a point where the exception is caught.\n. . .\nFor example, the sqrt function throws a DomainError when applied to a negative real value:\n\nJuliaPython\n\n\njulia&gt; sqrt(-1)\nERROR: DomainError with -1.0:\nsqrt was called with a negative real argument but will only return a complex result if called with a complex argument. Try sqrt(Complex(x)).\nStacktrace:\n[...]\n\n\n&gt;&gt;&gt; math.sqrt(-1)\nTraceback (most recent call last):\n  File \"&lt;input&gt;\", line 1, in &lt;module&gt;\n    math.sqrt(-1)\nValueError: math domain error\n\n\n\n. . .\nAn exception like this can be thrown using the throw keyword:\nif x &lt;= 0\n    err = DomainError(x, \"`x` must be positive.\")\n    throw(err)\nend\n. . .\nThere are many built-in exceptions available.\n\nbuilt-in exceptions\n\n\nException\n\n\n\n\nDomainError\n\n\nArgumentError\n\n\nBoundsError\n\n\nOverflowError\n\n\n\n. . .\nYou may also define your own exceptions in the following way:\njulia&gt; struct MyCustomException &lt;: Exception end\n. . .\nAn error is an eception of type ErrorException. It can be used to interrupt the normal control flow.\njulia&gt; fussy_sqrt(x) = x &gt;= 0 ? sqrt(x) : error(\"negative x not allowed\")\nfussy_sqrt (generic function with 1 method)\n. . .\nThe try-catch block can be used to handle exceptions:\ntry\n    # Code\ncatch e::DomainError\n    # Handle specific error\ncatch\n    # Handle other errors\nend",
    "crumbs": [
      "About me",
      "Numerical Linear Algebra",
      "Julia Basics"
    ]
  },
  {
    "objectID": "NumLinAlg/julia_basics.html#functions",
    "href": "NumLinAlg/julia_basics.html#functions",
    "title": "Julia Basics",
    "section": "Functions",
    "text": "Functions\nSimple functions can be defined via:\n\nJuliaPythonC++\n\n\nf(x) = x^2\n\n\nf = lambda x: x**2\n\n\nauto f = [](auto x){ return x*x; };\n\n\n\n. . .\nMore advanced functions are defined using the function keyword:\n\nJuliaPython\n\n\nfunction fac(n::Integer)\n  @assert n &gt; 0 \"n must be positive\"\n\n  if n ≤ 1\n    return 1\n  else\n    return n * fac(n-1)\n  end\nend\n\n\ndef fac(n: int) -&gt; int:\n    assert n &gt; 0, \"n must be positive!\"\n\n    if (n &lt;= 1):\n        return 1\n    else:\n        return n * fac(n - 1)\n\n\n\nNote that we use the @assert macro to ensure that the arguments are positive.\n. . .\nFunctions can be applied element-wise to arrays using the dot notation, f.(x):\n\nJuliaPythonMATLAB\n\n\njulia&gt; x = [0, 1, 2, 3, 4, 5];\njulia&gt; f(x) = x^2;\njulia&gt; f.(x)\n6-element Vector{Int64}:\n  0\n  1\n  4\n  9\n 16\n 25\n\n\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; x = np.array([-11, 1, 2, 3, 4, 5])\n&gt;&gt;&gt; f = lambda x: x**2\n&gt;&gt;&gt; f(x)\narray([ 0,  1,  4,  9, 16, 25])\n\n\n&gt;&gt; x = [0, 1, 2, 3, 4, 5];\n&gt;&gt; f = @(x) x.^2\nf =\n\n@(x) x .^ 2\n\n&gt;&gt; f(x)\nans = 0   1   4   9   16    25\n\n\n\n. . .\nThe same can be achieved with the map(f, arr) function:\njulia&gt; map(f, x)\n6-element Vector{Int64}:\n  0\n  1\n  4\n  9\n 16\n 25\n. . .\nThe advantage of the map command is that it can also be applied to anonymous functions:\njulia&gt; map(x -&gt; x^2, [0, 1, 2, 3, 4, 5])\n6-element Vector{Int64}:\n  0\n  1\n  4\n  9\n 16\n 25\n\nOptional Arguments\nFunctions in Julia can have positional arguments and keyword arguments, which are separated with a semicolon ;.\nfunction f(x, y=10; a=1)\n  return (x + y) * a\nend\n. . .\nSuch a function can be called via:\njulia&gt; f(5)\n15\n\njulia&gt; f(2, 5)\n7\n\njulia&gt; f(2, 5; a=3)\n21\n\n\nVarargs Functions\nSometimes it is convenient to write functions which can take an arbitray number of arguments. Such a function is called varargs functions. You can define a varargs function by following the last positional argument with an ellipsis:\n\nJuliaC++\n\n\nfunction display(args...)\n        println(typeof(args))\n        for x in args\n                println(x)\n        end\nend\njulia&gt; display(42, 3.7, \"hello\")\nTuple{Int64, Float64, String}\n42\n3.7\nhello\n\n\ntemplate&lt;typename... Args&gt;\nvoid display(Args&&... args)\n{\n    (std::cout &lt;&lt; ... &lt;&lt; args) &lt;&lt; '\\n';\n}\n42\n3.7\nhello\n\n\n\n. . .\n\n\n\n\n\n\nNote\n\n\n\nNote that the varargs mechanism works differently in Julia than in C++. In C++, the expression args + ... is shorthand for recursion, meaning that the expression is evaluated to ((((x1 + x2) + x3) + x4) + ... ).\nIn Julia, however, it is much simpler: the varargs argument is just a tuple that you can iterate over.\n\n\n\n\nNaming convention\n\n\n\n\n\n\nImportant\n\n\n\nAs a convention in Julia, functions that modify an argument should have a ! at the end.\n\n\nFor example, sort() and sort!() both sort an array; however, one returns a copy, and the other functions sorts the array in place.\n. . .\nIt is also good practice to use return nothing to indicate that a function does not return anything.\nfunction do_something()\n  println(\"Hello world!\")\n  return nothing\nend\n\n\n\n\n\n\n\nNoteExercise\n\n\n\nImplement a function which calculates the sine of a real number x.\n\\[\n\\sin(x) = \\sum_{k=0}^\\infty (-1)^k \\frac{x^{2k+1}}{(2k+1)!}\n\\]\n\n\n. . .\n\n\n\n\n\n\nNoteSolution\n\n\n\n\n\nfunction sine(x::Real)\n        @assert 0 &lt;= x && x &lt;= pi/4\n\n        sine = 0.0\n        for k in 0:9\n                sine += (-1)^k * x^(2k + 1) / factorial(2k + 1)\n        end\n        return sine\nend",
    "crumbs": [
      "About me",
      "Numerical Linear Algebra",
      "Julia Basics"
    ]
  },
  {
    "objectID": "NumLinAlg/julia_basics.html#strings",
    "href": "NumLinAlg/julia_basics.html#strings",
    "title": "Julia Basics",
    "section": "Strings",
    "text": "Strings\nOne can think of a String as an array of characters with some convenience functions. Julia supports Unicode characters via the UTF-8 encoding.\n. . .\nAs in Java and Python, strings are immutable. The value of a string object cannot be changed.\njulia&gt; name = \"Markus\"\n\"Markus\"\n\njulia&gt; pointer_from_objref(name)\nPtr{Nothing} @0x000072d21dee95b8\n\njulia&gt; name = \"Aurelius\"\n\"Aurelius\"\n\njulia&gt; pointer_from_objref(name)\nPtr{Nothing} @0x000072d21deea6c8\n. . .\nTo change a character in a string, you have to first convert the string to an array, modify the desired character, and then join the array back into a string:\n\nJuliaPython\n\n\nstr = \"hello world\"\nchars = collect(str)\nchars[6] = '_'\nnew_str = join(chars)  # hello_world\n\n\nstr = \"hello world\"\nchar_list = list(str)\nchar_list[5] = '_'\nnew_str = ''.join(char_list)\nprint(new_str)  # hello_world\n\n\n\n\nSingle Characters\nThere is a class-type for single characters, AbstractChar:\njulia&gt; c = 'ü'\n'ü': Unicode U+00FC (category Ll: Letter, lowercase)\n\njulia&gt; typeof(c)\nChar\n. . .\nYou can easily convert a character to its integer value:\njulia&gt; Int(c)\n252\n. . .\nKeep in mind that not all integer values are valid unicode characters. For performance, the Char conversion does not check that every value is valid.\njulia&gt; Char(0x110000)\n'\\U110000': Unicode U+110000 (category In: Invalid, too high)\n\njulia&gt; isvalid(Char, 0x110000)\nfalse\n. . .\nSince characters are basically like integers, you can treat them as such.\njulia&gt; 'A' &lt; 'a'\ntrue\n\njulia&gt; 'x' - 'a'\n23\n\n\nString Basics\nString literals are delimited by double quotes (not single quotes):\n\nJuliaPython\n\n\njulia&gt; str = \"Hello World!\\n\"\n\"Hello World!\\n\"\n\njulia&gt; str[begin]\n'H': ASCII/Unicode U+0048 (category Lu: Letter, uppercase)\n\njulia&gt; str[end]\n'\\n': ASCII/Unicode U+000A (category Cc: Other, control)\n\njulia&gt; str[2:5]\n\"ello\"\n\n\n&gt;&gt;&gt; str = \"Hello  World!\\n\"\n&gt;&gt;&gt; str[0]\n'H'\n&gt;&gt;&gt; str[-1]\n'\\n'\n&gt;&gt;&gt; str[1:4]\n'ell'\n\n\n\n\n\nSubstrings\nA SubString is a view into another string. It does not allocate memory, but instead references the original string.\n# Range Indexing\nstr = \"Hello, World!\"\nsubstring_copy = str[1:5]  # Creates a new string copy\nprintln(substring_copy)  # Outputs: \"Hello\"\n\n# SubString Function\nstr = \"Hello, World!\"\nsubstring_view = SubString(str, 1, 5)  # Creates a view into the original string\nprintln(substring_view)  # Outputs: \"Hello\"\n. . .\nSo while both methods can extract a substring, the SubString function is more memory-efficient as it does not create a new string but rather a view into the original string.\n\n\nUnicode and UTF-8\nAs mentioned above, Julia supports Unicode characters. Because of the variable length encodings, you cannot iterate over a string as you can in a normal array. Not every integer is a valid index.\n\nJuliaPython\n\n\njulia&gt; str  = \"\\u2200 x \\u2203 y\"\n\"∀ x ∃ y\"\n\njulia&gt; str[1]\n'∀': Unicode U+2200 (category Sm: Symbol, math)\n\njulia&gt; str[2]\nERROR: StringIndexError: invalid index [2], valid nearby indices [1]=&gt;'∀', [4]=&gt;' '\nStacktrace:\n[...]\n\njulia&gt; str[4]\n' ': ASCII/Unicode U+0020 (category Zs: Separator, space)\n\n\n&gt;&gt;&gt; str = \"\\u2200 x \\u2203 y\"\n&gt;&gt;&gt; str\n'∀ x ∃ y'\n&gt;&gt;&gt; str[0]\n'∀'\n&gt;&gt;&gt; str[1]\n' '\n&gt;&gt;&gt; str[2]\n'x'\n\n\n\nThis also means that the number of characters in a string is not always the same as the last index.\njulia&gt; str\n\"∀ x ∃ y\"\n\njulia&gt; length(str)\n7   # number of characters\n\njulia&gt; lastindex(str)\n11  # last index\n. . .\nTo iterate through a string, you can use the string as an iterable object:\njulia&gt; for c in str\n         print(c)\n       end\n∀ x ∃ y\n. . .\nIf you need to obtain the valid indices for a string, you can use the eachindex function:\njulia&gt; collect(eachindex(str))\n7-element Vector{Int64}:\n  1\n  4\n  5\n  6\n  7\n 10\n 11\n\n\nConcatenation\nMultiple strings can be concatenated:\n\nJuliaPython\n\n\njulia&gt; str = \"Hello \" * \"world\"\n\"Hello world\"\n\n\n&gt;&gt;&gt; str = \"Hello \" + \"world\"  \n&gt;&gt;&gt; str\n'Hello world'\n\n\n\n. . .\nThe choice of * to concatenate strings may seem unusual, but mathematically it makes sense, since concatenation is a non-commutative operation.\n\n\nString Interpolation\nYou can evaluate variables within a string with the $ character:\njulia&gt; x = 42\n42\n\njulia&gt; \"The solution is $x\"\n\"The solution is  42\"\n\njulia&gt; \"1 + 2 = $(1 + 2)\"\n\"1 + 2 = 3\"\n\n\nCommon String Operations\nBasic string operations\njulia&gt; \"Avocado\" &lt; \"Coffee\"\ntrue\n\njulia&gt; findfirst(\"and\", \"Avocados and Chocolate and Coffee.\")\n10:12\n\njulia&gt; findall(\"and\", \"Avocados and Chocolate and Coffee.\")\n2-element Vector{UnitRange{Int64}}:\n 10:12\n 24:26\n. . .\nTo repeat a string multiple times, use repeat:\n\nPythonJulia\n\n\n&gt;&gt;&gt; \"...X\" * 5\n'...X...X...X...X...X'\n\n\njulia&gt; repeat(\"...X\", 5)\n\"...X...X...X...X...X\"\n\n\n\n. . .\nTwo other very handy operations are split and join:\n\nJuliaPython\n\n\njulia&gt; str = \"Germany,Berlin,83500000,357596,+49,de\"\n\"Germany,Berlin,83500000,357596,+49,de\"\n\njulia&gt; words = split(str, ',')\n6-element Vector{SubString{String}}:\n \"Germany\"\n \"Berlin\"\n \"83500000\"\n \"357596\"\n \"+49\"\n \"de\"\n\njulia&gt; join(words, ',')\n\"Germany,Berlin,83500000,357596,+49,de\"\n\n\n&gt;&gt;&gt; str  = \"Germany,Berlin,83500000,357596,+49,de\"\n&gt;&gt;&gt; words = str.split(',')\n&gt;&gt;&gt; words\n['Germany', 'Berlin', '83500000', '357596', '+49', 'de']\n\n&gt;&gt;&gt; ','.join(words)\n'Germany,Berlin,83500000,357596,+49,de'\n\n\n\n. . .\nThese functions are very useful for handling csv-data.\n. . .\nTo check whether a string contains a specific substring, we can either use occursin or contains.\njulia&gt; occursin(\"world\", \"Hello world.\")\ntrue\n\njulia&gt; contains(\"Hello world.\", \"world\")\ntrue\nFor more complicated operations, it is recommended to use regular expressions.\n\n\nRegular Expressions\nJulia uses Perl-compatible regular expressions (regexes), as provided by the PCRE library.\nRegular expressions are a common concept found in other programming languages, so there is no need to go into detail here. For a quick refresher, I refer the reader to the Python regex documentation and the tutorial on regular-expressions.info.\n. . .\n\nJuliaPython\n\n\njulia&gt; re = r\"^\\s*(?:#|$)\"\nr\"^\\s*(?:#|$)\"\n\njulia&gt; typeof(re)\nRegex\n\n\n&gt;&gt;&gt; import re\n&gt;&gt;&gt; rx = re.compile(r'^\\s*(?:#|$)')\n&gt;&gt;&gt; type(rx)\n&lt;class 're.Pattern'&gt;\n\n\n\n. . .\nFor example, to match comment lines, you can use the following regex:\n\nJuliaPython\n\n\nm = match(r\"^\\s*(?:#|$)\", line)\nif m === nothing\n    println(\"not a comment\")\nelse\n    println(\"blank or comment\")\nend\n\n\nm = re.match(r'^\\s*(?:#|$)', line)\nif m==None:\n    print(\"not a comment\")\nelse:\n    print(\"blank or comment\")\n\n\n\n. . .\n\n\n\n\n\n\nNoteExample\n\n\n\nHere is a simple regex to parse a string that contains the time:\njulia&gt; time = \"12:45\"\n\"12:45\"\n\njulia&gt; m=match(r\"(?&lt;hour&gt;\\d{1,2}):(?&lt;minute&gt;\\d{2})\",\"12:45\")\nRegexMatch(\"12:45\", hour=\"12\", minute=\"45\")\n\n\n. . .\n\n\n\n\n\n\nNoteExercise\n\n\n\nWrite a regular expression to parse bibliography data in the following format:\nsurename, forename, and surename2, forename2. year. Title. Publisher.\nExample:\nLauwens, Ben, and Allen B. Downey. 2019. Think Julia. O’Reilly Media.\n\n\n. . .\n\n\n\n\n\n\nNoteSolution\n\n\n\n\n\njulia&gt; m = match(r\"^(?P&lt;names&gt;.*)\\. (?P&lt;year&gt;\\d{4})\\. (?&lt;title&gt;.*)\\. (?&lt;publisher&gt;.*)\\.$\", str)\nRegexMatch(\"Lauwens, Ben, and Allen B. Downey. 2019. Think Julia. O’Reilly Media.\", names=\"Lauwens, Ben, and Allen B. Downey\", year=\"2019\", title=\"Think Julia\", publisher=\"O’Reilly Media\")\n\njulia&gt; authors = split(m[\"names\"], \" and \")\n2-element Vector{SubString{String}}:\n \"Lauwens, Ben,\"\n \"Allen B. Downey\"\n\njulia&gt; year = parse(Int, m[\"year\"])\n2019",
    "crumbs": [
      "About me",
      "Numerical Linear Algebra",
      "Julia Basics"
    ]
  },
  {
    "objectID": "NumLinAlg/julia_basics.html#pretty-output",
    "href": "NumLinAlg/julia_basics.html#pretty-output",
    "title": "Julia Basics",
    "section": "Pretty Output",
    "text": "Pretty Output",
    "crumbs": [
      "About me",
      "Numerical Linear Algebra",
      "Julia Basics"
    ]
  },
  {
    "objectID": "NumLinAlg/julia_basics.html#symbols",
    "href": "NumLinAlg/julia_basics.html#symbols",
    "title": "Julia Basics",
    "section": "Symbols",
    "text": "Symbols\nSymbols are a special type of immutable data that represent identifiers or names. They are denoted by a colon (:) followed by the name, such as :example.\nThe advantage of symbols over strings is that they offer very efficient comparisons:\njulia&gt; @btime \"abcd\" == \"abcd\"\n  5.632 ns (0 allocations: 0 bytes)\ntrue\n\njulia&gt; @btime :abcd == :abcd\n  0.025 ns (0 allocations: 0 bytes)\ntrue\nIn this sense, symbols are very similar to enums, except that they do not provide type safety: all symbols are of type “symbol”, whereas enums have their own distinct types.\nSymbols are also used for meta-programming, which we will learn more about later.",
    "crumbs": [
      "About me",
      "Numerical Linear Algebra",
      "Julia Basics"
    ]
  },
  {
    "objectID": "NumLinAlg/julia_basics.html#fixed-width-strings",
    "href": "NumLinAlg/julia_basics.html#fixed-width-strings",
    "title": "Julia Basics",
    "section": "Fixed-width Strings",
    "text": "Fixed-width Strings\nIn many data science applications we have to deal with strings that are only a few characters long. For example, city names are usually very short, and country codes are only two characters long.\nFor better performance, it is advantageous to store such data using a fixed-width string. This can be done using the InlineStrings.jl package, which provides eight fixed-width string types of up to 255 bytes.\njulia&gt; using InlineStrings\n\njulia&gt; country = InlineString(\"South-Korea\")\n\"South-Korea\"\n\njulia&gt; typeof(country)\nString15\nTODO: Move this to chapter 5.",
    "crumbs": [
      "About me",
      "Numerical Linear Algebra",
      "Julia Basics"
    ]
  },
  {
    "objectID": "NumLinAlg/julia_basics.html#annotated-strings",
    "href": "NumLinAlg/julia_basics.html#annotated-strings",
    "title": "Julia Basics",
    "section": "Annotated Strings",
    "text": "Annotated Strings\nIs is possible to store additional information inside a string by\njulia&gt; printstyled(\"WARNING!\", color=:red, bold=true, blink=true)\nWARNING!\n\njulia&gt; str = styled\"{green:Avocados} are {bold:green}\"\n\"Avocados are green\"",
    "crumbs": [
      "About me",
      "Numerical Linear Algebra",
      "Julia Basics"
    ]
  },
  {
    "objectID": "NumLinAlg/julia_basics.html#references",
    "href": "NumLinAlg/julia_basics.html#references",
    "title": "Julia Basics",
    "section": "References",
    "text": "References\n\n\n[1] E. Engheim, Julia as a Second Language. Manning Publ., 2023.\n\n\n[2] B. Kamiński, Julia for Data Analysis. Manning Publ., 2022.\n\n\n[3] B. Lauwens and A. B. Downey, Think Julia. O’Reilly Media, 2019. Available: https://benlauwens.github.io/ThinkJulia.jl/latest/book\n\n\n[4] J. Storopoli, R. Huijzer, and L. Alonso, Julia Data Science. 2021. Available: https://juliadatascience.io",
    "crumbs": [
      "About me",
      "Numerical Linear Algebra",
      "Julia Basics"
    ]
  },
  {
    "objectID": "NumLinAlg/julia_basics.html#footnotes",
    "href": "NumLinAlg/julia_basics.html#footnotes",
    "title": "Julia Basics",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIt is possible to achieve this in C++ by using pointers or std::any, but let’s not go there.↩︎\nsee also on stackoverflow: Copy or clone a collection in Julia↩︎",
    "crumbs": [
      "About me",
      "Numerical Linear Algebra",
      "Julia Basics"
    ]
  },
  {
    "objectID": "NumLinAlg/julia_ecosystem-slides.html#important-julia-packages",
    "href": "NumLinAlg/julia_ecosystem-slides.html#important-julia-packages",
    "title": "The Julia Data Ecosystem",
    "section": "Important Julia Packages",
    "text": "Important Julia Packages\n\nPlots.jl: Modern plotting library similar to MatplotLib\nLinearSolve.jl High-performance library for solving linear equations\nDifferentialEquations.jl Efficient solvers for various differential equations\nFFTW.jl Bindings to the FFTW libeary for Fast Fourier Transform\nStatsKit.jl Convenience meta-package to load essential packages for statistics\nMLJ.jl Machine Learning framework for Julia\nTuring.jl Bayesian inference with probabilistic programming\nJuliaGPU Packages for programming on GPUs with Julia"
  },
  {
    "objectID": "NumLinAlg/julia_ecosystem-slides.html#plots.jl",
    "href": "NumLinAlg/julia_ecosystem-slides.html#plots.jl",
    "title": "The Julia Data Ecosystem",
    "section": "Plots.jl",
    "text": "Plots.jl\nPlots.jl is a data visualisation and plotting library similar to Matplotlib. It provides an interface for several backends, offering great flexibility while remaining simple to use.\nInstallation:\nPkg.add(\"Plots\")\nPkg.add(\"PlotThemes\")\nWe also need LaTeXStrings.jl:\n\nusing Plots\nusing LaTeXStrings\nusing WebIO\n\ntheme(:dark)"
  },
  {
    "objectID": "NumLinAlg/julia_ecosystem.html",
    "href": "NumLinAlg/julia_ecosystem.html",
    "title": "The Julia Data Ecosystem",
    "section": "",
    "text": "Plots.jl: Modern plotting library similar to MatplotLib\nLinearSolve.jl High-performance library for solving linear equations\nDifferentialEquations.jl Efficient solvers for various differential equations\nFFTW.jl Bindings to the FFTW libeary for Fast Fourier Transform\nStatsKit.jl Convenience meta-package to load essential packages for statistics\nMLJ.jl Machine Learning framework for Julia\nTuring.jl Bayesian inference with probabilistic programming\nJuliaGPU Packages for programming on GPUs with Julia",
    "crumbs": [
      "About me",
      "Numerical Linear Algebra",
      "Important Julia Packages"
    ]
  },
  {
    "objectID": "NumLinAlg/julia_ecosystem.html#important-julia-packages",
    "href": "NumLinAlg/julia_ecosystem.html#important-julia-packages",
    "title": "The Julia Data Ecosystem",
    "section": "",
    "text": "Plots.jl: Modern plotting library similar to MatplotLib\nLinearSolve.jl High-performance library for solving linear equations\nDifferentialEquations.jl Efficient solvers for various differential equations\nFFTW.jl Bindings to the FFTW libeary for Fast Fourier Transform\nStatsKit.jl Convenience meta-package to load essential packages for statistics\nMLJ.jl Machine Learning framework for Julia\nTuring.jl Bayesian inference with probabilistic programming\nJuliaGPU Packages for programming on GPUs with Julia",
    "crumbs": [
      "About me",
      "Numerical Linear Algebra",
      "Important Julia Packages"
    ]
  },
  {
    "objectID": "NumLinAlg/julia_ecosystem.html#plots.jl",
    "href": "NumLinAlg/julia_ecosystem.html#plots.jl",
    "title": "The Julia Data Ecosystem",
    "section": "Plots.jl",
    "text": "Plots.jl\nPlots.jl is a data visualisation and plotting library similar to Matplotlib. It provides an interface for several backends, offering great flexibility while remaining simple to use.\nInstallation:\nPkg.add(\"Plots\")\nPkg.add(\"PlotThemes\")\nWe also need LaTeXStrings.jl:\n\nusing Plots\nusing LaTeXStrings\nusing WebIO\n\ntheme(:dark)\n\n\nExample Plot of the trigonometric functions:\n\n\nCode\nx = range(0, 2π, length=100)\ny = sin.(x)\nplot(x, y)\nplot!(x, cos.(x))\n\n\n\n\n\n\nWe can use LaTeXStrings to add LaTeX labels to each plot;\nLet’s customize the plot by using a different colors, and also add a title and xlabel:\n\n\nCode\nx = range(0, 2π, length=100)\nplot(x, sin.(x), label=L\"$\\sin(x)$\", color=\"darkred\", lw=3)\nplot!(x, cos.(x), label=L\"$\\cos(x)$\", color=\"teal\", lw=2)\n\ntitle!(\"Trigonometric functions\")\nxlabel!(\"x-axis\")\nylabel!(\"y-axis\")\n\n\n\n\n\n\nScatter Plots:\n\n\nCode\nx = range(0, 10, length=100)\ny = sin.(x)\ny_noisy = @. sin(x) + 0.1*randn()\n\nplot(x, y, label=L\"$\\sin(x)$\")\nscatter!(x, y_noisy, label=\"data\", markersize=2.5)\n\n\n\n\n\n\nHistograms can be useful for visualizing statistical data:\n\n\nCode\nusing StatsPlots\nx = randn(1000)\n\nhistogram(x, bins=50, normalize=:pdf, label=\"data\")\ndensity!(x, trim=true, label=\"KDE\", lw=3)\n\n\n\n\n\n\n3D-Plots\nSurface Plots of the Rosenbrock function:\n\n\nCode\n# Use Plotly backend with MathJax support\nplotlyjs()\n#plotlyjs(extra_plot_kwargs=KW(:include_mathjax=&gt;\"cdn\"))\n\n# Rosenbrock function:\nf(x, y) = (1 - x)^2 + 100 * (y - x^2)^2\n\nx = range(-2, 2, length=100)\ny = range(-1, 3, length=100)\n\nsurface(x, y, f, color=:viridis, extra_plot_kwargs=KW(:width=&gt;900, :height=&gt;600))\n#surface(x, y, f, color=:viridis)\ntitle!(\"Rosenbrock function\")\nxlabel!(\"x\")\nylabel!(\"y\")\n\n\n    \n    \n\n\n\nContour Plots of the Himmelblau function:\n\n\nCode\n# Himmelblau-function\nf(x, y) = (x^2 + y - 11)^2 + (x + y^2 - 7)^2\n\nx = range(-5, 5, length=100)\ny = range(-5, 5, length=100)\nz = @. f(x', y)\n\ncontour(x, y, z, levels=20, clabels=true, color=:turbo)\ntitle!(\"Himmelblau function\")\nxlabel!(L\"x\")\nylabel!(L\"y\")\n\n\n    \n    \n\n\n\n\nDataFrames\nUsing the StatsPlots extension, you can use DataFrames as arguments:\n\n\nCode\nusing StatsPlots, RDatasets\n\ndata = dataset(\"datasets\", \"iris\")\n@df data scatter(:SepalLength, :SepalWidth;\n    group = :Species,\n    title = \"Scatter Plot of the iris dataset\",\n    xlabel = \"Sepal Length (cm)\",\n    ylabel = \"Sepal Width (cm)\",\n)\n\n\n    \n    \n\n\nUnlike in Seaborn, it is not possible to label the axes automatically.\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndata = sns.load_dataset(\"iris\")\nsns.scatterplot(data, x=\"sepal_length\", y=\"sepal_width\", hue=\"species\")\nplt.show()",
    "crumbs": [
      "About me",
      "Numerical Linear Algebra",
      "Important Julia Packages"
    ]
  },
  {
    "objectID": "NumLinAlg/julia-LinearSolveJL-slides.html#linearsolve.jl",
    "href": "NumLinAlg/julia-LinearSolveJL-slides.html#linearsolve.jl",
    "title": "LinearSolve.jl",
    "section": "LinearSolve.jl",
    "text": "LinearSolve.jl\n\nLinearSolve.jl High-performance library for solving linear equations\n\nInstallation:\nPkg.add(\"LinearSolve\")"
  },
  {
    "objectID": "NumLinAlg/julia-LinearSolveJL.html",
    "href": "NumLinAlg/julia-LinearSolveJL.html",
    "title": "LinearSolve.jl",
    "section": "",
    "text": "LinearSolve.jl High-performance library for solving linear equations\n\nInstallation:\nPkg.add(\"LinearSolve\")\n\nlorem ipsum",
    "crumbs": [
      "About me",
      "Numerical Linear Algebra",
      "Linear Equations"
    ]
  },
  {
    "objectID": "NumLinAlg/julia-LinearSolveJL.html#linearsolve.jl",
    "href": "NumLinAlg/julia-LinearSolveJL.html#linearsolve.jl",
    "title": "LinearSolve.jl",
    "section": "",
    "text": "LinearSolve.jl High-performance library for solving linear equations\n\nInstallation:\nPkg.add(\"LinearSolve\")\n\nlorem ipsum",
    "crumbs": [
      "About me",
      "Numerical Linear Algebra",
      "Linear Equations"
    ]
  },
  {
    "objectID": "Optimization/convexity-slides.html#convex-sets",
    "href": "Optimization/convexity-slides.html#convex-sets",
    "title": "Convex Sets and convex Functions",
    "section": "Convex Sets",
    "text": "Convex Sets\nBefore we start with optimisation algorithms, we first need to introduce some concepts.\n\n\n\n\n\n\n\nConvex Set\n\n\nA set \\(M\\) is called convex if for any \\(\\mathbf{x}_1, \\mathbf{x}_2 \\in M\\): \\[\n\\theta \\mathbf{x}_1 + (1-\\theta) \\mathbf{x}_2 \\in M\n\\qquad \\forall \\theta \\in [0, 1]\n\\]\n\n\n\n\n\nIn other words, a set is convex if any line connecting two of its points is also contained within the set.\n\n\n\n\n\n\n\n\n\n\nconvex set\nsource: wikimedia.org license: CC BY-SA 4.0\n\n\n\n\n \n\n\n\n\n\nnonconvex set\nsource: wikimedia.org license: CC BY-SA 4.0\n\n\n\n\n\n\nFigure 1: Examples for convex and nonconvex sets"
  },
  {
    "objectID": "Optimization/convexity-slides.html#convex-functions",
    "href": "Optimization/convexity-slides.html#convex-functions",
    "title": "Convex Sets and convex Functions",
    "section": "Convex Functions",
    "text": "Convex Functions\n\n\n\n\n\n\nConvex functions\n\n\nLet \\(D\\) be a convex set. A function \\(f: D \\to \\mathbb{R}\\) is called convex if \\[\nf\\bigl(\\theta \\mathbf{x}_1 + (1-\\theta) \\mathbf{x}_2\\bigr) \\leq \\theta f(\\mathbf{x}_1) + (1-\\theta) f(\\mathbf{x}_2), \\qquad \\theta \\in [0, 1]\n\\]\n\n\n\n\nVisually, this means that the graph between two points always lies below the secant line connecting them.\n\n\nCode\nusing Plots\nusing LaTeXStrings\ntheme(:dark)\n#default(size = (800, 600))  # set default plot size\n\n# Define objective function f\nf(x) = -0.01548523*x^4 + 0.09320228*x^3 + 0.21426876*x^2 + -0.83797152*x + 0.90722445\n\nxmin = -0.654\nxmax = 4.074\nx = range( xmin, xmax, length=100)\n\nx1 = 0.56\nx2 = 3.284\ntheta = 0.3\nx_comb = theta * x1 + (1 - theta) * x2\n\n# Plot function f\nplot(x, f, color=:darkblue, linewidth=4,\n    legend=false, \n    xticks = ([x1, x2], [\"x₁\", \"x₂\"]),\n    yticks = ([f(x1), f(x2)], [\"f(x₁)\", \"f(x₂)\"]))\n\n# Draw the line segment connecting (x1, f(x1)) and (x2, f(x2))\nplot!([x1, x2], [f(x1), f(x2)],\n    lw = 1.5, ls = :dash, color = :green)\n\n# Plot horizontal and vertical lines\nplot!([xmin, x1, x1], [f(x1), f(x1), 0],\n        lw = 1.5, ls = :dash, color = :gray )\nplot!([x2, x2, xmin], [0, f(x2), f(x2)],\n    lw = 1.5, ls = :dash, color = :gray )\n\n# Plot points (x1, f(x1)) and (x2, f(x2))\nscatter!([x1, x2, x_comb], [f(x1), f(x2), f(x_comb)],\n        markersize = 6, color = :red)\n\n# Annotations\nannotate!(x_comb + 0.05, f(x_comb) - 0.05, text(L\"f(\\theta x_1 + (1-\\theta) x_2)\", :white, :left, :top, 15))\nannotate!(x_comb + 0.05, theta * f(x1) + (1-theta) * f(x2), text(L\"\\theta f(x_1) + (1-\\theta) f(x_2)\", :white, :right, 15))\n\n\n\n\n\n\n\nFigure 4: A convex function\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nplt.style.use('seaborn')\n\nf = lambda x: -0.01548523*x**4 + 0.09320228*x**3 + 0.21426876*x**2 + -0.83797152*x + 0.90722445\n\nxmin = -0.654\nxmax = 4.074\nx = np.linspace( xmin, xmax, num=100)\n\nx1 = 0.56\nx2 = 3.284\ntheta = 0.55\nx_comb = theta * x1 + (1 - theta) * x2\n\n# Plot function f\nplt.plot(x, f(x))\n\n\n# Set xticks and xticklabels\nax = plt.gca()\nplt.xticks([x1, x2])\nax.set_xticklabels([r'$x_1$', r'$x_2$'])\nplt.yticks(np.array([f(x1), f(x2)]))\nax.set_yticklabels([r'$f(x_1)$', r'$f(x_2)$'])\n\n# move axes to origin\nax.spines[\"bottom\"].set_position(\"zero\")\nax.spines[\"left\"].set_position(\"zero\")\n\n# Box off\nax.spines[\"top\"].set_color(\"none\")\nax.spines[\"right\"].set_color(\"none\")\n\n\n# Draw the line segment connecting (x1, f(x1)) and (x2, f(x2))\nplt.plot([x1, x2], [f(x1), f(x2)],\n    color = \"green\", linestyle = \"dashed\", linewidth = 1.5)\n\n# Plot horizontal and vertical lines\nplt.plot([0, x1, x1], [f(x1), f(x1), 0],\n    color = \"gray\", linestyle = \"dashed\", linewidth = 1.5)\nplt.plot([x2, x2, 0], [0, f(x2), f(x2)],\n    color = \"gray\", linestyle = \"dashed\", linewidth = 1.5)\n\n# Plot points (x1, f(x1)), (x2, f(x2)) and (xm, f(xm))\nplt.plot([x1, x2, x_comb], [f(x1), f(x2), f(x_comb)],\n    \".r\", markersize = 15)"
  },
  {
    "objectID": "Optimization/convexity.html",
    "href": "Optimization/convexity.html",
    "title": "Convex Sets and convex Functions",
    "section": "",
    "text": "Before we start with optimisation algorithms, we first need to introduce some concepts.\n. . .\n\n\n\n\n\n\nNoteConvex Set\n\n\n\nA set \\(M\\) is called convex if for any \\(\\mathbf{x}_1, \\mathbf{x}_2 \\in M\\): \\[\n\\theta \\mathbf{x}_1 + (1-\\theta) \\mathbf{x}_2 \\in M\n\\qquad \\forall \\theta \\in [0, 1]\n\\]\n\n\n. . .\nIn other words, a set is convex if any line connecting two of its points is also contained within the set.\n. . .\n\n\n\n\n\n\n\n\nconvex set\nsource: wikimedia.org license: CC BY-SA 4.0\n\n\n\n\n \n\n\n\n\n\nnonconvex set\nsource: wikimedia.org license: CC BY-SA 4.0\n\n\n\n\n\n\nFigure 1: Examples for convex and nonconvex sets\n\n\n\n\nThe expression \\(\\theta \\mathbf{x}_1 + (1-\\theta) \\mathbf{x}_2\\) is called an convex-combination.\n. . .\nThis can be generalized to more than two points. Let’s say we have multiple points \\(x_1, \\dotsc, x_n\\), then we have \\[\n\\sum_{i=1}^n \\theta_i \\mathbf{x}_i \\in M\n\\] where \\[\n\\theta_i \\ge 0 \\quad \\forall 1 \\leq i \\leq n, \\quad \\sum_{i=1}^n \\theta_i = 1.\n\\]\n. . .\nFor anyone familiar with statistics, this will look very similar to the expectation of a probability distribution.\nAnd indeed, this can be generalised to continuous functions: Suppose \\(p(\\mathbf{x})\\) satisfies \\(p(\\mathbf{x}) \\gt 0\\) and \\[\n\\int_M p(\\mathbf{x}) \\, \\mathrm{d}\\mathbf{x} = 1,\n\\] then \\[\n\\int_M p(\\mathbf{x}) \\mathbf{x} \\, \\mathrm{d}\\mathbf{x} \\in M.\n\\]\nIn other words, the expectation value must be within the convex set.\n\n\n\nSimplices: \\[\nS = \\left\\{\n\\mathbf{x} \\in \\mathbb{R}^n: \\exists \\theta_1, \\dotsc, \\theta_n \\in [0, 1], \\, \\textstyle\\sum_{i=1}^n \\displaystyle \\theta_i = 1 : \\mathbf{x} = \\sum_{i=1}^n \\theta_i \\mathbf{v}_i\n\\right\\}\n\\]\nPolyhedra \\[\n  P = \\Bigl\\{\n     \\mathbf{x} \\in \\mathbb{R}^n : \\mathbf{a}_j^\\mathrm{T} \\mathbf{x} \\leq b_j, \\, \\mathbf{c}_k^\\mathrm{T} \\mathbf{x} = d_k, \\, j=1,\\dotsc, m, \\, k=1,\\dotsc,p\n  \\Bigr\\}\n\\]\n\n. . .\n\n\n\n\n\n\n\n\nSimplex\nauthor: Robert Webb\nsource: wikimedia.org url: Stella software\n\n\n\n\n \n\n\n\n\n\nPolyhedron\nauthor: Tilman Piesk\nsource: wikimedia.org license: CC BY-SA 4.0\n\n\n\n\n\n\nFigure 2: Simplices and Polyhedra are examples for convex sets.\n\n\n\n\n\n\n\nIntersection: If \\(A\\) and \\(B\\) are convex, then the intersection \\[\nA \\cap B\n\\] is also convex.\naffine Transformations: If \\(M\\) is a convex set and \\(f:\\mathbb{R}^n \\to \\mathbb{R}^n\\) is an affine transformation, i.e. \\(f(\\mathbf{x}) = A \\mathbf{x} + \\mathbf{b}\\), then the image \\[\nf(M)\n\\] is also convex.\nThe projection of a convex set onto some of it’s coordinates is convex: If \\(S \\subseteq \\mathbb{R}^m \\times \\mathbb{R}^n\\), then \\[\nT = \\{ x_1 \\in \\mathbb{R}^m | (x_1, x_2) \\in S \\;\\text{for some $x_2 \\in \\mathbb{R}^n$} \\}\n\\] is convex.[1]\n\n. . .\nAs a simple corollary, we can see that the perspective function \\(f: \\mathbb{R}^n \\times \\mathbb{R}^+\\), \\[\nf(\\mathbf{x}, t) = \\frac{\\mathbf{x}}{t}\n\\] preserves convexity.\n. . .\nVisually, we can interpret the perspective function as a pinhole camera.\n\n\n\n\n\n\n\n\n\nImportantSeparating Hyperplane Theorem\n\n\n\nSuppose \\(A\\) and \\(B\\) are non-empty, disjoint sets, i.e. \\(A \\cap B = \\emptyset\\). Then there exists \\(\\mathbf{a} \\ne \\mathbf{0}\\) and \\(b\\) such that \\(\\mathbf{a}^\\mathrm{T} \\mathbf{x} \\leq b\\) for all \\(\\mathbf{x} \\in A\\) and \\(b \\leq \\mathbf{a}^\\mathrm{T} \\mathbf{x}\\) for all \\(\\mathbf{x} \\in B\\).\n\n\n. . .\n\n\n\n\n\n\nFigure 3: Separating Hyperplane Theorem\nauthor: Oleg Alexandrov\nsource: Wikimedia license: public domain (CC0)\n\n\n\n. . .\n\nProof. See notes.\n\n. . .\n\n\n\n\n\n\nNote\n\n\n\nThis result can be generalized to the Hahn-Banach separation theorem.",
    "crumbs": [
      "About me",
      "Optimization",
      "Convex Sets and Functions"
    ]
  },
  {
    "objectID": "Optimization/convexity.html#convex-sets",
    "href": "Optimization/convexity.html#convex-sets",
    "title": "Convex Sets and convex Functions",
    "section": "",
    "text": "Before we start with optimisation algorithms, we first need to introduce some concepts.\n. . .\n\n\n\n\n\n\nNoteConvex Set\n\n\n\nA set \\(M\\) is called convex if for any \\(\\mathbf{x}_1, \\mathbf{x}_2 \\in M\\): \\[\n\\theta \\mathbf{x}_1 + (1-\\theta) \\mathbf{x}_2 \\in M\n\\qquad \\forall \\theta \\in [0, 1]\n\\]\n\n\n. . .\nIn other words, a set is convex if any line connecting two of its points is also contained within the set.\n. . .\n\n\n\n\n\n\n\n\nconvex set\nsource: wikimedia.org license: CC BY-SA 4.0\n\n\n\n\n \n\n\n\n\n\nnonconvex set\nsource: wikimedia.org license: CC BY-SA 4.0\n\n\n\n\n\n\nFigure 1: Examples for convex and nonconvex sets\n\n\n\n\nThe expression \\(\\theta \\mathbf{x}_1 + (1-\\theta) \\mathbf{x}_2\\) is called an convex-combination.\n. . .\nThis can be generalized to more than two points. Let’s say we have multiple points \\(x_1, \\dotsc, x_n\\), then we have \\[\n\\sum_{i=1}^n \\theta_i \\mathbf{x}_i \\in M\n\\] where \\[\n\\theta_i \\ge 0 \\quad \\forall 1 \\leq i \\leq n, \\quad \\sum_{i=1}^n \\theta_i = 1.\n\\]\n. . .\nFor anyone familiar with statistics, this will look very similar to the expectation of a probability distribution.\nAnd indeed, this can be generalised to continuous functions: Suppose \\(p(\\mathbf{x})\\) satisfies \\(p(\\mathbf{x}) \\gt 0\\) and \\[\n\\int_M p(\\mathbf{x}) \\, \\mathrm{d}\\mathbf{x} = 1,\n\\] then \\[\n\\int_M p(\\mathbf{x}) \\mathbf{x} \\, \\mathrm{d}\\mathbf{x} \\in M.\n\\]\nIn other words, the expectation value must be within the convex set.\n\n\n\nSimplices: \\[\nS = \\left\\{\n\\mathbf{x} \\in \\mathbb{R}^n: \\exists \\theta_1, \\dotsc, \\theta_n \\in [0, 1], \\, \\textstyle\\sum_{i=1}^n \\displaystyle \\theta_i = 1 : \\mathbf{x} = \\sum_{i=1}^n \\theta_i \\mathbf{v}_i\n\\right\\}\n\\]\nPolyhedra \\[\n  P = \\Bigl\\{\n     \\mathbf{x} \\in \\mathbb{R}^n : \\mathbf{a}_j^\\mathrm{T} \\mathbf{x} \\leq b_j, \\, \\mathbf{c}_k^\\mathrm{T} \\mathbf{x} = d_k, \\, j=1,\\dotsc, m, \\, k=1,\\dotsc,p\n  \\Bigr\\}\n\\]\n\n. . .\n\n\n\n\n\n\n\n\nSimplex\nauthor: Robert Webb\nsource: wikimedia.org url: Stella software\n\n\n\n\n \n\n\n\n\n\nPolyhedron\nauthor: Tilman Piesk\nsource: wikimedia.org license: CC BY-SA 4.0\n\n\n\n\n\n\nFigure 2: Simplices and Polyhedra are examples for convex sets.\n\n\n\n\n\n\n\nIntersection: If \\(A\\) and \\(B\\) are convex, then the intersection \\[\nA \\cap B\n\\] is also convex.\naffine Transformations: If \\(M\\) is a convex set and \\(f:\\mathbb{R}^n \\to \\mathbb{R}^n\\) is an affine transformation, i.e. \\(f(\\mathbf{x}) = A \\mathbf{x} + \\mathbf{b}\\), then the image \\[\nf(M)\n\\] is also convex.\nThe projection of a convex set onto some of it’s coordinates is convex: If \\(S \\subseteq \\mathbb{R}^m \\times \\mathbb{R}^n\\), then \\[\nT = \\{ x_1 \\in \\mathbb{R}^m | (x_1, x_2) \\in S \\;\\text{for some $x_2 \\in \\mathbb{R}^n$} \\}\n\\] is convex.[1]\n\n. . .\nAs a simple corollary, we can see that the perspective function \\(f: \\mathbb{R}^n \\times \\mathbb{R}^+\\), \\[\nf(\\mathbf{x}, t) = \\frac{\\mathbf{x}}{t}\n\\] preserves convexity.\n. . .\nVisually, we can interpret the perspective function as a pinhole camera.\n\n\n\n\n\n\n\n\n\nImportantSeparating Hyperplane Theorem\n\n\n\nSuppose \\(A\\) and \\(B\\) are non-empty, disjoint sets, i.e. \\(A \\cap B = \\emptyset\\). Then there exists \\(\\mathbf{a} \\ne \\mathbf{0}\\) and \\(b\\) such that \\(\\mathbf{a}^\\mathrm{T} \\mathbf{x} \\leq b\\) for all \\(\\mathbf{x} \\in A\\) and \\(b \\leq \\mathbf{a}^\\mathrm{T} \\mathbf{x}\\) for all \\(\\mathbf{x} \\in B\\).\n\n\n. . .\n\n\n\n\n\n\nFigure 3: Separating Hyperplane Theorem\nauthor: Oleg Alexandrov\nsource: Wikimedia license: public domain (CC0)\n\n\n\n. . .\n\nProof. See notes.\n\n. . .\n\n\n\n\n\n\nNote\n\n\n\nThis result can be generalized to the Hahn-Banach separation theorem.",
    "crumbs": [
      "About me",
      "Optimization",
      "Convex Sets and Functions"
    ]
  },
  {
    "objectID": "Optimization/convexity.html#convex-functions",
    "href": "Optimization/convexity.html#convex-functions",
    "title": "Convex Sets and convex Functions",
    "section": "Convex Functions",
    "text": "Convex Functions\n\n\n\n\n\n\nNoteConvex functions\n\n\n\nLet \\(D\\) be a convex set. A function \\(f: D \\to \\mathbb{R}\\) is called convex if \\[\nf\\bigl(\\theta \\mathbf{x}_1 + (1-\\theta) \\mathbf{x}_2\\bigr) \\leq \\theta f(\\mathbf{x}_1) + (1-\\theta) f(\\mathbf{x}_2), \\qquad \\theta \\in [0, 1]\n\\]\n\n\n. . .\nVisually, this means that the graph between two points always lies below the secant line connecting them.\n\n\nCode\nusing Plots\nusing LaTeXStrings\ntheme(:dark)\n#default(size = (800, 600))  # set default plot size\n\n# Define objective function f\nf(x) = -0.01548523*x^4 + 0.09320228*x^3 + 0.21426876*x^2 + -0.83797152*x + 0.90722445\n\nxmin = -0.654\nxmax = 4.074\nx = range( xmin, xmax, length=100)\n\nx1 = 0.56\nx2 = 3.284\ntheta = 0.3\nx_comb = theta * x1 + (1 - theta) * x2\n\n# Plot function f\nplot(x, f, color=:darkblue, linewidth=4,\n    legend=false, \n    xticks = ([x1, x2], [\"x₁\", \"x₂\"]),\n    yticks = ([f(x1), f(x2)], [\"f(x₁)\", \"f(x₂)\"]))\n\n# Draw the line segment connecting (x1, f(x1)) and (x2, f(x2))\nplot!([x1, x2], [f(x1), f(x2)],\n    lw = 1.5, ls = :dash, color = :green)\n\n# Plot horizontal and vertical lines\nplot!([xmin, x1, x1], [f(x1), f(x1), 0],\n        lw = 1.5, ls = :dash, color = :gray )\nplot!([x2, x2, xmin], [0, f(x2), f(x2)],\n    lw = 1.5, ls = :dash, color = :gray )\n\n# Plot points (x1, f(x1)) and (x2, f(x2))\nscatter!([x1, x2, x_comb], [f(x1), f(x2), f(x_comb)],\n        markersize = 6, color = :red)\n\n# Annotations\nannotate!(x_comb + 0.05, f(x_comb) - 0.05, text(L\"f(\\theta x_1 + (1-\\theta) x_2)\", :white, :left, :top, 15))\nannotate!(x_comb + 0.05, theta * f(x1) + (1-theta) * f(x2), text(L\"\\theta f(x_1) + (1-\\theta) f(x_2)\", :white, :right, 15))\n\n\n\n\n\n\n\nFigure 4: A convex function\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nplt.style.use('seaborn')\n\nf = lambda x: -0.01548523*x**4 + 0.09320228*x**3 + 0.21426876*x**2 + -0.83797152*x + 0.90722445\n\nxmin = -0.654\nxmax = 4.074\nx = np.linspace( xmin, xmax, num=100)\n\nx1 = 0.56\nx2 = 3.284\ntheta = 0.55\nx_comb = theta * x1 + (1 - theta) * x2\n\n# Plot function f\nplt.plot(x, f(x))\n\n\n# Set xticks and xticklabels\nax = plt.gca()\nplt.xticks([x1, x2])\nax.set_xticklabels([r'$x_1$', r'$x_2$'])\nplt.yticks(np.array([f(x1), f(x2)]))\nax.set_yticklabels([r'$f(x_1)$', r'$f(x_2)$'])\n\n# move axes to origin\nax.spines[\"bottom\"].set_position(\"zero\")\nax.spines[\"left\"].set_position(\"zero\")\n\n# Box off\nax.spines[\"top\"].set_color(\"none\")\nax.spines[\"right\"].set_color(\"none\")\n\n\n# Draw the line segment connecting (x1, f(x1)) and (x2, f(x2))\nplt.plot([x1, x2], [f(x1), f(x2)],\n    color = \"green\", linestyle = \"dashed\", linewidth = 1.5)\n\n# Plot horizontal and vertical lines\nplt.plot([0, x1, x1], [f(x1), f(x1), 0],\n    color = \"gray\", linestyle = \"dashed\", linewidth = 1.5)\nplt.plot([x2, x2, 0], [0, f(x2), f(x2)],\n    color = \"gray\", linestyle = \"dashed\", linewidth = 1.5)\n\n# Plot points (x1, f(x1)), (x2, f(x2)) and (xm, f(xm))\nplt.plot([x1, x2, x_comb], [f(x1), f(x2), f(x_comb)],\n    \".r\", markersize = 15)\n\n\nExamples for convex function\n\nExample:\n\n\n\n\n\n\nTipHimmelblau-function\n\n\n\nThe Himmelblau function is a common test function for optimization problems. It is defined by:\n\\[\nf(x,y) = (x^2 + y - 11)^2 + (x + y^2 - 7)^2\n\\]\nThis function has four identical local minima, one of which is \\(f(3, 2) = 0\\).\n\n\n. . .\n\n\nCode\nusing Plots\ntheme(:dark)\n\n# Himmelblau function\nf(x,y) = (x^2 + y - 11)^2 + (x + y^2 - 7)^2\n\nx = range(-5, 5, length=100);\ny = range(-5, 5, length=100);\nz = @. f(x', y);\n\ncontour(x, y, z, levels=20, color=:turbo, cbar=false, lw=1)\nscatter!([3.0, -2.805118, -3.779310, 3.584428], [2.0, 3.131312, -3.283186, -1.848126], legend=false)\n\ntitle!(\"Contour Plot of the Himmelblau function\")\nxlabel!(\"x\")\nylabel!(\"y\")\n\n\n\n\n\n\n\nFigure 5: Contour plot of the Himmelblau function\n\n\n\n\n\n\n\nCode\nusing Plots; plotlyjs()\ntheme(:dark)\n\n# Himmelblau function\nf(x,y) = (x^2 + y - 11)^2 + (x + y^2 - 7)^2\n\nx = range(-5, 5, length=100);\ny = range(-5, 5, length=100);\nz = @. f(x', y);\n\nsurface(x, y, z, color=:hot, cbar=false, lw=1)\n\ntitle!(\"Surface Plot of the Himmelblau function\")\nxlabel!(\"x\")\nylabel!(\"y\")\n\n\n\nThe WebIO Jupyter extension was not detected. See the\n\n    WebIO Jupyter integration documentation\n\nfor more information.\n\n\n\n    \n    \n\n\n\n. . .\n\n\n\n\n\n\nTipSolution\n\n\n\n\n\nCalculate the gradient: \\[\n\\begin{aligned}\n\\nabla f &=\n\\begin{bmatrix}\n2(x^2 + y - 11) 2x + 2(x + y^2 - 7) \\\\\n2(x^2 + y - 11) + 2(x + y^2 - 7) 2y\n\\end{bmatrix} \\\\\n&=\n\\begin{bmatrix}\n4x^3 + 2y^2 + 4xy - 42x - 14 \\\\\n4 y^3 + 2x^2 + 4xy - 26y - 22\n\\end{bmatrix}\n\\end{aligned}\n\\]\nCalculate the Hessian: \\[\n\\begin{aligned}\nH &=\n\\begin{bmatrix}\n12x^2 + 4y - 42 & 4x + 4y \\\\\n4x + 4y & 12y^2 + 4x - 26\n\\end{bmatrix}\n\\end{aligned}\n\\]\nSubstitue \\((3, 2)\\) for \\(x\\) and \\(y\\): \\[\nH(3, 2) =\n\\begin{bmatrix}\n74 & 20 \\\\\n20 & 34\n\\end{bmatrix}\n\\]\nDeterminte the characteristic polynomial: \\[\n\\begin{aligned}\n\\det (H - \\lambda I) &=\n\\begin{vmatrix}\n74 - \\lambda & 20 \\\\\n20 & 34 - \\lambda\n\\end{vmatrix} \\\\\n&= (74 - \\lambda) (34 - \\lambda) - 20^2  \\\\\n&= \\lambda^2 - 108 \\lambda + 2116 \\\\\n&\\overset{\\text{!}}{=} 0\n\\end{aligned}\n\\]\nSolve for \\(\\lambda\\) to obtain the Eigenvalues: \\[\n\\begin{aligned}\n\\lambda_1 = \\frac{108}{2} - \\sqrt{ \\left( \\frac{108}{2} \\right)^2 - 2116}\n\\approx 25.716 \\\\\n\\lambda_2 = \\frac{108}{2} + \\sqrt{ \\left( \\frac{108}{2} \\right)^2 - 2116}\n\\approx 82.284\n\\end{aligned}\n\\]\nAll Eigenvalues are greater than 0, so \\(f\\) is in (3, 2) positive definite.\n\n\n\n. . .\nAlternatively, we can also solve this using the Symbolics package in Julia:\n\nJuliaPython + SymPyMATLAB/OctavePython + Autograd\n\n\nusing Symbolics\nusing LinearAlgebra\n\n# Himmelblau function\nf(x, y) = (x^2 + y - 11)^2 + (x + y^2 - 7)^2\n\nvars = @variables x, y\nf_sym = f(x, y)\n\nH = Symbolics.hessian(f_sym, vars)\nH_at_point = substitute.(H, Ref(Dict( x=&gt;3.0, y=&gt;2.0) ))\n\nisposdef(H_at_point)\n\n\nimport numpy as np\nfrom sympy import symbols, hessian\nfrom scipy import linalg\n\nf = lambda x, y: (x**2 + y - 11)**2 + (x + y**2 - 7)**2  \n\nx, y = symbols(\"x y\")\nf_sym = f(x, y)\n\nH = hessian(f_sym, (x,y))\nH_at_point = np.array( H.subs( {x:3, y:2} ) )\n\nlinalg.cholesky(H_at_point)\n\n\npkg load symbolic\n\n% Himmelblau function\nf = @(x, y) (x^2 + y - 11)^2 + (x + y^2 - 7)^2\n\nsyms x; syms y;\n\nf_sym = f(x, y)\nH_sym = hessian(f_sym)\nH = function_handle(H_sym)\nH_at_point = H(3, 2)\n\nchol(H_at_point)\n\n\nimport autograd.numpy as np\nfrom autograd import hessian\nfrom scipy import linalg\n\nf = lambda X: (X[0]**2 + X[1] - 11)**2 + (X[0] + X[1]**2 - 7)**2  \n\nH = hessian(f)\npoint = np.array([3.0, 2.0])\nH_at_point = H(point)\n\nlinalg.cholesky(H_at_point)\n\n\n\n\nTODO:\n\ndefinition conxex functions\nexamples: norm(x), affine fct. f(x) = c.T x + b, quadratic fct. x.T A x\nsublevel sets of convex functions are convex sets (proof trivial)\nEpigraphs: A function is convex if and only if it’s epigraph is convex.\nJennsen’s inequality\nOperations that preserve convexity: Composition with affine mapping\nDefinition of convex conjugate of a function (generalization of Legendre transformation)\nExamples for convex conjugate (see p. 92)",
    "crumbs": [
      "About me",
      "Optimization",
      "Convex Sets and Functions"
    ]
  },
  {
    "objectID": "Optimization/index-slides.html#why-learn-optimization",
    "href": "Optimization/index-slides.html#why-learn-optimization",
    "title": "Introduction",
    "section": "Why learn Optimization?",
    "text": "Why learn Optimization?\nConvex optimisation is an important field of applied mathematics. It involves finding the minimum of a given objective function subject to certain constraints. Optimisation has many applications in machine learning, computational physics, and finance. Examples include minimising risk for portfolio optimisation, minimising an error function to fit a machine learning model and minimising the energy of a system in computational physics.\n\n\n\n\nnonlinear optimization\nsource: arXiv:1805.04829"
  },
  {
    "objectID": "Optimization/index-slides.html#about-this-course",
    "href": "Optimization/index-slides.html#about-this-course",
    "title": "Introduction",
    "section": "About this Course",
    "text": "About this Course\nTarget Audience:\n\nStudents in math/physics/engineering\nProgrammers who want to develop a better understanding of optimization algorithms\nanyone who is interested in convex optimization\n\n\nPrerequisites:\n\nsolid knowledge of Linear Algebra and Calculus\nbasic programming skills (Julia/Python/MATLAB)"
  },
  {
    "objectID": "Optimization/index-slides.html#introduction",
    "href": "Optimization/index-slides.html#introduction",
    "title": "Introduction",
    "section": "Introduction",
    "text": "Introduction\nThis course focuses on optimisation problems of the following form:\nFind a minimum of \\[\n\\mathop{\\mathrm{arg\\,min}}_{\\mathbf{x}} \\; f(\\mathbf{x})\n\\] subject to \\[\n\\begin{aligned}\nh(\\mathbf{x}) &= 0 \\\\\ng(\\mathbf{x}) &\\leq 0\n\\end{aligned}\n\\]\nThe function \\(f\\) is called objective function, and \\(h\\) and \\(g\\) are constraints of the optimization problem.\n\n\nSuch optimisation problems can arise, for example, from modelling real-world problems with neural networks, where the aim is to minimise the error between the model and the training dataset. However, large neuronal networks can have billions of parameters (‘weights’). Consequently, these problems can be extremely complex, to the extent that they cannot be solved by hand. We are therefore interested in finding algorithms that can solve these optimization problems efficiently.\n\n\n\nA good optimisation algorithm should have the following properties:\n\nRobustness: The algorithm should work with a very general set of data.\nEfficiency: It should not require excessive computational resources.\nAccuracy: The results should be accurate and not overly sensitive to errors in the data."
  },
  {
    "objectID": "Optimization/index-slides.html#examples-for-optimization-problems",
    "href": "Optimization/index-slides.html#examples-for-optimization-problems",
    "title": "Introduction",
    "section": "Examples for Optimization Problems",
    "text": "Examples for Optimization Problems\nOptimisation problems occur in all kinds of applications. Here are some examples:"
  },
  {
    "objectID": "Optimization/index-slides.html#machine-learning",
    "href": "Optimization/index-slides.html#machine-learning",
    "title": "Introduction",
    "section": "1. Machine Learning",
    "text": "1. Machine Learning\nA common problem in machine learning is classification. You are given a set of points belonging to different classes and need to find a decision boundary to separate them. One possible solution is to fit the decision boundary so that the margin is maximised. This is the approach used by so-called Support Vector Machines (SVM).\n\n\n\nSupport Vector Machines as maxmimum-margin-classifiers\nauthor: Sidharth GN, source: quarkml.com"
  },
  {
    "objectID": "Optimization/index-slides.html#markowitz-portfolio-optimization",
    "href": "Optimization/index-slides.html#markowitz-portfolio-optimization",
    "title": "Introduction",
    "section": "2. Markowitz-Portfolio Optimization",
    "text": "2. Markowitz-Portfolio Optimization\n\nThe Markowitz Mean-Variance Portfolio Optimization model provides a framework for investors to construct diversified portfolios that minimize risk for a given level of expected return. The core idea is that investors care about two things: the expected return of their portfolio and the risk of that portfolio. By quantifying these, an optimal trade-off can be found.\n\nThis can be expressed mathematically as follows: Minimize the risk \\[\n\\min_{\\mathbf{x}} \\mathbf{x}^\\mathrm{T} \\Sigma \\mathbf{x}\n\\]\n\nsubject to the constraints that the expected return exceeds a target value \\(R_{\\text{target}}\\) and that the sum of all portfolio weights is 100%.\n\\[\n\\begin{aligned}\n\\sum_{i=1}^N x_i &= 1 \\\\\n\\sum_{i=1}^N \\mathbb{E}[R_i] x_i &\\geq R_{\\text{target}}.\n\\end{aligned}\n\\]\n\n\nwhere:\n\n\\(\\mathbf{x}\\) is a vector of portfolio weights between 0 and 100%,\n\\(\\Sigma\\) is the covariance matrix representing the expected risk,\n\\(\\mathbb{E}[R_i]\\) are the expected returns of each assets, and\n\\(R_{\\text{target}}\\) is a constraint for the expected return\n\n\n\n\nThe risk of an asset is essentially its standard deviation in pricing, or its volatility. The covariance matrix and expected returns are model parameters that need to be estimated beforehand.\n\nAs the objective function is a quadratic form with a positive semi-definite covariance matrix, this is a convex optimisation problem."
  },
  {
    "objectID": "Optimization/index-slides.html#partial-differential-equations",
    "href": "Optimization/index-slides.html#partial-differential-equations",
    "title": "Introduction",
    "section": "3. Partial Differential Equations",
    "text": "3. Partial Differential Equations\nThe Poisson equation is one of the simplest differential equations. It describes the electric potential in a capacitor with a given charge density.\n\\[\n\\begin{aligned}\n- \\Delta u &= f, && \\text{in $\\Omega$}, \\\\\nu &= 0, && \\text{on $\\partial\\Omega$}\n\\end{aligned}\n\\]\n\nHere, \\(\\Omega := [a, b]^2 \\subseteq \\mathbb{R}^2\\) is the domain of the problem, and \\(u  = 0\\) is the (Dirichlet) boundary condition.\n\n\nMultiplying both sides by a test function v and then applying Green’s identity gives us the weak formulation of the differential equation:\n\\[\n\\int_\\Omega \\nabla u \\cdot \\nabla v \\, \\mathrm{d}\\mathbf{x} = \\int_\\Omega f v \\,\\mathrm{d}x\n\\]\n\n\nThe weak formulation plays an important role in the finite element method. It can also be viewed as the Gateaux differential of an energy functional:\n\\[\nJ[u] = \\frac{1}{2} \\int_\\Omega \\nabla u \\cdot \\nabla u \\, \\mathrm{d}\\mathbf{x} - \\int_\\Omega f v \\,\\mathrm{d}\\mathbf{x} \\overset{\\text{!}}{=} \\min\n\\]\nThis is a variational problem. The minimum of the energy functional is also a solution of the Poisson equation."
  },
  {
    "objectID": "Optimization/index-slides.html#references",
    "href": "Optimization/index-slides.html#references",
    "title": "Introduction",
    "section": "References",
    "text": "References\n\n\nBoyd, Stephen, and Lieven Vandenberghe. 2004. Convex Optimization. Cambridge University Press. https://web.stanford.edu/~boyd/cvxbook/.\n\n\nKochenderfer, Mykel J., and Tim A. Wheeler. 2019. Algorithms for Optimization. Cambridge, MA: The MIT Press. https://algorithmsbook.com/optimization/.\n\n\nNocedal, Jorge, and Stephen J. Wright. 2006. Numerical Optimization. 2nd ed. Springer.\n\n\nRüdiger Reinhardt, Armin, and Tobias Gerlach Hoffmann. 2013. Nichtlineare Optimierung: Theorie, Numerik Und Experimente. Springer Spektrum."
  },
  {
    "objectID": "Optimization/index.html",
    "href": "Optimization/index.html",
    "title": "Introduction",
    "section": "",
    "text": "Convex optimisation is an important field of applied mathematics. It involves finding the minimum of a given objective function subject to certain constraints. Optimisation has many applications in machine learning, computational physics, and finance. Examples include minimising risk for portfolio optimisation, minimising an error function to fit a machine learning model and minimising the energy of a system in computational physics.\n\n\n\n\nnonlinear optimization\nsource: arXiv:1805.04829",
    "crumbs": [
      "About me",
      "Optimization",
      "Introduction"
    ]
  },
  {
    "objectID": "Optimization/index.html#why-learn-optimization",
    "href": "Optimization/index.html#why-learn-optimization",
    "title": "Introduction",
    "section": "",
    "text": "Convex optimisation is an important field of applied mathematics. It involves finding the minimum of a given objective function subject to certain constraints. Optimisation has many applications in machine learning, computational physics, and finance. Examples include minimising risk for portfolio optimisation, minimising an error function to fit a machine learning model and minimising the energy of a system in computational physics.\n\n\n\n\nnonlinear optimization\nsource: arXiv:1805.04829",
    "crumbs": [
      "About me",
      "Optimization",
      "Introduction"
    ]
  },
  {
    "objectID": "Optimization/index.html#about-this-course",
    "href": "Optimization/index.html#about-this-course",
    "title": "Introduction",
    "section": "About this Course",
    "text": "About this Course\n\nTarget Audience\nThis course is primarily aimed at undergraduate students of mathematics, physics and engineering. However, it is also suitable for software developers and engineers interested in machine learning who want to develop a better understanding of the optimisation algorithms behind these models.\n\n\nPrerequisites\nThis is not an introductory course, so a solid understanding of linear algebra and calculus. For the implementation of the numerical algorithms, it is also useful to have some programming skills in either MATLAB, Python or Julia. However, there will be a short introduction to Julia programming at the beginning, so basic programming skills are sufficient.\n\n\nSyllabus\n\nWeek 1 – 5: lorem ipsum\nWeek 6 – 10: lorem ipsum\n\n\n\n\n\n\n\nNote\n\n\n\nThe exact structure of this course is subject to change and may vary.",
    "crumbs": [
      "About me",
      "Optimization",
      "Introduction"
    ]
  },
  {
    "objectID": "Optimization/index.html#literature",
    "href": "Optimization/index.html#literature",
    "title": "Introduction",
    "section": "Literature",
    "text": "Literature\n\nRecommended Textbooks\n\nThe book [1] is certainly considered the ‘bible’ of convex optimisation. It has been cited over 4,400 times and is extremely comprehensive. The fact that it is available for free is an added bonus. However, I think this book is a bit overwhelming, especially for beginners. For instance, it devotes over 300 pages to the theory behind convex functions before moving on to numerical algorithms.\nIn my opinion, the book [2] by Nocedal and Wright is better structured, covering everything from quasi-Newton and trust region methods to algorithms for constrained optimisation problems.\nMathematical optimisation is a highly practical field. As such, a modern textbook on the subject should include code to demonstrate how to implement these algorithms in practice. This is the case for [3], which is an excellent textbook for bridging the gap between maths and programming. It also contains many colourful illustrations, making it a pleasure to read. If I had to recommend one book for learning optimization, it would be this one.\n\n\n\n\n\n\n\n\n[1]\n\n\n\n\n\n \n\n\n\n\n\n\n[2]\n\n\n\n\n\n \n\n\n\n\n\n\n[4]\n\n\n\n\n\n \n\n\n\n\n\n\n[3]\n\n\n\n\n\n\n\n\nOnline Courses\n\nThere are also a few online courses on optimisation available. For example:\n\n\nStanford EE364A Convex Optimization by Stephen Boyd, 2023\nOptimization Method for Machine Learning by Julius Pfrommer, KIT 2020/21",
    "crumbs": [
      "About me",
      "Optimization",
      "Introduction"
    ]
  },
  {
    "objectID": "Optimization/index.html#introduction",
    "href": "Optimization/index.html#introduction",
    "title": "Introduction",
    "section": "Introduction",
    "text": "Introduction\nThis course focuses on optimisation problems of the following form:\nFind a minimum of \\[\n\\mathop{\\mathrm{arg\\,min}}_{\\mathbf{x}} \\; f(\\mathbf{x})\n\\] subject to \\[\n\\begin{aligned}\nh(\\mathbf{x}) &= 0 \\\\\ng(\\mathbf{x}) &\\leq 0\n\\end{aligned}\n\\]\nThe function \\(f\\) is called objective function, and \\(h\\) and \\(g\\) are constraints of the optimization problem.\n. . .\n\nSuch optimisation problems can arise, for example, from modelling real-world problems with neural networks, where the aim is to minimise the error between the model and the training dataset. However, large neuronal networks can have billions of parameters (‘weights’). Consequently, these problems can be extremely complex, to the extent that they cannot be solved by hand. We are therefore interested in finding algorithms that can solve these optimization problems efficiently.\n\n. . .\nA good optimisation algorithm should have the following properties:\n\nRobustness: The algorithm should work with a very general set of data.\nEfficiency: It should not require excessive computational resources.\nAccuracy: The results should be accurate and not overly sensitive to errors in the data.",
    "crumbs": [
      "About me",
      "Optimization",
      "Introduction"
    ]
  },
  {
    "objectID": "Optimization/index.html#examples-for-optimization-problems",
    "href": "Optimization/index.html#examples-for-optimization-problems",
    "title": "Introduction",
    "section": "Examples for Optimization Problems",
    "text": "Examples for Optimization Problems\nOptimisation problems occur in all kinds of applications. Here are some examples:",
    "crumbs": [
      "About me",
      "Optimization",
      "Introduction"
    ]
  },
  {
    "objectID": "Optimization/index.html#machine-learning",
    "href": "Optimization/index.html#machine-learning",
    "title": "Introduction",
    "section": "1. Machine Learning",
    "text": "1. Machine Learning\nA common problem in machine learning is classification. You are given a set of points belonging to different classes and need to find a decision boundary to separate them. One possible solution is to fit the decision boundary so that the margin is maximised. This is the approach used by so-called Support Vector Machines (SVM).\n\n\n\nSupport Vector Machines as maxmimum-margin-classifiers\nauthor: Sidharth GN, source: quarkml.com\n\n\n\nIf \\(w\\) is the normal vector of the decision boundary, \\(b\\) is the ‘bias’ parameter that determines the distance to the origin of the coordinate system and \\(t_n\\) is the target value (1 if the point \\(x_n\\) belongs to the class and -1 if it does not), then we need to find:\n\\[\n\\mathop{\\mathrm{arg\\,max}}_{\\mathbf{w}, b} \\frac{1}{\\lVert \\mathbf{w} \\rVert} \\min_{n=1,\\dotsc,N} \\left\\{ t_n \\mathbf{w}^\\mathrm{T} \\mathbf{x}_n + b \\right\\}\n\\]\n. . . Without loss of generality, we can choose w and b so that the margin is scaled to 1. This leads to the following optimization problem:\n\\[\n\\begin{aligned}\n\\mathop{\\mathrm{arg\\,min}}_{\\mathbf{w}, b} \\frac{1}{2} \\lVert \\mathbf{w} \\rVert^2 \\\\\n\\text{s.t.}\\quad t_n (\\mathbf{w}^\\mathrm{T} \\mathbf{x}_n + b) \\geq 1\n\\end{aligned}\n\\]\n. . .\nThis is an example for a quadratic programming problem, which is quite difficult to solve.",
    "crumbs": [
      "About me",
      "Optimization",
      "Introduction"
    ]
  },
  {
    "objectID": "Optimization/index.html#markowitz-portfolio-optimization",
    "href": "Optimization/index.html#markowitz-portfolio-optimization",
    "title": "Introduction",
    "section": "2. Markowitz-Portfolio Optimization",
    "text": "2. Markowitz-Portfolio Optimization\n\nThe Markowitz Mean-Variance Portfolio Optimization model provides a framework for investors to construct diversified portfolios that minimize risk for a given level of expected return. The core idea is that investors care about two things: the expected return of their portfolio and the risk of that portfolio. By quantifying these, an optimal trade-off can be found.\n\nThis can be expressed mathematically as follows: Minimize the risk \\[\n\\min_{\\mathbf{x}} \\mathbf{x}^\\mathrm{T} \\Sigma \\mathbf{x}\n\\]\n. . .\nsubject to the constraints that the expected return exceeds a target value \\(R_{\\text{target}}\\) and that the sum of all portfolio weights is 100%.\n\\[\n\\begin{aligned}\n\\sum_{i=1}^N x_i &= 1 \\\\\n\\sum_{i=1}^N \\mathbb{E}[R_i] x_i &\\geq R_{\\text{target}}.\n\\end{aligned}\n\\]\n. . .\nwhere:\n\n\\(\\mathbf{x}\\) is a vector of portfolio weights between 0 and 100%,\n\\(\\Sigma\\) is the covariance matrix representing the expected risk,\n\\(\\mathbb{E}[R_i]\\) are the expected returns of each assets, and\n\\(R_{\\text{target}}\\) is a constraint for the expected return\n\n. . .\n\nThe risk of an asset is essentially its standard deviation in pricing, or its volatility. The covariance matrix and expected returns are model parameters that need to be estimated beforehand.\n\nAs the objective function is a quadratic form with a positive semi-definite covariance matrix, this is a convex optimisation problem.",
    "crumbs": [
      "About me",
      "Optimization",
      "Introduction"
    ]
  },
  {
    "objectID": "Optimization/index.html#partial-differential-equations",
    "href": "Optimization/index.html#partial-differential-equations",
    "title": "Introduction",
    "section": "3. Partial Differential Equations",
    "text": "3. Partial Differential Equations\nThe Poisson equation is one of the simplest differential equations. It describes the electric potential in a capacitor with a given charge density.\n\\[\n\\begin{aligned}\n- \\Delta u &= f, && \\text{in $\\Omega$}, \\\\\nu &= 0, && \\text{on $\\partial\\Omega$}\n\\end{aligned}\n\\]\n. . .\nHere, \\(\\Omega := [a, b]^2 \\subseteq \\mathbb{R}^2\\) is the domain of the problem, and \\(u  = 0\\) is the (Dirichlet) boundary condition.\n. . .\nMultiplying both sides by a test function v and then applying Green’s identity gives us the weak formulation of the differential equation:\n\\[\n\\int_\\Omega \\nabla u \\cdot \\nabla v \\, \\mathrm{d}\\mathbf{x} = \\int_\\Omega f v \\,\\mathrm{d}x\n\\]\n. . .\nThe weak formulation plays an important role in the finite element method. It can also be viewed as the Gateaux differential of an energy functional:\n\\[\nJ[u] = \\frac{1}{2} \\int_\\Omega \\nabla u \\cdot \\nabla u \\, \\mathrm{d}\\mathbf{x} - \\int_\\Omega f v \\,\\mathrm{d}\\mathbf{x} \\overset{\\text{!}}{=} \\min\n\\]\nThis is a variational problem. The minimum of the energy functional is also a solution of the Poisson equation.",
    "crumbs": [
      "About me",
      "Optimization",
      "Introduction"
    ]
  },
  {
    "objectID": "Optimization/index.html#references",
    "href": "Optimization/index.html#references",
    "title": "Introduction",
    "section": "References",
    "text": "References\n\n\n[1] S. Boyd and L. Vandenberghe, Convex Optimization. Cambridge University Press, 2004. Available: https://web.stanford.edu/~boyd/cvxbook/\n\n\n[2] J. Nocedal and S. J. Wright, Numerical Optimization, 2nd ed. Springer, 2006.\n\n\n[3] M. J. Kochenderfer and T. A. Wheeler, Algorithms for Optimization. Cambridge, MA: The MIT Press, 2019. Available: https://algorithmsbook.com/optimization/\n\n\n[4] A. Rüdiger Reinhardt and T. G. Hoffmann, Nichtlineare Optimierung: Theorie, Numerik Und Experimente. Springer Spektrum, 2013.",
    "crumbs": [
      "About me",
      "Optimization",
      "Introduction"
    ]
  }
]